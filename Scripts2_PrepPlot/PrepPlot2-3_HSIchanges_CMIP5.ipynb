{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_gwls.txt', 'r') as file:    path_gwls  = file.read()\n",
    "    \n",
    "dir_CMIP5    = f'{path_main}Data/CMIP5/HSIs/'\n",
    "dir_GWL      = f'{path_gwls}cmip5_all_ens/'\n",
    "dir_EMT      = f'{path_main}Data/CMIP5/EMT/'\n",
    "dir_names    = f'{path_main}Scripts/Model_lists/'\n",
    "dir_out      = f'{path_main}Data/Plot_preparation/HSI_changes/CMIP5/'\n",
    "if not os.path.exists(dir_out): os.mkdir(dir_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Lisbon', 'Madrid', 'Barcelona', 'Rome', 'Athens', 'Istanbul', 'Sofia', 'Bucharest', 'Belgrade', 'Zagreb',\n",
    "          'Milan', 'Budapest', 'Munich', 'Vienna', 'Prague', 'Paris', 'Brussels', 'Amsterdam', 'London', 'Dublin',\n",
    "          'Hamburg', 'Copenhagen', 'Berlin', 'Warsaw', 'Kharkiv', 'Kyiv', 'Minsk', 'Vilnius', 'Riga', 'Moscow',\n",
    "          'NizhnyNovgorod', 'Kazan', 'SaintPetersburg', 'Helsinki', 'Stockholm', 'Oslo']\n",
    "\n",
    "#Define HSIs\n",
    "HSI_names = ['TX']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CMIP5_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(line[:-1])\n",
    "\n",
    "#Get model names (including member)\n",
    "dir_data = dir_CMIP5 + 'Berlin/rcp85/'\n",
    "model_names = sorted(list(set([\"_\".join(file.split('_')[2:4]) for file in os.listdir(dir_data)])))\n",
    "\n",
    "#Read warming levels\n",
    "fname = dir_GWL + 'cmip5_warming_levels_all_ens_1850_1900_no_bounds_check.yml'\n",
    "with open(fname, 'r') as file:\n",
    "    GWL_data = yaml.safe_load(file)\n",
    "\n",
    "#Define warming levels\n",
    "GWL_levels = ['10', '20', '30', '40']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GWL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "scenarios = ['historical', RCP]\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(model_names), len(cities), len(GWL_levels), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':      ('model', model_names),\n",
    "                               'city':       ('city', cities),\n",
    "                               'GWL_level':  ('GWL_level', GWL_levels),\n",
    "                               't_method':   ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'GWL_level', 't_method'), da_empty.copy())\n",
    "\n",
    "missing_data = dict([ (GWL,set()) for GWL in GWL_levels])\n",
    "    \n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "        #Define members\n",
    "        if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "        elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "        else:                      members = ['r1i1p1']        \n",
    "        \n",
    "        #Loop over members\n",
    "        for member in members:\n",
    "\n",
    "            #Define name for storing data in array\n",
    "            model_name = model + '_' + member\n",
    "            \n",
    "            #Loop over scenarios\n",
    "            create = 1\n",
    "            for scen in scenarios:\n",
    "\n",
    "                #Define folder\n",
    "                dir_data = dir_CMIP5 + city + '/' + scen + '/'\n",
    "\n",
    "                #Read data\n",
    "                fnames_CMIP5 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file and member in file]\n",
    "                fnames_CMIP5 = [file for file in fnames_CMIP5 if 'HSIs_' + city in file]\n",
    "                if len(fnames_CMIP5)!=1:  sys.exit('File is not unique')\n",
    "                data_read = xr.open_dataset(dir_data + fnames_CMIP5[0])\n",
    "\n",
    "                #Concatenate data\n",
    "                if create==1:\n",
    "                    data_CMIP5 = data_read\n",
    "                    create = 0\n",
    "                else:\n",
    "                    data_CMIP5 = xr.concat((data_CMIP5, data_read), dim='time')            \n",
    "\n",
    "            #Read time periods when certain global warming levels (GWL) are reached\n",
    "            time_GWL = dict()\n",
    "            for GWL_level in GWL_levels:\n",
    "                data_level = GWL_data['warming_level_' + GWL_level]\n",
    "                entry_sel = [entry for entry in data_level if entry['model']==model and entry['exp']==RCP and entry['ensemble']==member]\n",
    "\n",
    "                if entry_sel==[]:\n",
    "                    print(model + ': ' + str(GWL_level) + ' missing')\n",
    "                    missing_data[GWL_level] = missing_data[GWL_level].union([model])\n",
    "                    continue\n",
    "\n",
    "                #Select data in time period when GWL is reached\n",
    "                start_year = entry_sel[0]['start_year']\n",
    "                end_year   = entry_sel[0]['end_year']\n",
    "                time_GWL = slice(str(entry_sel[0]['start_year']), str(entry_sel[0]['end_year']))\n",
    "\n",
    "                #Select data\n",
    "                data_20y = data_CMIP5.sel(time=time_GWL)\n",
    "                data_ref = data_CMIP5.sel(time=slice('1981', '2010'))\n",
    "\n",
    "                #Calculate summer average\n",
    "                JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "                JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "\n",
    "                #Calculate yearly maximum\n",
    "                Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "                Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "\n",
    "                #Calculate 90th percentile (for each month in JJA separately)\n",
    "                create = 1\n",
    "                for month in np.arange(6, 9):\n",
    "\n",
    "                    sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                    sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                    sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                    sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                    sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                    sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "\n",
    "                    if create==1:\n",
    "                        Q90_20y = sel_dat_20y\n",
    "                        Q90_ref = sel_dat_ref\n",
    "\n",
    "                        create = 0\n",
    "                    else:\n",
    "                        Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                        Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "\n",
    "                #Calculate mean of 90th percentiles\n",
    "                Q90_20y = Q90_20y.mean('month')\n",
    "                Q90_ref = Q90_ref.mean('month')\n",
    "\n",
    "                #Calculate change\n",
    "                data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "                data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "                data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "\n",
    "                #Loop over HSIs\n",
    "                for HSI in HSI_names:\n",
    "\n",
    "                    #Save in array\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "\n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + RCP + '_GWL.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)    \n",
    "\n",
    "print('\\nMissing data:')\n",
    "[print(str(key) + ': ' + str(data)) for key, data in missing_data.items()];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data according to European warming (EMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "scenarios = ['historical', RCP]\n",
    "\n",
    "EMT_change     = np.array([1.0, 2.0, 3.0])\n",
    "EMT_change_str = ['1.0K', '2.0K', '3.0K']\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "missing_data = dict([ (EMT,set()) for EMT in EMT_change_str])\n",
    "\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(model_names), len(cities), len(EMT_change), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':          ('model', model_names),\n",
    "                               'city':           ('city', cities),\n",
    "                               'EMT_change':     ('EMT_change', EMT_change_str),\n",
    "                               't_method':       ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'EMT_change', 't_method'), da_empty.copy())\n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[RCP]):\n",
    "        \n",
    "        #Define members\n",
    "        if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "        elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "        else:                      members = ['r1i1p1']        \n",
    "        \n",
    "        #Loop over members\n",
    "        for member in members:\n",
    "\n",
    "            #Define name for storing data in array\n",
    "            model_name = model + '_' + member\n",
    "            \n",
    "            #Loop over scenarios\n",
    "            create = 1\n",
    "            for scen in scenarios:\n",
    "\n",
    "                #Define folder\n",
    "                dir_data = dir_CMIP5 + city + '/' + scen + '/'\n",
    "\n",
    "                #Read data\n",
    "                fnames_CMIP5 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file and member in file]\n",
    "                fnames_CMIP5 = [file for file in fnames_CMIP5 if 'HSIs_' + city in file]\n",
    "                if len(fnames_CMIP5)!=1:  sys.exit('File is not unique')\n",
    "                data_read = xr.open_dataset(dir_data + fnames_CMIP5[0])\n",
    "\n",
    "                #Concatenate data\n",
    "                if create==1:\n",
    "                    data_CMIP5 = data_read\n",
    "                    create = 0\n",
    "                else:\n",
    "                    data_CMIP5 = xr.concat((data_CMIP5, data_read), dim='time')\n",
    "\n",
    "            #Read European mean temperature (EMT)\n",
    "            files_EMT = sorted([dir_EMT + file for file in os.listdir(dir_EMT) if model + '_' in file and 'EMT_' in file and member in file])\n",
    "            data_EMT  = xr.concat((xr.open_dataset(file) for file in files_EMT), dim='time')\n",
    "\n",
    "            #Calculate EMT relative to 1981-2010 and calculate 20-year means\n",
    "            dataEMT_ref = data_EMT.sel(time=slice('1981', '2010')).mean('time')\n",
    "            dataEMT_rel = data_EMT - dataEMT_ref\n",
    "            dataEMT_20y = dataEMT_rel.rolling(time=20, center=True).mean()\n",
    "\n",
    "            #Loop over selected EMT levels\n",
    "            for dEMT, dEMT_str in zip(EMT_change, EMT_change_str):\n",
    "\n",
    "                #Identify 20-year period in wich level is reached for first time\n",
    "                ind  = np.where(dataEMT_20y.tas>dEMT)[0]\n",
    "                if len(np.where(dataEMT_20y.tas>dEMT)[0])==0:\n",
    "                    missing_data[dEMT_str] = missing_data[dEMT_str].union([model])\n",
    "                    continue\n",
    "                else:\n",
    "                    ind = ind[0]\n",
    "\n",
    "\n",
    "                central_year = dataEMT_20y.isel(time=ind).time.dt.year\n",
    "                start_year   = int(central_year - 20 / 2)\n",
    "                end_year     = int(central_year + (20 / 2 - 1))\n",
    "                years_sel    = slice(str(start_year), str(end_year))\n",
    "\n",
    "                if end_year>2099:\n",
    "                    print(model, end=': ')\n",
    "                    print(end_year, end=', ')\n",
    "\n",
    "                #Select data\n",
    "                data_20y = data_CMIP5.sel(time=years_sel)\n",
    "                data_ref = data_CMIP5.sel(time=slice('1981', '2010'))\n",
    "\n",
    "                #Calculate summer average\n",
    "                JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "                JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "\n",
    "                #Calculate yearly maximum\n",
    "                Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "                Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "\n",
    "                #Calculate 90th percentile (for each month in JJA separately)\n",
    "                create = 1\n",
    "                for month in np.arange(6, 9):\n",
    "\n",
    "                    sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                    sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                    sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                    sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                    sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                    sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "\n",
    "                    if create==1:\n",
    "                        Q90_20y = sel_dat_20y\n",
    "                        Q90_ref = sel_dat_ref\n",
    "\n",
    "                        create = 0\n",
    "                    else:\n",
    "                        Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                        Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "\n",
    "                #Calculate mean of 90th percentiles\n",
    "                Q90_20y = Q90_20y.mean('month')\n",
    "                Q90_ref = Q90_ref.mean('month')\n",
    "\n",
    "                #Calculate change\n",
    "                data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "                data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "                data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "\n",
    "                #Loop over HSIs\n",
    "                for HSI in HSI_names:\n",
    "\n",
    "                    #Save in array\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "                \n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + RCP + '_EMT.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)\n",
    "\n",
    "print('\\nMissing data:')\n",
    "[print(str(key) + ': ' + str(data)) for key, data in missing_data.items()];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare time period data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select time periods\n",
    "time_periods = [[2036, 2065],\n",
    "                [2070, 2099]]\n",
    "\n",
    "#Define time string\n",
    "time_strings = [str(time[0]) + '-' + str(time[1]) for time in time_periods]\n",
    "\n",
    "#Define RCPs\n",
    "RCPs = ['rcp85']\n",
    "scenarios = ['historical', RCP]\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(model_names), len(cities), len(time_periods), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':       ('model', model_names),\n",
    "                               'city':        ('city', cities),\n",
    "                               'time_period': ('time_period', time_strings),\n",
    "                               't_method':    ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'time_period', 't_method'), da_empty.copy())\n",
    "\n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[RCP]):\n",
    "        \n",
    "        #Define members\n",
    "        if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "        elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "        else:                      members = ['r1i1p1']        \n",
    "        \n",
    "        #Loop over members\n",
    "        for member in members:\n",
    "\n",
    "            #Define name for storing data in array\n",
    "            model_name = model + '_' + member\n",
    "            \n",
    "            #Loop over scenarios\n",
    "            create = 1\n",
    "            for scen in scenarios:\n",
    "\n",
    "                #Define folder\n",
    "                dir_data = dir_CMIP5 + city + '/' + scen + '/'\n",
    "\n",
    "                #Read data\n",
    "                fnames_CMIP5 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file and member in file]\n",
    "                fnames_CMIP5 = [file for file in fnames_CMIP5 if 'HSIs_' + city in file]\n",
    "                if len(fnames_CMIP5)!=1:  sys.exit('File is not unique')\n",
    "                data_read = xr.open_dataset(dir_data + fnames_CMIP5[0])\n",
    "\n",
    "                #Concatenate data\n",
    "                if create==1:\n",
    "                    data_CMIP5 = data_read\n",
    "                    create = 0\n",
    "                else:\n",
    "                    data_CMIP5 = xr.concat((data_CMIP5, data_read), dim='time')            \n",
    "\n",
    "            #Loop over time periods\n",
    "            for time_period, time_string in zip(time_periods, time_strings):\n",
    "\n",
    "                #Select data in selected time period\n",
    "                time_sel = slice(str(time_period[0]), str(time_period[1]))\n",
    "\n",
    "                #Select data\n",
    "                data_20y = data_CMIP5.sel(time=years_sel)\n",
    "                data_ref = data_CMIP5.sel(time=slice('1981', '2010'))\n",
    "\n",
    "                #Calculate summer average\n",
    "                JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "                JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "\n",
    "                #Calculate yearly maximum\n",
    "                Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "                Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "\n",
    "                #Calculate 90th percentile (for each month in JJA separately)\n",
    "                create = 1\n",
    "                for month in np.arange(6, 9):\n",
    "\n",
    "                    sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                    sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                    sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                    sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                    sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                    sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "\n",
    "                    if create==1:\n",
    "                        Q90_20y = sel_dat_20y\n",
    "                        Q90_ref = sel_dat_ref\n",
    "\n",
    "                        create = 0\n",
    "                    else:\n",
    "                        Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                        Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "\n",
    "                #Calculate mean of 90th percentiles\n",
    "                Q90_20y = Q90_20y.mean('month')\n",
    "                Q90_ref = Q90_ref.mean('month')\n",
    "\n",
    "                #Calculate change\n",
    "                data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "                data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "                data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "\n",
    "                #Loop over HSIs\n",
    "                for HSI in HSI_names:\n",
    "\n",
    "                    #Save in array\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"time_period\": time_string, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"time_period\": time_string, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                    data_coll[HSI].loc[{\"model\": model_name, \"city\": city, \"time_period\": time_string, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "\n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + RCP + '_time-periods.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
