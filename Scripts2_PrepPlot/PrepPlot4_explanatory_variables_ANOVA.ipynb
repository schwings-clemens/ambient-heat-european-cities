{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main path\n",
    "with open('../path_main.txt', 'r') as file:   path_main  = file.read()\n",
    "    \n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_CORDEX  = f'{path_main}Data/EURO-CORDEX/HSIs/'\n",
    "dir_EMT     = f'{path_main}Data/EURO-CORDEX/EMT/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_out     = f'{path_main}Data/EURO-CORDEX/ANOVA_input/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-reflection",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Lisbon', 'Madrid', 'Barcelona', 'Rome', 'Athens', 'Istanbul', 'Sofia', 'Bucharest', 'Belgrade', 'Zagreb',\n",
    "          'Milan', 'Budapest', 'Munich', 'Vienna', 'Prague', 'Paris', 'Brussels', 'Amsterdam', 'London', 'Dublin',\n",
    "          'Hamburg', 'Copenhagen', 'Berlin', 'Warsaw', 'Kharkiv', 'Kyiv', 'Minsk', 'Vilnius', 'Riga', 'Moscow',\n",
    "          'NizhnyNovgorod', 'Kazan', 'SaintPetersburg', 'Helsinki', 'Stockholm', 'Oslo']\n",
    "\n",
    "#Define HSIs\n",
    "HSI_names = ['TN', 'TX']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp26'] = []\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP26.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp26'].append(eval(line[:-1]))\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "\n",
    "#Define time periods\n",
    "time_periods = [[1981, 2010], [2070, 2099]]\n",
    "time_strings = [str(time[0]) + '-' + str(time[1]) for time in time_periods]\n",
    "\n",
    "#Define changes in EMT relative to 1981-2010\n",
    "EMT_change     = np.array([1.0, 2.0, 3.0])\n",
    "EMT_change_str = ['1.0K', '2.0K', '3.0K', '1981-2010']\n",
    "\n",
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "\n",
    "N_gridcells = ''\n",
    "# N_gridcells = '_3x3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-novelty",
   "metadata": {},
   "source": [
    "## Prepare time period data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "scenarios = ['historical', RCP]\n",
    "\n",
    "indicators = ['mean', 'SD']\n",
    "\n",
    "#Combine model names to one string\n",
    "mod_names = [\"_\".join(model) for model in all_models[RCP]]\n",
    "\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty  = np.zeros((len(all_models[RCP]), len(cities), len(time_periods), len(indicators))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':       ('model', mod_names),\n",
    "                               'city':        ('city', cities),\n",
    "                               'time_period': ('time_period', time_strings),\n",
    "                               'indicator':      ('indicator', indicators)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'time_period', 'indicator'), da_empty.copy())\n",
    "    \n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "        #Get name of CMIP5 driving model\n",
    "        if ('CNRM-CERFAC' in model[0]) or ('CSIRO-QCCCE' in model[0]) or ('MPI-M' in model[0]) or ('NOAA-GFDL' in model[0]):\n",
    "            mod_CMIP5 = '-'.join(model[0].split('-')[2:])\n",
    "        else:\n",
    "            mod_CMIP5 = '-'.join(model[0].split('-')[1:])\n",
    "            \n",
    "        #Loop over scenarios\n",
    "        create = 1\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Define folder\n",
    "            dir_data = dir_CORDEX + city + '/' + scen + '/'\n",
    "\n",
    "            #Read data\n",
    "            fnames_CORDEX = [file for file in os.listdir(dir_data) if scen + '_' in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "            if N_gridcells=='':  fnames_CORDEX = [file for file in fnames_CORDEX if 'HSIs_' + city in file]\n",
    "            else:                fnames_CORDEX = [file for file in fnames_CORDEX if N_gridcells[1::] in file]\n",
    "            if len(fnames_CORDEX)!=1:  sys.exit('File is not unique')\n",
    "            data_read = xr.open_dataset(dir_data + fnames_CORDEX[0])\n",
    "\n",
    "            #Concatenate data\n",
    "            if create==1:\n",
    "                data_CORDEX = data_read\n",
    "                create = 0\n",
    "            else:\n",
    "                data_CORDEX = xr.concat((data_CORDEX, data_read), dim='time')\n",
    "        \n",
    "        #Loop over time periods\n",
    "        for time_period, time_string in zip(time_periods, time_strings):\n",
    "\n",
    "            #Select data in selected time period\n",
    "            time_sel = slice(str(time_period[0]), str(time_period[1]))\n",
    "               \n",
    "            #Select data\n",
    "            data_30y = data_CORDEX.sel(time=time_sel)\n",
    "            JJA_30y  = data_30y.isel(time=(data_30y.time.dt.month>=6) & (data_30y.time.dt.month<=8))\n",
    "\n",
    "            #Calculate mean and interannual SD\n",
    "            HSI_mean = JJA_30y.mean('time').mean()\n",
    "            HSI_std  = JJA_30y.std('time').mean()\n",
    "            \n",
    "            #Loop over HSIs\n",
    "            for HSI in HSI_names:\n",
    "                \n",
    "                #Save in array\n",
    "                data_coll[HSI].loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"indicator\": \"mean\"}] = HSI_mean[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"indicator\": \"SD\"}]   = HSI_std[HSI]\n",
    "                \n",
    "#Save data in file\n",
    "fname_out1 = dir_out + 'ANOVA' + N_gridcells + '_' + 'HSIs-mean_' + RCP + '_time-periods.nc'\n",
    "fname_out2 = dir_out + 'ANOVA' + N_gridcells + '_' + 'HSIs-SD_' + RCP + '_time-periods.nc'\n",
    "if os.path.exists(fname_out1): os.remove(fname_out1)\n",
    "if os.path.exists(fname_out2): os.remove(fname_out2)\n",
    "data_coll.sel(indicator='mean').to_netcdf(fname_out1)\n",
    "data_coll.sel(indicator='SD').to_netcdf(fname_out2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-sword",
   "metadata": {},
   "source": [
    "## Prepare EMT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-experience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "scenarios = ['historical', RCP]\n",
    "\n",
    "indicators = ['mean', 'SD']#, 'SD_max']\n",
    "\n",
    "#Combine model names to one string\n",
    "mod_names = [\"_\".join(model) for model in all_models[RCP]]\n",
    "\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty  = np.zeros((len(all_models[RCP]), len(cities), len(EMT_change_str), len(indicators))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':      ('model', mod_names),\n",
    "                               'city':       ('city', cities),\n",
    "                               'EMT_change': ('EMT_change', EMT_change_str),\n",
    "                               'indicator':  ('indicator', indicators)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'EMT_change', 'indicator'), da_empty.copy())\n",
    "    \n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "        #Get name of CMIP5 driving model\n",
    "        if ('CNRM-CERFAC' in model[0]) or ('CSIRO-QCCCE' in model[0]) or ('MPI-M' in model[0]) or ('NOAA-GFDL' in model[0]):\n",
    "            mod_CMIP5 = '-'.join(model[0].split('-')[2:])\n",
    "        else:\n",
    "            mod_CMIP5 = '-'.join(model[0].split('-')[1:])\n",
    "            \n",
    "        #Loop over scenarios\n",
    "        create = 1\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Define folder\n",
    "            dir_data = dir_CORDEX + city + '/' + scen + '/'\n",
    "\n",
    "            #Read data\n",
    "            fnames_CORDEX = [file for file in os.listdir(dir_data) if scen + '_' in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "            if N_gridcells=='':  fnames_CORDEX = [file for file in fnames_CORDEX if 'HSIs_' + city in file]\n",
    "            else:                fnames_CORDEX = [file for file in fnames_CORDEX if N_gridcells[1::] in file]\n",
    "            if len(fnames_CORDEX)!=1:  sys.exit('File is not unique')\n",
    "            data_read = xr.open_dataset(dir_data + fnames_CORDEX[0])\n",
    "\n",
    "            #Concatenate data\n",
    "            if create==1:\n",
    "                data_CORDEX = data_read\n",
    "                create = 0\n",
    "            else:\n",
    "                data_CORDEX = xr.concat((data_CORDEX, data_read), dim='time')\n",
    "        \n",
    "        #Read European mean temperature (EMT)\n",
    "        files_EMT = sorted([dir_EMT + file for file in os.listdir(dir_EMT) if \"_\".join(model) in file and 'EMT_' in file])\n",
    "        data_EMT  = xr.concat((xr.open_dataset(file) for file in files_EMT), dim='time')\n",
    "\n",
    "        #Calculate EMT relative to 1981-2010 and calculate 20-year means\n",
    "        dataEMT_ref = data_EMT.sel(time=slice('1981', '2010')).mean('time')\n",
    "        dataEMT_rel = data_EMT - dataEMT_ref\n",
    "        dataEMT_20y = dataEMT_rel.rolling(time=20, center=True).mean()\n",
    "\n",
    "        #Loop over selected EMT levels\n",
    "        for dEMT, dEMT_str in zip(EMT_change, EMT_change_str):\n",
    "\n",
    "            #Identify 20-year period in wich level is reached for first time\n",
    "            ind  = np.where(dataEMT_20y.tas>dEMT)[0][0]\n",
    "            central_year = dataEMT_20y.isel(time=ind).time.dt.year\n",
    "            start_year   = int(central_year - 20 / 2)\n",
    "            end_year     = int(central_year + (20 / 2 - 1))\n",
    "            years_sel    = slice(str(start_year), str(end_year))\n",
    "\n",
    "            if end_year>2099:\n",
    "                print(model)\n",
    "                print(end_year)\n",
    "\n",
    "            #Select data and get only summer\n",
    "            data_20y = data_CORDEX.sel(time=years_sel)\n",
    "            JJA_20y  = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "\n",
    "            #Calculate mean and interannual SD\n",
    "            HSI_mean = JJA_20y.mean('time').mean()\n",
    "            HSI_std  = JJA_20y.std('time').mean()\n",
    "            \n",
    "            #Loop over HSIs\n",
    "            for HSI in HSI_names:\n",
    "                \n",
    "                #Save in array\n",
    "                data_coll[HSI].loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"indicator\": \"mean\"}] = HSI_mean[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"indicator\": \"SD\"}]   = HSI_std[HSI]\n",
    "\n",
    "#Save data in file\n",
    "fname_out1 = dir_out + 'ANOVA' + N_gridcells + '_' + 'HSIs-mean_' + RCP + '_EMT.nc'\n",
    "fname_out2 = dir_out + 'ANOVA' + N_gridcells + '_' + 'HSIs-SD_' + RCP + '_EMT.nc'\n",
    "if os.path.exists(fname_out1): os.remove(fname_out1)\n",
    "if os.path.exists(fname_out2): os.remove(fname_out2)\n",
    "data_coll.sel(indicator='mean').to_netcdf(fname_out1)\n",
    "data_coll.sel(indicator='SD').to_netcdf(fname_out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e9722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
