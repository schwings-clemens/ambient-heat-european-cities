{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_gwls.txt', 'r') as file:    path_gwls  = file.read()\n",
    "    \n",
    "dir_CMIP6    = f'{path_main}Data/CMIP6/HSIs/'\n",
    "dir_GWL      = f'{path_gwls}cmip6_all_ens/'\n",
    "dir_EMT      = f'{path_main}Data/CMIP6/EMT/'\n",
    "dir_names    = f'{path_main}Scripts/Model_lists/'\n",
    "dir_out      = f'{path_main}Data/Plot_preparation/HSI_changes/CMIP6/'\n",
    "if not os.path.exists(dir_out): os.mkdir(dir_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Lisbon', 'Madrid', 'Barcelona', 'Rome', 'Athens', 'Istanbul', 'Sofia', 'Bucharest', 'Belgrade', 'Zagreb',\n",
    "          'Milan', 'Budapest', 'Munich', 'Vienna', 'Prague', 'Paris', 'Brussels', 'Amsterdam', 'London', 'Dublin',\n",
    "          'Hamburg', 'Copenhagen', 'Berlin', 'Warsaw', 'Kharkiv', 'Kyiv', 'Minsk', 'Vilnius', 'Riga', 'Moscow',\n",
    "          'NizhnyNovgorod', 'Kazan', 'SaintPetersburg', 'Helsinki', 'Stockholm', 'Oslo']\n",
    "\n",
    "#Define HSIs\n",
    "HSI_names = ['TX']\n",
    "\n",
    "#Define models and SSPs which should be used\n",
    "all_models = dict()\n",
    "all_models['ssp585'] = []\n",
    "with open(dir_names + 'Models_CMIP6_SSP585.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['ssp585'].append(line[:-1])\n",
    "\n",
    "#Read warming levels\n",
    "fname = dir_GWL + 'cmip6_warming_levels_all_ens_1850_1900.yml'\n",
    "with open(fname, 'r') as file:\n",
    "    GWL_data = yaml.safe_load(file)\n",
    "\n",
    "#Define warming levels\n",
    "GWL_levels = ['10', '20', '30', '40']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GWL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define SSP\n",
    "SSP = 'ssp585'\n",
    "scenarios = ['historical', SSP]\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(all_models[SSP]), len(cities), len(GWL_levels), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':      ('model', all_models['ssp585']),\n",
    "                               'city':       ('city', cities),\n",
    "                               'GWL_level':  ('GWL_level', GWL_levels),\n",
    "                               't_method':   ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'GWL_level', 't_method'), da_empty.copy())\n",
    "\n",
    "missing_data = dict([ (GWL,set()) for GWL in GWL_levels])\n",
    "    \n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[SSP]):\n",
    "\n",
    "        #Select ensemble member\n",
    "        if model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'CNRM-CM6-1-HR', 'UKESM1-0-LL', 'MIROC-ES2L']:\n",
    "            member = \"r1i1p1f2\"\n",
    "        elif model in ['HadGEM3-GC31-LL', 'HadGEM3-GC31-MM']:\n",
    "            member = \"r1i1p1f3\"\n",
    "        else:\n",
    "            member = \"r1i1p1f1\"\n",
    "        \n",
    "        #Loop over scenarios\n",
    "        create = 1\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Define folder\n",
    "            dir_data = dir_CMIP6 + city + '/' + scen + '/'\n",
    "\n",
    "            #Read data\n",
    "            fnames_CMIP6 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file]\n",
    "            fnames_CMIP6 = [file for file in fnames_CMIP6 if 'HSIs_' + city in file]\n",
    "            if len(fnames_CMIP6)!=1:  sys.exit('File is not unique')\n",
    "            data_read = xr.open_dataset(dir_data + fnames_CMIP6[0])\n",
    "\n",
    "            #Concatenate data\n",
    "            if create==1:\n",
    "                data_CMIP6 = data_read\n",
    "                create = 0\n",
    "            else:\n",
    "                data_CMIP6 = xr.concat((data_CMIP6, data_read), dim='time')            \n",
    "        \n",
    "        #Read time periods when certain global warming levels (GWL) are reached\n",
    "        time_GWL = dict()\n",
    "        for GWL_level in GWL_levels:\n",
    "            data_level = GWL_data['warming_level_' + GWL_level]\n",
    "            entry_sel = [entry for entry in data_level if entry['model']==model and entry['exp']==SSP and entry['ensemble']==member]\n",
    "\n",
    "            if entry_sel==[]:\n",
    "                missing_data[GWL_level] = missing_data[GWL_level].union([model])\n",
    "                continue\n",
    "            \n",
    "            #Select data in time period when GWL is reached\n",
    "            start_year = entry_sel[0]['start_year']\n",
    "            end_year   = entry_sel[0]['end_year']\n",
    "            time_GWL = slice(str(entry_sel[0]['start_year']), str(entry_sel[0]['end_year']))\n",
    "            \n",
    "            #Select data\n",
    "            data_20y = data_CMIP6.sel(time=time_GWL)\n",
    "            data_ref = data_CMIP6.sel(time=slice('1981', '2010'))\n",
    "            \n",
    "            #Calculate summer average\n",
    "            JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "            JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "            \n",
    "            #Calculate yearly maximum\n",
    "            Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "            Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "            \n",
    "            #Calculate 90th percentile (for each month in JJA separately)\n",
    "            create = 1\n",
    "            for month in np.arange(6, 9):\n",
    "\n",
    "                sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "                \n",
    "                if create==1:\n",
    "                    Q90_20y = sel_dat_20y\n",
    "                    Q90_ref = sel_dat_ref\n",
    "                    \n",
    "                    create = 0\n",
    "                else:\n",
    "                    Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                    Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "                    \n",
    "            #Calculate mean of 90th percentiles\n",
    "            Q90_20y = Q90_20y.mean('month')\n",
    "            Q90_ref = Q90_ref.mean('month')\n",
    "            \n",
    "            #Calculate change\n",
    "            data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "            data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "            data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "            \n",
    "            #Loop over HSIs\n",
    "            for HSI in HSI_names:\n",
    "                \n",
    "                #Save in array\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"GWL_level\": GWL_level, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "\n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + SSP + '_GWL.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)    \n",
    "\n",
    "print('\\nMissing data:')\n",
    "[print(str(key) + ': ' + str(data)) for key, data in missing_data.items()];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data according to European warming (EMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define SSP\n",
    "SSP = 'ssp585'\n",
    "scenarios = ['historical', SSP]\n",
    "\n",
    "EMT_change     = np.array([1.0, 2.0, 3.0])\n",
    "EMT_change_str = ['1.0K', '2.0K', '3.0K']\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(all_models[SSP]), len(cities), len(EMT_change), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':          ('model', all_models['ssp585']),\n",
    "                               'city':           ('city', cities),\n",
    "                               'EMT_change':     ('EMT_change', EMT_change_str),\n",
    "                               't_method':       ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'EMT_change', 't_method'), da_empty.copy())\n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[SSP]):\n",
    "\n",
    "        #Loop over scenarios\n",
    "        create = 1\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Define folder\n",
    "            dir_data = dir_CMIP6 + city + '/' + scen + '/'\n",
    "\n",
    "            #Read data\n",
    "            fnames_CMIP6 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file]\n",
    "            fnames_CMIP6 = [file for file in fnames_CMIP6 if 'HSIs_' + city in file]\n",
    "            if len(fnames_CMIP6)!=1:  sys.exit('File is not unique')\n",
    "            data_read = xr.open_dataset(dir_data + fnames_CMIP6[0])\n",
    "\n",
    "            #Concatenate data\n",
    "            if create==1:\n",
    "                data_CMIP6 = data_read\n",
    "                create = 0\n",
    "            else:\n",
    "                data_CMIP6 = xr.concat((data_CMIP6, data_read), dim='time')\n",
    "        \n",
    "        #Read European mean temperature (EMT)\n",
    "        files_EMT = sorted([dir_EMT + file for file in os.listdir(dir_EMT) if model + '_' in file and 'EMT_' in file])\n",
    "        data_EMT  = xr.concat((xr.open_dataset(file) for file in files_EMT), dim='time')\n",
    "\n",
    "        #Calculate EMT relative to 1981-2010 and calculate 20-year means\n",
    "        dataEMT_ref = data_EMT.sel(time=slice('1981', '2010')).mean('time')\n",
    "        dataEMT_rel = data_EMT - dataEMT_ref\n",
    "        dataEMT_20y = dataEMT_rel.rolling(time=20, center=True).mean()\n",
    "\n",
    "        #Loop over selected EMT levels\n",
    "        for dEMT, dEMT_str in zip(EMT_change, EMT_change_str):\n",
    "\n",
    "            #Identify 20-year period in wich level is reached for first time\n",
    "            ind  = np.where(dataEMT_20y.tas>dEMT)[0][0]\n",
    "            central_year = dataEMT_20y.isel(time=ind).time.dt.year\n",
    "            start_year   = int(central_year - 20 / 2)\n",
    "            end_year     = int(central_year + (20 / 2 - 1))\n",
    "            years_sel    = slice(str(start_year), str(end_year))\n",
    "\n",
    "            if end_year>2099:\n",
    "                print(model)\n",
    "                print(end_year)\n",
    "\n",
    "            #Select data\n",
    "            data_20y = data_CMIP6.sel(time=years_sel)\n",
    "            data_ref = data_CMIP6.sel(time=slice('1981', '2010'))\n",
    "            \n",
    "            #Calculate summer average\n",
    "            JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "            JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "            \n",
    "            #Calculate yearly maximum\n",
    "            Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "            Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "            \n",
    "            #Calculate 90th percentile (for each month in JJA separately)\n",
    "            create = 1\n",
    "            for month in np.arange(6, 9):\n",
    "\n",
    "                sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "                \n",
    "                if create==1:\n",
    "                    Q90_20y = sel_dat_20y\n",
    "                    Q90_ref = sel_dat_ref\n",
    "                    \n",
    "                    create = 0\n",
    "                else:\n",
    "                    Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                    Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "                    \n",
    "            #Calculate mean of 90th percentiles\n",
    "            Q90_20y = Q90_20y.mean('month')\n",
    "            Q90_ref = Q90_ref.mean('month')\n",
    "            \n",
    "            #Calculate change\n",
    "            data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "            data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "            data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "            \n",
    "            #Loop over HSIs\n",
    "            for HSI in HSI_names:\n",
    "                \n",
    "                #Save in array\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"EMT_change\": dEMT_str, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "                \n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + SSP + '_EMT.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare time period data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select time periods\n",
    "time_periods = [[2036, 2065],\n",
    "                [2070, 2099]]\n",
    "\n",
    "#Define time string\n",
    "time_strings = [str(time[0]) + '-' + str(time[1]) for time in time_periods]\n",
    "\n",
    "#Define SSP\n",
    "SSP = 'ssp585'\n",
    "scenarios = ['historical', SSP]\n",
    "\n",
    "time_selections = ['JJA_mean', 'Q90', 'Ymax']\n",
    "\n",
    "#Create empty array for storing heat stress indicators\n",
    "da_empty = np.zeros((len(all_models[SSP]), len(cities), len(time_periods), len(time_selections))) * np.NaN\n",
    "data_coll = xr.Dataset(coords={'model':       ('model', all_models['ssp585']),\n",
    "                               'city':        ('city', cities),\n",
    "                               'time_period': ('time_period', time_strings),\n",
    "                               't_method':    ('t_method', time_selections)})\n",
    "\n",
    "for HSI in HSI_names:  data_coll[HSI] = (('model', 'city', 'time_period', 't_method'), da_empty.copy())\n",
    "\n",
    "#Loop over cities\n",
    "for city in cities:\n",
    "    \n",
    "    print(city, end=', ')\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models[SSP]):\n",
    "\n",
    "        #Loop over scenarios\n",
    "        create = 1\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Define folder\n",
    "            dir_data = dir_CMIP6 + city + '/' + scen + '/'\n",
    "\n",
    "            #Read data\n",
    "            fnames_CMIP6 = [file for file in os.listdir(dir_data) if scen + '_' in file and model + '_' in file]\n",
    "            fnames_CMIP6 = [file for file in fnames_CMIP6 if 'HSIs_' + city in file]\n",
    "            if len(fnames_CMIP6)!=1:  sys.exit('File is not unique')\n",
    "            data_read = xr.open_dataset(dir_data + fnames_CMIP6[0])\n",
    "\n",
    "            #Concatenate data\n",
    "            if create==1:\n",
    "                data_CMIP6 = data_read\n",
    "                create = 0\n",
    "            else:\n",
    "                data_CMIP6 = xr.concat((data_CMIP6, data_read), dim='time')            \n",
    "        \n",
    "        #Loop over time periods\n",
    "        for time_period, time_string in zip(time_periods, time_strings):\n",
    "\n",
    "            #Select data in selected time period\n",
    "            time_sel = slice(str(time_period[0]), str(time_period[1]))\n",
    "               \n",
    "            #Select data\n",
    "            data_20y = data_CMIP6.sel(time=years_sel)\n",
    "            data_ref = data_CMIP6.sel(time=slice('1981', '2010'))\n",
    "            \n",
    "            #Calculate summer average\n",
    "            JJA_20y = data_20y.isel(time=(data_20y.time.dt.month>=6) & (data_20y.time.dt.month<=8))\n",
    "            JJA_ref = data_ref.isel(time=(data_ref.time.dt.month>=6) & (data_ref.time.dt.month<=8))\n",
    "            \n",
    "            #Calculate yearly maximum\n",
    "            Ymax_20y = data_20y.resample(time='1Y').max()\n",
    "            Ymax_ref = data_ref.resample(time='1Y').max()\n",
    "            \n",
    "            #Calculate 90th percentile (for each month in JJA separately)\n",
    "            create = 1\n",
    "            for month in np.arange(6, 9):\n",
    "\n",
    "                sel_mon_20y = JJA_20y.time.dt.month==month\n",
    "                sel_mon_ref = JJA_ref.time.dt.month==month\n",
    "                sel_dat_20y = JJA_20y.isel(time=sel_mon_20y)\n",
    "                sel_dat_ref = JJA_ref.isel(time=sel_mon_ref)\n",
    "                sel_dat_20y = sel_dat_20y.quantile(0.9)\n",
    "                sel_dat_ref = sel_dat_ref.quantile(0.9)\n",
    "                \n",
    "                if create==1:\n",
    "                    Q90_20y = sel_dat_20y\n",
    "                    Q90_ref = sel_dat_ref\n",
    "                    \n",
    "                    create = 0\n",
    "                else:\n",
    "                    Q90_20y = xr.concat((Q90_20y, sel_dat_20y), dim='month')\n",
    "                    Q90_ref = xr.concat((Q90_ref, sel_dat_ref), dim='month')\n",
    "                    \n",
    "            #Calculate mean of 90th percentiles\n",
    "            Q90_20y = Q90_20y.mean('month')\n",
    "            Q90_ref = Q90_ref.mean('month')\n",
    "            \n",
    "            #Calculate change\n",
    "            data_chg_JJA  = JJA_20y.mean() - JJA_ref.mean()\n",
    "            data_chg_Q90  = Q90_20y.mean() - Q90_ref.mean()\n",
    "            data_chg_Ymax = Ymax_20y.mean() - Ymax_ref.mean()\n",
    "\n",
    "            #Loop over HSIs\n",
    "            for HSI in HSI_names:\n",
    "                \n",
    "                #Save in array\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"time_period\": time_string, \"t_method\": \"JJA_mean\"}] = data_chg_JJA[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"time_period\": time_string, \"t_method\": \"Q90\"}]      = data_chg_Q90[HSI]\n",
    "                data_coll[HSI].loc[{\"model\": model, \"city\": city, \"time_period\": time_string, \"t_method\": \"Ymax\"}]     = data_chg_Ymax[HSI]\n",
    "\n",
    "#Save data in file\n",
    "fname_out = dir_out + 'HSIs-changes_' + SSP + '_time-periods.nc'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "data_coll.to_netcdf(fname_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
