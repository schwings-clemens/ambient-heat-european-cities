{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import mplotutils as mpu\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_grids.txt', 'r') as file:   path_grids = file.read()\n",
    "    \n",
    "dir_data_Ymax = f'{path_main}Data/EURO-CORDEX/Yearmax/'\n",
    "dir_data_EMT  = f'{path_main}Data/EURO-CORDEX/EMT/'\n",
    "dir_scripts   = f'{path_main}Scripts/'\n",
    "dir_names     = f'{path_main}Scripts/Model_lists/'\n",
    "dir_regrid    = f'{path_grids}Regridding/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define models and RCPs which should be used\n",
    "all_models = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models.append(eval(line[:-1]))\n",
    "\n",
    "#Define scenario\n",
    "RCP = 'rcp85'        \n",
    "        \n",
    "#Read standard grid\n",
    "fname_grid_stand = dir_regrid + 'Standard_grid_CORDEX-EUR-11_NCC-NorESM1-M_SMHI-RCA4.nc'\n",
    "grid_standard = xr.open_dataset(fname_grid_stand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate change of TXx (fut - hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variables = ['tasmin', 'tasmax']\n",
    "vars_out = dict()\n",
    "vars_out['tasmax'] = 'TXx'\n",
    "vars_out['tasmin'] = 'TNx'\n",
    "\n",
    "data_all = dict()\n",
    "\n",
    "for variab in variables:\n",
    "\n",
    "    dir_data = dir_data_Ymax + variab + '/'\n",
    "\n",
    "    print(len(all_models), end=': ')\n",
    "\n",
    "    #Loop over all models\n",
    "    create = 1\n",
    "    for i, model in enumerate(all_models):\n",
    "\n",
    "        print(i, end=', ')\n",
    "\n",
    "        #Get file names\n",
    "        f_hist = [file for file in os.listdir(dir_data) if \"_\".join(model) in file and '1981-2010' in file]\n",
    "        f_rcp  = [file for file in os.listdir(dir_data) if \"_\".join(model) in file and '2070-2099' in file]\n",
    "        if len(f_hist)!=1:  sys.exit('File is not unique')\n",
    "        if len(f_rcp)!=1:   sys.exit('File is not unique')\n",
    "\n",
    "        #Read data and calculate difference and rename\n",
    "        data_hist = xr.open_dataset(dir_data + f_hist[0])\n",
    "        data_rcp  = xr.open_dataset(dir_data + f_rcp[0])\n",
    "        data_diff = data_rcp.mean('time') - data_hist.mean('time')\n",
    "        data_diff = data_diff.rename({variab: vars_out[variab]})\n",
    "        \n",
    "        #Save in NetCDF\n",
    "        fname_tmp = dir_data_Ymax + \"_\".join(model) + '_' + variab + \"_tmp.nc\"\n",
    "        data_diff.to_netcdf(fname_tmp)\n",
    "\n",
    "        #Regrid to standard grid\n",
    "        fname_grid = dir_regrid + 'grid_xy_CORDEX-EUR-11_NCC-NorESM1-M_SMHI-RCA4'\n",
    "        fname_regrid = dir_data_Ymax + \"_\".join(model) + variab + \"_regridded.nc\"\n",
    "        os.system(\"cdo remapbil,\" + fname_grid + \" \" + fname_tmp + \" \" + fname_regrid)\n",
    "\n",
    "        #Read regridded dataset\n",
    "        data_regr = xr.open_dataset(fname_regrid)\n",
    "        data_regr = data_regr.reindex({'rlat': grid_standard['rlat'], 'rlon': grid_standard['rlon']}, method='nearest')\n",
    "\n",
    "        #Remove unnecessary variables\n",
    "        vars_remove = set(data_regr.data_vars).difference([vars_out[variab]])\n",
    "        data_regr = data_regr.drop(vars_remove)\n",
    "        if 'height' in data_regr: data_regr = data_regr.drop('height')\n",
    "\n",
    "        #Collect in one array\n",
    "        if create==1:\n",
    "            data_coll = data_regr\n",
    "            create = 0\n",
    "        else:\n",
    "            data_coll = xr.concat((data_coll, data_regr), dim='model')\n",
    "\n",
    "        #Remove temporary files\n",
    "        os.remove(fname_tmp)\n",
    "        os.remove(fname_regrid)\n",
    "\n",
    "    #Add model names\n",
    "    data_coll['model'] = [\"_\".join(model) for model in all_models]\n",
    "    \n",
    "    #Save in file\n",
    "    fname_out = dir_data_Ymax + vars_out[variab] + '_all_models_yearmax.nc'\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    data_coll.to_netcdf(fname_out)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate IQR of TXx in reference period (1981-2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['tasmax']\n",
    "vars_out = dict()\n",
    "vars_out['tasmax'] = 'TXx'\n",
    "vars_out['tasmin'] = 'TNx'\n",
    "\n",
    "data_all = dict()\n",
    "\n",
    "for variab in variables:\n",
    "\n",
    "    dir_data = dir_data_Ymax + variab + '/'\n",
    "\n",
    "    print(len(all_models), end=': ')\n",
    "\n",
    "    #Loop over all models\n",
    "    create = 1\n",
    "    for i, model in enumerate(all_models):\n",
    "\n",
    "        print(i, end=', ')\n",
    "\n",
    "        #Get file names\n",
    "        f_hist = [file for file in os.listdir(dir_data) if \"_\".join(model) in file and '1981-2010' in file]\n",
    "        if len(f_hist)!=1:  sys.exit('File is not unique')\n",
    "\n",
    "        #Read data and calculate IQR\n",
    "        data_read = xr.open_dataset(dir_data + f_hist[0])\n",
    "        data_Q75  = data_read.quantile(0.75, dim='time')\n",
    "        data_Q25  = data_read.quantile(0.25, dim='time')\n",
    "        data_IQR  = data_Q75 - data_Q25\n",
    "        \n",
    "        #Rename variable\n",
    "        data_IQR  = data_IQR.rename({variab: vars_out[variab]})\n",
    "        \n",
    "        #Save in NetCDF\n",
    "        fname_tmp = dir_data_Ymax + \"_\".join(model) + '_' + variab + \"_tmp_IQR_TXx.nc\"\n",
    "        if os.path.exists(fname_tmp): os.remove(fname_tmp)\n",
    "        data_IQR.to_netcdf(fname_tmp)\n",
    "\n",
    "        #Regrid to standard grid\n",
    "        fname_grid = dir_regrid + 'grid_xy_CORDEX-EUR-11_NCC-NorESM1-M_SMHI-RCA4'\n",
    "        fname_regrid = dir_data_Ymax + \"_\".join(model) + variab + \"_regridded_tmp_IQR_TXx.nc\"\n",
    "        if os.path.exists(fname_regrid): os.remove(fname_regrid)\n",
    "        os.system(\"cdo remapbil,\" + fname_grid + \" \" + fname_tmp + \" \" + fname_regrid)\n",
    "\n",
    "        #Read regridded dataset\n",
    "        data_regr = xr.open_dataset(fname_regrid)\n",
    "        data_regr = data_regr.reindex({'rlat': grid_standard['rlat'], 'rlon': grid_standard['rlon']}, method='nearest')\n",
    "\n",
    "        #Remove unnecessary variables\n",
    "        vars_remove = set(data_regr.data_vars).difference([vars_out[variab]])\n",
    "        data_regr = data_regr.drop(vars_remove)\n",
    "        if 'height' in data_regr: data_regr = data_regr.drop('height')\n",
    "\n",
    "        #Collect in one array\n",
    "        if create==1:\n",
    "            data_coll = data_regr\n",
    "            create = 0\n",
    "        else:\n",
    "            data_coll = xr.concat((data_coll, data_regr), dim='model')\n",
    "\n",
    "        #Remove temporary files\n",
    "        os.remove(fname_tmp)\n",
    "        os.remove(fname_regrid)\n",
    "        \n",
    "    #Save in file\n",
    "    fname_save = dir_data_Ymax + vars_out[variab] + '-IQR_all_models.nc'\n",
    "    if os.path.exists(fname_save): os.remove(fname_save)\n",
    "    data_coll.to_netcdf(fname_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
