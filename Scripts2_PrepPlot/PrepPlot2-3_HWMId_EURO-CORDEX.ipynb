{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:     path_main  = file.read()\n",
    "with open('../path_gwls.txt', 'r') as file:     path_gwls  = file.read()\n",
    "with open('../path_EUR-11.txt', 'r') as file:   path_eur11 = file.read()\n",
    "    \n",
    "dir_CORDEX  = f'{path_main}Data/EURO-CORDEX/'\n",
    "dir_GWL     = f'{path_gwls}cmip5_all_ens/'\n",
    "dir_EMT     = f'{path_main}Data/EURO-CORDEX/EMT/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_scripts = f'{path_main}/Scripts/'\n",
    "dir_sftlf   = f'{path_eur11}/historical/sftlf/'\n",
    "dir_out     = f'{path_main}Data/Plot_preparation/HWMId/'\n",
    "if not os.path.exists(dir_out): os.mkdir(dir_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Lisbon', 'Madrid', 'Barcelona', 'Rome', 'Athens', 'Istanbul', 'Sofia', 'Bucharest', 'Belgrade', 'Zagreb',\n",
    "          'Milan', 'Budapest', 'Munich', 'Vienna', 'Prague', 'Paris', 'Brussels', 'Amsterdam', 'London', 'Dublin',\n",
    "          'Hamburg', 'Copenhagen', 'Berlin', 'Warsaw', 'Kharkiv', 'Kyiv', 'Minsk', 'Vilnius', 'Riga', 'Moscow',\n",
    "          'NizhnyNovgorod', 'Kazan', 'SaintPetersburg', 'Helsinki', 'Stockholm', 'Oslo']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Define HSIs\n",
    "HSI_names = ['TX', 'TN']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp26'] = []\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP26.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp26'].append(eval(line[:-1]))\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "\n",
    "#Read warming levels\n",
    "fname = dir_GWL + 'cmip5_warming_levels_all_ens_1850_1900_no_bounds_check.yml'\n",
    "with open(fname, 'r') as file:\n",
    "    GWL_data = yaml.safe_load(file)\n",
    "\n",
    "#Define warming levels\n",
    "GWL_levels = ['10', '20', '30']\n",
    "\n",
    "#Define out_name\n",
    "out_name = '_3x3'\n",
    "# out_name = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read land-sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "#Initialize dictionary\n",
    "data_LSM = dict()\n",
    "\n",
    "#Loop over all models\n",
    "for model in all_models['rcp85']:\n",
    "    \n",
    "    #Get file names\n",
    "    fnames = [file for file in os.listdir(dir_sftlf) if model[0] in file and model[1] in file]\n",
    "    \n",
    "    #Define file names for certain models, for which no LSM exists\n",
    "    if model[1]=='IPSL-WRF381P':\n",
    "        fnames = ['sftlf_EUR-11_CNRM-CERFACS-CNRM-CM5_historical_r0i0p0_IPSL-WRF381P_v2-ADAPTED-FROM-OLDER-VERSION_fx.nc']\n",
    "    if model[0]=='ICHEC-EC-EARTH' and model[1]=='CLMcom-ETH-COSMO-crCLIM-v1-1':\n",
    "        fnames = ['sftlf_EUR-11_MPI-M-MPI-ESM-LR_historical_r0i0p0_CLMcom-ETH-COSMO-crCLIM-v1-1_v1_fx.nc']\n",
    "    if model[0]=='IPSL-IPSL-CM5A-MR' and model[1]=='DMI-HIRHAM5':\n",
    "        fnames = ['sftlf_EUR-11_MPI-M-MPI-ESM-LR_historical_r1i1p1_DMI-HIRHAM5_v1_fx.nc']    \n",
    "    \n",
    "    #Get file name\n",
    "    if len(fnames)>=1:\n",
    "        fname = fnames[0]\n",
    "    else:\n",
    "        sys.exit('File name not defined')\n",
    "    \n",
    "    #Read data\n",
    "    data_sftlf = xr.open_dataset(dir_sftlf + fname)\n",
    " \n",
    "    #Convert LSM data to %\n",
    "    if data_sftlf.sftlf.max()<50:\n",
    "        data_sftlf['sftlf'] = 100 * data_sftlf['sftlf']\n",
    "\n",
    "    #Convert longitude from [0, 360] to [-180, 180]\n",
    "    if 'longitude' in data_sftlf.coords:  lat_name, lon_name = 'latitude', 'longitude'\n",
    "    elif 'lon' in data_sftlf.coords:      lat_name, lon_name = 'lat', 'lon'\n",
    "    if data_sftlf[lon_name].max()>180:\n",
    "        data_sftlf[lon_name] = data_sftlf[lon_name].where(data_sftlf[lon_name]<180, ((data_sftlf[lon_name] + 180) % 360) - 180)\n",
    "    \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "        \n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]\n",
    "\n",
    "        #Find grid point closest to city\n",
    "        loc_city = (np.abs(data_sftlf[lon_name] - lon_sel)) + (np.abs(data_sftlf[lat_name] - lat_sel))\n",
    "        ind_city = np.unravel_index(np.argmin(loc_city.values), loc_city.shape)\n",
    "\n",
    "        #Select NxN box around grid point\n",
    "        N1 = int(N/2 - 0.5)\n",
    "        N2 = int(N/2 + 0.5)\n",
    "        lat_rng  = slice(ind_city[0] - N1, ind_city[0] + N2)\n",
    "        lon_rng  = slice(ind_city[1] - N1, ind_city[1] + N2)\n",
    "        if 'rlat' in data_sftlf.dims:   data_sftlf_city = data_sftlf.isel(rlat=lat_rng, rlon=lon_rng)\n",
    "        elif 'x' in data_sftlf.dims:    data_sftlf_city = data_sftlf.isel(y=lat_rng, x=lon_rng)\n",
    "        \n",
    "        #Save in dictionary\n",
    "        data_LSM[model[0] + '_' + model[1] + '_' + city] = data_sftlf_city.sftlf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare EMT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define folders\n",
    "dir_HWMId = dir_CORDEX + 'HWMId' + out_name + '/'\n",
    "dir_save  = dir_out + 'EURO-CORDEX' + out_name + '/'\n",
    "\n",
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "\n",
    "#Define quantiles\n",
    "quantiles = ['Q50', 'Q90']\n",
    "\n",
    "#Define changes in EMT relative to 1981-2010\n",
    "EMT_change     = np.array([1.0, 2.0, 3.0])\n",
    "EMT_change_str = ['1.0K', '2.0K', '3.0K']\n",
    "\n",
    "#Define minimum fraction of land required on each grid point\n",
    "land_fractions = [0, 25, 50, 75, 100]\n",
    "\n",
    "#Loop over cities\n",
    "for HSI in HSI_names:\n",
    "    \n",
    "    print(HSI)\n",
    "\n",
    "    #Combine model names to one string\n",
    "    mod_names = [\"_\".join(model) for model in all_models[RCP]]\n",
    "\n",
    "    #Create empty numpy array and define coordinates\n",
    "    if out_name=='_3x3':\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(EMT_change), len(quantiles), len(land_fractions), 2)) * np.NaN\n",
    "        coords={'model':        ('model', mod_names),\n",
    "                'city':         ('city', cities),\n",
    "                'EMT_change':   ('EMT_change', EMT_change_str),\n",
    "                'quantile':     ('quantile', quantiles),\n",
    "                'land_frac':    ('land_frac', land_fractions),\n",
    "                'range_3x3box': ('range_3x3box', ['min', 'max'])}\n",
    "    else:\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(EMT_change), len(quantiles))) * np.NaN\n",
    "        coords={'model':      ('model', mod_names),\n",
    "                'city':       ('city', cities),\n",
    "                'EMT_change': ('EMT_change', EMT_change_str),\n",
    "                'quantile':   ('quantile', quantiles)}    \n",
    "    \n",
    "    #Create empty data array for storing SREX-averaged heat indices\n",
    "    data_coll = xr.Dataset(coords=coords)\n",
    "    data_coll['HWMID'] = (coords.keys(), da_empty)\n",
    "\n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "        \n",
    "        #Select folder\n",
    "        if out_name=='':  dir_data = dir_HWMId + 'HWMId-' + HSI + '/'    \n",
    "        else:             dir_data = dir_HWMId + city + '/' + RCP + '/'\n",
    "                \n",
    "        #Loop over models\n",
    "        for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "            #Read data\n",
    "            fname_CORDEX = [file for file in os.listdir(dir_data) if HSI in file and RCP + '_' in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "            if len(fname_CORDEX)!=1:  sys.exit('File is not unique')\n",
    "            data_CORDEX = xr.open_dataset(dir_data + fname_CORDEX[0])              \n",
    "            \n",
    "            #Select city\n",
    "            if out_name=='':  data_CORDEX = data_CORDEX.sel(city=city)\n",
    "            \n",
    "            #Read European mean temperature (EMT)\n",
    "            files_EMT = sorted([dir_EMT + file for file in os.listdir(dir_EMT) if \"_\".join(model) in file and 'EMT_' in file])\n",
    "            data_EMT  = xr.concat((xr.open_dataset(file) for file in files_EMT), dim='time')\n",
    "            \n",
    "            #Calculate EMT relative to 1981-2010 and calculate 20-year means\n",
    "            dataEMT_ref = data_EMT.sel(time=slice('1981', '2010')).mean('time')\n",
    "            dataEMT_rel = data_EMT - dataEMT_ref\n",
    "            dataEMT_20y = dataEMT_rel.rolling(time=20, center=True).mean()\n",
    "\n",
    "            #Loop over selected EMT levels\n",
    "            for dEMT, dEMT_str in zip(EMT_change, EMT_change_str):\n",
    "\n",
    "                #Identify 20-year period in wich level is reached for first time\n",
    "                ind  = np.where(dataEMT_20y.tas>dEMT)[0][0]\n",
    "                central_year = dataEMT_20y.isel(time=ind).time.dt.year\n",
    "                start_year   = int(central_year - 20 / 2)\n",
    "                end_year     = int(central_year + (20 / 2 - 1))\n",
    "                years_sel    = slice(str(start_year), str(end_year))\n",
    "                \n",
    "                if end_year>2099:\n",
    "                    print(model)\n",
    "                    print(end_year)\n",
    "                \n",
    "                #Calculate median and 90th quantile\n",
    "                data_Q50 = data_CORDEX.HWMID.sel(time=years_sel).median('time')\n",
    "                data_Q90 = data_CORDEX.HWMID.sel(time=years_sel).quantile(0.90, dim='time')\n",
    "                \n",
    "                if out_name=='_3x3':\n",
    "                    \n",
    "                    #Read land fraction for each model and city\n",
    "                    land_frac = data_LSM[model[0] + '_' + model[1] + '_' + city]\n",
    "\n",
    "                    #Rename land fraction for MPI-WRF combination\n",
    "                    if (model[0]=='MPI-M-MPI-ESM-LR') and (model[1]=='IPSL-WRF381P'):\n",
    "                        land_frac = land_frac.rename({'rlat': 'y', 'rlon': 'x'})                       \n",
    "\n",
    "                    #Get coordinate names\n",
    "                    if 'longitude' in land_frac.coords:  lat_name1, lon_name1 = 'latitude', 'longitude'\n",
    "                    elif 'lon' in land_frac.coords:      lat_name1, lon_name1 = 'lat', 'lon'                        \n",
    "                    if 'rlon' in land_frac.coords:       lat_name2, lon_name2 = 'rlat', 'rlon'\n",
    "                    elif 'x' in land_frac.coords:        lat_name2, lon_name2 = 'y', 'x'   \n",
    "\n",
    "                    #Check if coordinates agree and reindex if they are slightly shifted\n",
    "                    check1a = np.sum(np.abs(land_frac[lat_name1].values - data_Q50[lat_name1].values))\n",
    "                    check1b = np.sum(np.abs(land_frac[lon_name1].values - data_Q50[lon_name1].values))\n",
    "                    check2a = np.sum(np.abs(land_frac[lat_name2].values - data_Q50[lat_name2].values))\n",
    "                    check2b = np.sum(np.abs(land_frac[lon_name2].values - data_Q50[lon_name2].values))\n",
    "                    if (check1a>0.001) or (check1b>0.001):\n",
    "                        sys.exit('Coordinates between data and LSM do not agree')\n",
    "                    if (check2a!=0) or (check2b!=0):\n",
    "                        land_frac[lon_name2] = data_Q50[lon_name2]\n",
    "                        land_frac[lat_name2] = data_Q50[lat_name2]                  \n",
    "                    \n",
    "                    #Loop over different minimum land fractions\n",
    "                    for land_min in land_fractions:\n",
    "\n",
    "                        #Apply land-sea mask\n",
    "                        data_Q90_land = data_Q90.where(land_frac>=land_min)\n",
    "                        data_Q50_land = data_Q50.where(land_frac>=land_min)\n",
    "                        \n",
    "                        #Test that final array still has all entries\n",
    "                        if data_Q90_land.shape!=(3,3):  sys.exit('bla')\n",
    "                            \n",
    "                        #Put data in array\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q50_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q50_land.max()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q90_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q90_land.max()\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    #Put data in array\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q50'}] = data_Q50\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"EMT_change\": dEMT_str, \"quantile\": 'Q90'}] = data_Q90\n",
    "\n",
    "    #Save data in file\n",
    "    fname_out = dir_save + 'HWMId-' + HSI + '_' + RCP + '_EMT.nc'\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    data_coll.to_netcdf(fname_out)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GWL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define folders\n",
    "dir_HWMId = dir_CORDEX + 'HWMId' + out_name + '/'\n",
    "dir_save  = dir_out + 'EURO-CORDEX' + out_name + '/'\n",
    "\n",
    "#Define RCP\n",
    "RCP = 'rcp85'\n",
    "\n",
    "#Define quantiles\n",
    "quantiles = ['Q50', 'Q90']\n",
    "\n",
    "#Define minimum fraction of land required on each grid point\n",
    "land_fractions = [0, 25, 50, 75, 100]\n",
    "\n",
    "#Loop over cities\n",
    "for HSI in HSI_names:\n",
    "    \n",
    "    print(HSI)\n",
    "\n",
    "    #Combine model names to one string\n",
    "    mod_names = [\"_\".join(model) for model in all_models[RCP]]\n",
    "\n",
    "    #Create empty numpy array and define coordinates\n",
    "    if out_name=='_3x3':\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(GWL_levels), len(quantiles), len(land_fractions), 2)) * np.NaN\n",
    "        coords={'model':        ('model', mod_names),\n",
    "                'city':         ('city', cities),\n",
    "                'GWL_level':    ('GWL_level', GWL_levels),\n",
    "                'quantile':     ('quantile', quantiles),\n",
    "                'land_frac':    ('land_frac', land_fractions),\n",
    "                'range_3x3box': ('range_3x3box', ['min', 'max'])}\n",
    "    else:\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(GWL_levels), len(quantiles))) * np.NaN\n",
    "        coords={'model':     ('model', mod_names),\n",
    "                'city':      ('city', cities),\n",
    "                'GWL_level': ('GWL_level', GWL_levels),\n",
    "                'quantile':  ('quantile', quantiles)}    \n",
    "    \n",
    "    #Create empty data array for storing SREX-averaged heat indices\n",
    "    data_coll = xr.Dataset(coords=coords)\n",
    "    data_coll['HWMID'] = (coords.keys(), da_empty)\n",
    "    \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "        \n",
    "        #Select folder\n",
    "        if out_name=='':  dir_data = dir_HWMId + 'HWMId-' + HSI + '/'    \n",
    "        else:             dir_data = dir_HWMId + city + '/' + RCP + '/'\n",
    "                \n",
    "        #Loop over models\n",
    "        for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "            #Get name of CMIP5 driving model\n",
    "            if ('CNRM-CERFAC' in model[0]) or ('CSIRO-QCCCE' in model[0]) or ('MPI-M' in model[0]) or ('NOAA-GFDL' in model[0]):\n",
    "                mod_CMIP5 = '-'.join(model[0].split('-')[2:])\n",
    "            else:\n",
    "                mod_CMIP5 = '-'.join(model[0].split('-')[1:])\n",
    "            \n",
    "            #Read data\n",
    "            fname_CORDEX = [file for file in os.listdir(dir_data) if HSI in file and RCP + '_' in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "            if len(fname_CORDEX)!=1:  sys.exit('File is not unique')\n",
    "            data_CORDEX = xr.open_dataset(dir_data + fname_CORDEX[0])              \n",
    "            \n",
    "            #Select city\n",
    "            if out_name=='':  data_CORDEX = data_CORDEX.sel(city=city)\n",
    "            \n",
    "            #Read time periods when certain global warming levels (GWL) are reached\n",
    "            time_GWL = dict()\n",
    "            for level in GWL_levels:\n",
    "                data_level = GWL_data['warming_level_' + level]\n",
    "                entry_sel = [entry for entry in data_level if entry['model']==mod_CMIP5 and entry['exp']==RCP and entry['ensemble']==model[2]]\n",
    "                \n",
    "                #Select data in time period when GWL is reached\n",
    "                time_GWL = slice(str(entry_sel[0]['start_year']), str(entry_sel[0]['end_year']))\n",
    "                \n",
    "                #Calculate median and 90th quantile\n",
    "                data_Q50 = data_CORDEX.HWMID.sel(time=time_GWL).median('time')\n",
    "                data_Q90 = data_CORDEX.HWMID.sel(time=time_GWL).quantile(0.90, dim='time')\n",
    "                \n",
    "                if out_name=='_3x3':\n",
    "                    \n",
    "                    #Read land fraction for each model and city\n",
    "                    land_frac = data_LSM[model[0] + '_' + model[1] + '_' + city]\n",
    "\n",
    "                    #Rename land fraction for MPI-WRF combination\n",
    "                    if (model[0]=='MPI-M-MPI-ESM-LR') and (model[1]=='IPSL-WRF381P'):\n",
    "                        land_frac = land_frac.rename({'rlat': 'y', 'rlon': 'x'})                       \n",
    "\n",
    "                    #Get coordinate names\n",
    "                    if 'longitude' in land_frac.coords:  lat_name1, lon_name1 = 'latitude', 'longitude'\n",
    "                    elif 'lon' in land_frac.coords:      lat_name1, lon_name1 = 'lat', 'lon'                        \n",
    "                    if 'rlon' in land_frac.coords:       lat_name2, lon_name2 = 'rlat', 'rlon'\n",
    "                    elif 'x' in land_frac.coords:        lat_name2, lon_name2 = 'y', 'x'   \n",
    "\n",
    "                    #Check if coordinates agree and reindex if they are slightly shifted\n",
    "                    check1a = np.sum(np.abs(land_frac[lat_name1].values - data_Q50[lat_name1].values))\n",
    "                    check1b = np.sum(np.abs(land_frac[lon_name1].values - data_Q50[lon_name1].values))\n",
    "                    check2a = np.sum(np.abs(land_frac[lat_name2].values - data_Q50[lat_name2].values))\n",
    "                    check2b = np.sum(np.abs(land_frac[lon_name2].values - data_Q50[lon_name2].values))\n",
    "                    if (check1a>0.001) or (check1b>0.001):\n",
    "                        sys.exit('Coordinates between data and LSM do not agree')\n",
    "                    if (check2a!=0) or (check2b!=0):\n",
    "                        land_frac[lon_name2] = data_Q50[lon_name2]\n",
    "                        land_frac[lat_name2] = data_Q50[lat_name2]                  \n",
    "                    \n",
    "                    #Loop over different minimum land fractions\n",
    "                    for land_min in land_fractions:\n",
    "\n",
    "                        #Apply land-sea mask\n",
    "                        data_Q90_land = data_Q90.where(land_frac>=land_min)\n",
    "                        data_Q50_land = data_Q50.where(land_frac>=land_min)\n",
    "                        \n",
    "                        #Test that final array still has all entries\n",
    "                        if data_Q90_land.shape!=(3,3):  sys.exit('bla')                    \n",
    "\n",
    "                        #Put data in array\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q50_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q50_land.max()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q90_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q90_land.max()\n",
    "                else:\n",
    "                        \n",
    "                    #Put data in array\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q50'}] = data_Q50\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"GWL_level\": level, \"quantile\": 'Q90'}] = data_Q90\n",
    "                \n",
    "    #Save data in file\n",
    "    fname_out = dir_save + 'HWMId-' + HSI + '_' + RCP + '_GWL.nc'\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    data_coll.to_netcdf(fname_out)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare time period data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define folders\n",
    "dir_HWMId = dir_CORDEX + 'HWMId' + out_name + '/'\n",
    "dir_save  = dir_out + 'EURO-CORDEX' + out_name + '/'\n",
    "\n",
    "#Select time periods\n",
    "time_periods = [[1981, 2010],\n",
    "                [2036, 2065],\n",
    "                [2070, 2099]]\n",
    "\n",
    "#Define time string\n",
    "time_strings = [str(time[0]) + '-' + str(time[1]) for time in time_periods]\n",
    "\n",
    "#Define RCPs\n",
    "RCP = 'rcp85'\n",
    "\n",
    "#Define quantiles\n",
    "quantiles = ['Q50', 'Q90']\n",
    "\n",
    "#Define minimum fraction of land required on each grid point\n",
    "land_fractions = [0, 25, 50, 75, 100]\n",
    "\n",
    "#Loop over cities\n",
    "for HSI in HSI_names:\n",
    "\n",
    "    print(HSI)\n",
    "\n",
    "    #Combine model names to one string\n",
    "    mod_names = [\"_\".join(model) for model in all_models[RCP]]\n",
    "\n",
    "    #Create empty numpy array and define coordinates\n",
    "    if out_name=='_3x3':\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(time_periods), len(quantiles), len(land_fractions), 2)) * np.NaN\n",
    "        coords={'model':        ('model', mod_names),\n",
    "                'city':         ('city', cities),\n",
    "                'time_period':  ('time_period', time_strings),\n",
    "                'quantile':     ('quantile', quantiles),\n",
    "                'land_frac':    ('land_frac', land_fractions),\n",
    "                'range_3x3box': ('range_3x3box', ['min', 'max'])}\n",
    "    else:\n",
    "        da_empty = np.zeros((len(all_models[RCP]), len(cities), len(time_periods), len(quantiles))) * np.NaN\n",
    "        coords={'model':       ('model', mod_names),\n",
    "                'city':        ('city', cities),\n",
    "                'time_period': ('time_period', time_strings),\n",
    "                'quantile':    ('quantile', quantiles)}    \n",
    "    \n",
    "    #Create empty data array for storing SREX-averaged heat indices\n",
    "    data_coll = xr.Dataset(coords=coords)\n",
    "    data_coll['HWMID'] = (coords.keys(), da_empty)\n",
    "\n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "\n",
    "        #Select folder\n",
    "        if out_name=='':  dir_data = dir_HWMId + 'HWMId-' + HSI + '/'    \n",
    "        else:             dir_data = dir_HWMId + city + '/' + RCP + '/'\n",
    "\n",
    "        #Loop over models\n",
    "        for i1, model in enumerate(all_models[RCP]):\n",
    "\n",
    "            #Get name of CMIP5 driving model\n",
    "            if ('CNRM-CERFAC' in model[0]) or ('CSIRO-QCCCE' in model[0]) or ('MPI-M' in model[0]) or ('NOAA-GFDL' in model[0]):\n",
    "                mod_CMIP5 = '-'.join(model[0].split('-')[2:])\n",
    "            else:\n",
    "                mod_CMIP5 = '-'.join(model[0].split('-')[1:])\n",
    "\n",
    "            #Read data\n",
    "            fname_CORDEX = [file for file in os.listdir(dir_data) if HSI in file and RCP + '_' in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "            if len(fname_CORDEX)!=1:  sys.exit('File is not unique')\n",
    "            data_CORDEX = xr.open_dataset(dir_data + fname_CORDEX[0])              \n",
    "\n",
    "            #Select city\n",
    "            if out_name=='':  data_CORDEX = data_CORDEX.sel(city=city)\n",
    "\n",
    "            #Loop over time periods\n",
    "            for time_period, time_string in zip(time_periods, time_strings):\n",
    "\n",
    "                #Select data in time period when GWL is reached\n",
    "                time_sel = slice(str(time_period[0]), str(time_period[1]))\n",
    "                data_Q50 = data_CORDEX.HWMID.sel(time=time_sel).median('time')\n",
    "                data_Q90 = data_CORDEX.HWMID.sel(time=time_sel).quantile(0.90, dim='time')\n",
    "                \n",
    "                if out_name=='_3x3':\n",
    "                    \n",
    "                    #Read land fraction for each model and city\n",
    "                    land_frac = data_LSM[model[0] + '_' + model[1] + '_' + city]\n",
    "\n",
    "                    #Rename land fraction for MPI-WRF combination\n",
    "                    if (model[0]=='MPI-M-MPI-ESM-LR') and (model[1]=='IPSL-WRF381P'):\n",
    "                        land_frac = land_frac.rename({'rlat': 'y', 'rlon': 'x'})                       \n",
    "\n",
    "                    #Get coordinate names\n",
    "                    if 'longitude' in land_frac.coords:  lat_name1, lon_name1 = 'latitude', 'longitude'\n",
    "                    elif 'lon' in land_frac.coords:      lat_name1, lon_name1 = 'lat', 'lon'                        \n",
    "                    if 'rlon' in land_frac.coords:       lat_name2, lon_name2 = 'rlat', 'rlon'\n",
    "                    elif 'x' in land_frac.coords:        lat_name2, lon_name2 = 'y', 'x'   \n",
    "\n",
    "                    #Check if coordinates agree and reindex if they are slightly shifted\n",
    "                    check1a = np.sum(np.abs(land_frac[lat_name1].values - data_Q50[lat_name1].values))\n",
    "                    check1b = np.sum(np.abs(land_frac[lon_name1].values - data_Q50[lon_name1].values))\n",
    "                    check2a = np.sum(np.abs(land_frac[lat_name2].values - data_Q50[lat_name2].values))\n",
    "                    check2b = np.sum(np.abs(land_frac[lon_name2].values - data_Q50[lon_name2].values))\n",
    "                    if (check1a>0.001) or (check1b>0.001):\n",
    "                        sys.exit('Coordinates between data and LSM do not agree')\n",
    "                    if (check2a!=0) or (check2b!=0):\n",
    "                        land_frac[lon_name2] = data_Q50[lon_name2]\n",
    "                        land_frac[lat_name2] = data_Q50[lat_name2]                  \n",
    "                    \n",
    "                    #Loop over different minimum land fractions\n",
    "                    for land_min in land_fractions:\n",
    "\n",
    "                        #Apply land-sea mask\n",
    "                        data_Q90_land = data_Q90.where(land_frac>=land_min)\n",
    "                        data_Q50_land = data_Q50.where(land_frac>=land_min)\n",
    "                        \n",
    "                        #Test that final array still has all entries\n",
    "                        if data_Q90_land.shape!=(3,3):  sys.exit('bla')                    \n",
    "\n",
    "                        #Put data in array\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q50_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q50', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q50_land.max()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'min'}] = data_Q90_land.min()\n",
    "                        data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q90', \"land_frac\": land_min, 'range_3x3box': 'max'}] = data_Q90_land.max()\n",
    "                else:\n",
    "                    \n",
    "                    #Put data in array\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q50'}] = data_Q50\n",
    "                    data_coll.HWMID.loc[{\"model\": \"_\".join(model), \"city\": city, \"time_period\": time_string, \"quantile\": 'Q90'}] = data_Q90\n",
    "\n",
    "    #Save data in file\n",
    "    data_coll.to_netcdf(dir_save + 'HWMId-' + HSI + '_' + RCP + '_time-periods.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
