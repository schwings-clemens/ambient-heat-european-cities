{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f41528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580ba52",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3119b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ELUC_NGHGI = '/work/mj0060/m300896/GCB2021_commentary/Data/data_ELUC_NGHGI/'\n",
    "dir_SLAND      = '/work/mj0060/m300896/GCB2021_commentary/Data/data_ELUC_NGHGI_SLAND_plot/'\n",
    "dir_ctrs       = '/work/mj0060/m300896/Trendy/Data/data_ancillary/info_countries/'\n",
    "dir_ELUC_2021  = '/work/mj0060/m300896/GCB2021_commentary/Data/ELUC_countries/'\n",
    "dir_peat       = '/work/mj0060/m300896/GCB2021/Data/Peat_data/'\n",
    "dir_out        = '/work/mj0060/m300896/GCB2021_commentary/Data/repository_data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4b81a",
   "metadata": {},
   "source": [
    "## Read country names and define countries for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c219db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_cntrs = dir_ctrs + 'Country codes 3 letters.xlsx'\n",
    "data_cntrs  = pd.read_excel(fname_cntrs, sheet_name=0, header=None, index_col=0)\n",
    "\n",
    "#Select countries\n",
    "countries_sel = ['USA', 'RUS', 'CAN', 'CHN', 'BRA', 'IDN', 'COD']\n",
    "countries_EU  = ['AUT', 'BEL', 'BGR', 'HRV', 'CYP', 'CZE', 'DNK', 'EST', 'FIN', 'FRA', 'DEU', 'GRC', 'HUN', 'IRL', 'ITA', 'LVA', 'LTU', 'LUX', 'MLT', 'NLD', 'POL', 'PRT', 'ROU', 'SVK', 'SVN', 'ESP', 'SWE', 'GBR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98744525",
   "metadata": {},
   "source": [
    "## Define time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eff7a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001-2015\n"
     ]
    }
   ],
   "source": [
    "#Define time\n",
    "time_sta = 2001\n",
    "time_end = 2015\n",
    "time_len = time_end - time_sta + 1\n",
    "time_str = str(time_sta) + '-' + str(time_end)\n",
    "\n",
    "print(time_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ca324",
   "metadata": {},
   "source": [
    "## Read peat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd5d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read peat data\n",
    "fname_peat_drai = dir_peat + 'Country_emissions_peat-drainage_FAO_1850-2021.xlsx'\n",
    "fname_peat_fire = dir_peat + 'Country_emissions_peat-fires_GFED4_1997-2021.xlsx'\n",
    "data_peat_in_1 = pd.read_excel(fname_peat_drai, header=0, index_col=0)\n",
    "data_peat_in_2 = pd.read_excel(fname_peat_fire, header=0, index_col=0)\n",
    "data_peat_in_1 = data_peat_in_1.loc[(data_peat_in_1.index>=time_sta) & (data_peat_in_1.index<=time_end)]\n",
    "data_peat_in_2 = data_peat_in_2.loc[(data_peat_in_2.index>=time_sta) & (data_peat_in_2.index<=time_end)]\n",
    "\n",
    "#Select time\n",
    "if (data_peat_in_1.index[0]!=time_sta) | (data_peat_in_1.index[-1]!=time_end) | (len(data_peat_in_1.index)!=time_len):  sys.exit('Check time selection of peat 1!')\n",
    "if (data_peat_in_2.index[0]!=time_sta) | (data_peat_in_2.index[-1]!=time_end) | (len(data_peat_in_2.index)!=time_len):  sys.exit('Check time selection of peat 2!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa463a34",
   "metadata": {},
   "source": [
    "## Prepare BLUE data (and add peat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86b5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data\n",
    "fname_ELUC  = dir_ELUC_2021 + 'ELUC_BLUE_countries-ISOcode_ELUC-net_vRemapCountries_2000-2020.xlsx'\n",
    "data_BLUE_read = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_BLUE_read = data_BLUE_read.loc[(data_BLUE_read.index>=time_sta) & (data_BLUE_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_BLUE_read.index[0]!=time_sta) | (data_BLUE_read.index[-1]!=time_end) | (len(data_BLUE_read.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "\n",
    "#Create empty dataframe\n",
    "data_ELUC_BLUE_2021_all = data_BLUE_read.copy()\n",
    "data_ELUC_BLUE_2021_all[:] = np.NaN\n",
    "\n",
    "#Loop over all countries\n",
    "for col in data_BLUE_read.columns:\n",
    "    \n",
    "    #Sum ELUC and peat\n",
    "    if col in data_peat_in_1.columns:\n",
    "        data_BLUE_read[col] = data_BLUE_read[col] + data_peat_in_1[col]\n",
    "    if col in data_peat_in_2.columns:\n",
    "        data_BLUE_read[col] = data_BLUE_read[col] + data_peat_in_2[col]\n",
    "\n",
    "    #Save in dataframe\n",
    "    data_ELUC_BLUE_2021_all[col] = data_BLUE_read[col]\n",
    "\n",
    "#Add data from Taiwan and Hongkong to China\n",
    "data_ELUC_BLUE_2021_all['CHN'] = data_ELUC_BLUE_2021_all['CHN'] + data_ELUC_BLUE_2021_all['TWN'] + data_ELUC_BLUE_2021_all['HKG']    \n",
    "    \n",
    "#Select countries\n",
    "data_BLUE_ctrs = data_ELUC_BLUE_2021_all[countries_sel]\n",
    "\n",
    "#Calculate sum over EU countries and add to dataframe\n",
    "data_BLUE_EU   = data_ELUC_BLUE_2021_all[countries_EU].sum(axis=1)\n",
    "data_BLUE_ctrs = data_BLUE_ctrs.assign(EU27_UK=data_BLUE_EU)\n",
    "\n",
    "## UNITS\n",
    "#data_ELUC_BLUE_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd486c4",
   "metadata": {},
   "source": [
    "## Prepare H&N2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821994b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read ELUC data (which already include peat)\n",
    "fname_ELUC = dir_ELUC_NGHGI + 'HN2021_ELUC-net-with-peat_GCB2021_countries.xlsx'\n",
    "data_HN2021_read = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_HN2021_read = data_HN2021_read.loc[(data_HN2021_read.index>=time_sta) & (data_HN2021_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_HN2021_read.index[0]!=time_sta) | (data_HN2021_read.index[-1]!=time_end) | (len(data_HN2021_read.index)!=time_len):  sys.exit('Check time selection of H&N2021!')\n",
    "\n",
    "#Create dataframe for storing data\n",
    "data_HN2021_ctrs = pd.DataFrame(index=data_HN2021_read.index)\n",
    "\n",
    "#Loop over selected countries\n",
    "for country in countries_sel:\n",
    "\n",
    "    #Get long name for country\n",
    "    ctr_long = data_cntrs.loc[country].item()\n",
    "    \n",
    "    #Change country name\n",
    "    if \"Congo, Democratic Republic of the\" in ctr_long:\n",
    "        ctr_long = \"Democratic Republic of the Congo\"\n",
    "\n",
    "    #Collect data in dataframe\n",
    "    data_HN2021_ctrs[country] = data_HN2021_read[ctr_long]\n",
    "    \n",
    "#Loop over EU countries\n",
    "data_HN2021_EU = pd.DataFrame(index=data_HN2021_read.index)\n",
    "for country in countries_EU:\n",
    "\n",
    "    #Get long name for country\n",
    "    ctr_long = data_cntrs.loc[country].item()\n",
    "    \n",
    "    #Change country name\n",
    "    if \"United Kingdom of Great Britain and Northern Ireland\" in ctr_long:\n",
    "        ctr_long = \"United Kingdom\"\n",
    "    elif \"Czechia\" in ctr_long:\n",
    "        ctr_long = \"Czech Republic\"\n",
    "    \n",
    "    #Collect data in dataframe\n",
    "    data_HN2021_EU[country] = data_HN2021_read[ctr_long]\n",
    "\n",
    "#Calculate sum over EU countries and add to dataframe\n",
    "data_HN2021_EU = data_HN2021_EU.sum(axis=1)\n",
    "data_HN2021_ctrs = data_HN2021_ctrs.assign(EU27_UK=data_HN2021_EU)\n",
    "      \n",
    "## UNITS\n",
    "#data_ELUC_HN_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b2fb5",
   "metadata": {},
   "source": [
    "## Prepare OSCAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba709a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ELUC data \n",
    "fname_ELUC = dir_ELUC_NGHGI + 'OSCAR_ELUC-net-with-peat_GCB2021_IPCCcountries.xlsx'\n",
    "data_OSCAR_read = pd.read_excel(fname_ELUC, header=0, index_col=0)\n",
    "\n",
    "#Select time\n",
    "data_OSCAR_read = data_OSCAR_read.loc[(data_OSCAR_read.index>=time_sta) & (data_OSCAR_read.index<=time_end)]\n",
    "\n",
    "#Check time selection\n",
    "if (data_OSCAR_read.index[0]!=time_sta) | (data_OSCAR_read.index[-1]!=time_end) | (len(data_OSCAR_read.index)!=time_len):  sys.exit('Check time selection of BLUE!')\n",
    "\n",
    "#Select countries\n",
    "data_OSCAR_ctrs = data_OSCAR_read[countries_sel]\n",
    "\n",
    "#Calculate sum over EU countries and add to dataframe\n",
    "data_OSCAR_EU   = data_OSCAR_read[countries_EU].sum(axis=1)\n",
    "data_OSCAR_ctrs = data_OSCAR_ctrs.assign(EU27_UK=data_OSCAR_EU)\n",
    "\n",
    "## UNITS\n",
    "#data_ELUC_OSCAR_2021 has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e98a90-ba37-4f82-b526-4a667337c47e",
   "metadata": {},
   "source": [
    "## Save bookkeeping data in excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9402c70-7224-478e-803c-8e5ce1b8bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BM_models = ['BLUE', 'OSCAR', 'H&N2021']\n",
    "\n",
    "#Define output file name\n",
    "fname_out = dir_out + 'Fig2_Data_country-level_anthropogenic-LULUCF-flux_BM-models_' + time_str + '.xlsx'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    \n",
    "#Create xlsx-file (it will be filled at end of loop with country data from every model)\n",
    "with pd.ExcelWriter(fname_out) as writer:\n",
    "    \n",
    "    for model in BM_models:\n",
    "\n",
    "        if model=='BLUE':      data = data_BLUE_ctrs\n",
    "        elif model=='OSCAR':   data = data_OSCAR_ctrs\n",
    "        elif model=='H&N2021': data = data_HN2021_ctrs\n",
    "        \n",
    "        #Convert Tg C/year to Tg CO2/year\n",
    "        data = data * 44 / 12        \n",
    "\n",
    "        #Add units in first cell and sort columns\n",
    "        data = data.rename_axis('unit: Tg CO2/year')\n",
    "        data = data.sort_index(axis=1)\n",
    "\n",
    "        #Create sheet in xlsx for every model and store country data\n",
    "        data.to_excel(writer, sheet_name=model, index=True, header=True, float_format='%.2f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3e3a4-0b83-41e2-96b4-1e1000cfa1a2",
   "metadata": {},
   "source": [
    "## Prepare SLAND data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "101b2305-d94d-406e-8d1e-94757a653dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read SLAND\n",
    "file_name  = dir_SLAND + 'Collection_SLAND_total-weighted_' + time_str + '.pickle'\n",
    "data_SLAND = pd.read_pickle(file_name)\n",
    "\n",
    "#Read SLAND on forests\n",
    "file_name = dir_SLAND + 'Collection_SLAND_non-intact-forest_mask2013_' + time_str + '.pickle'\n",
    "data_SLAND_forest = pd.read_pickle(file_name)\n",
    "\n",
    "#Convert unit from Tg C/year to Tg CO2/year\n",
    "data_SLAND        = 44/12 * data_SLAND\n",
    "data_SLAND_forest = 44/12 * data_SLAND_forest\n",
    "\n",
    "#Select SLAND median for specific countries\n",
    "countries_sel = ['BRA', 'CAN', 'CHN', 'COD', 'IDN', 'RUS', 'USA', 'EU27_UK']\n",
    "data_SLAND_all_sel = data_SLAND.loc[countries_sel].median(axis=1)\n",
    "data_SLAND_for_sel = data_SLAND_forest.loc[countries_sel].median(axis=1)\n",
    "\n",
    "#Get uncertainty\n",
    "models_SLAND = data_SLAND_forest.columns\n",
    "data_SLAND_all_unc = data_SLAND.loc[countries_sel][models_SLAND]\n",
    "data_SLAND_for_unc = data_SLAND_forest.loc[countries_sel][models_SLAND]\n",
    "\n",
    "#Save uncertainty in data frames\n",
    "data_DGVMs_ALL = pd.DataFrame(index=data_SLAND_all_unc.index, columns=['median', 'lower range', 'upper range'])\n",
    "data_DGVMs_FOR = pd.DataFrame(index=data_SLAND_for_unc.index, columns=['median', 'lower range', 'upper range'])\n",
    "data_DGVMs_ALL['median']      = data_SLAND_all_unc.quantile(0.50, axis=1)\n",
    "data_DGVMs_ALL['lower range'] = data_SLAND_all_unc.quantile(0.25, axis=1)\n",
    "data_DGVMs_ALL['upper range'] = data_SLAND_all_unc.quantile(0.75, axis=1)\n",
    "data_DGVMs_FOR['median']      = data_SLAND_for_unc.quantile(0.50, axis=1)\n",
    "data_DGVMs_FOR['lower range'] = data_SLAND_for_unc.quantile(0.25, axis=1)\n",
    "data_DGVMs_FOR['upper range'] = data_SLAND_for_unc.quantile(0.75, axis=1)\n",
    "\n",
    "data_SLAND_out = dict()\n",
    "data_SLAND_out['all-land']        = data_DGVMs_ALL\n",
    "data_SLAND_out['managed-forests'] = data_DGVMs_FOR\n",
    "\n",
    "# ## UNITS\n",
    "# data_DGVMs_ALL and data_DGVMs_FOR have units: Tg CO2 / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe862c-fc0f-4aac-9769-0fa9a8223f67",
   "metadata": {},
   "source": [
    "## Save SLAND data in excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13deccc-e0b2-4c9b-878f-0a467c6f3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data that should be stored\n",
    "selections = ['all-land', 'managed-forests']\n",
    "\n",
    "#Loop over selections\n",
    "for selection in selections:\n",
    "    \n",
    "    #Define output file name and sheet names\n",
    "    if selection=='all-land':\n",
    "        fname_out = dir_out + 'Fig1_Data_country-level_natural-land-flux_DGVMs_' + time_str + '.xlsx'\n",
    "        sheet_name = 'Total natural sink (all land)'\n",
    "    elif selection=='managed-forests':\n",
    "        fname_out = dir_out + 'Fig2_Data_country-level_natural-land-flux_DGVMs_' + time_str + '.xlsx'\n",
    "        sheet_name = 'Natural sink in managed forests'\n",
    "    \n",
    "    #Select data\n",
    "    data = data_SLAND_out[selection].sort_index()\n",
    "\n",
    "    #Add units in first cell and sort\n",
    "    data = data.rename_axis('unit: Tg CO2/year')\n",
    "    data = data.sort_index()\n",
    "\n",
    "    #Create sheet in xlsx for every model and store country data\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    data.to_excel(fname_out, sheet_name=sheet_name, index=True, header=True, float_format='%.2f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012d41a",
   "metadata": {},
   "source": [
    "## Read data NGHGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb8b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data   \n",
    "fname_NGHGI = dir_ELUC_NGHGI + 'Grassi_Giacomo_NGHGI_2021_11_preliminary.xlsx'\n",
    "data_NGHGI  = pd.read_excel(fname_NGHGI, sheet_name='summary DB2', header=2, index_col=0)\n",
    "\n",
    "#Read new data for Indonesia\n",
    "fname_IDN = dir_ELUC_NGHGI + 'LULUCF_Indonesia_UNFCCC_BUR3.xlsx'\n",
    "data_IDN  = pd.read_excel(fname_IDN, header=0, index_col=0)\n",
    "\n",
    "#Get column and index names\n",
    "data_NGHGI.columns = data_NGHGI.iloc[0]\n",
    "data_NGHGI.index = data_NGHGI['ISO']\n",
    "\n",
    "#Select data\n",
    "data_NGHGI = data_NGHGI.iloc[1:196, 12:16]\n",
    "data_NGHGI = data_NGHGI.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "######################## Temporarily change data for China ########################\n",
    "\n",
    "data_China = pd.DataFrame(columns=['NGHGI'], index=np.arange(2000, 2021))\n",
    "data_China.loc[2005] =  -803000 / 1000\n",
    "data_China.loc[2010] = -1029720 / 1000\n",
    "data_China.loc[2012] =  -575848 / 1000\n",
    "data_China.loc[2014] = -1150910 / 1000\n",
    "data_China = data_China.astype(float)\n",
    "\n",
    "#Interpolate and extrapolate data\n",
    "data_China = data_China.interpolate(limit_direction='both')\n",
    "\n",
    "#Add data to NGHGI\n",
    "data_NGHGI.loc['CHN'][0] = data_China[(data_China.index>=2001) & (data_China.index<=2005)].mean()\n",
    "data_NGHGI.loc['CHN'][1] = data_China[(data_China.index>=2006) & (data_China.index<=2010)].mean()\n",
    "data_NGHGI.loc['CHN'][2] = data_China[(data_China.index>=2011) & (data_China.index<=2015)].mean()\n",
    "data_NGHGI.loc['CHN'][3] = data_China[(data_China.index>=2016) & (data_China.index<=2020)].mean()\n",
    "\n",
    "######################## Temporarily change data for China ########################\n",
    "\n",
    "\n",
    "\n",
    "#Define index for time selection (start)\n",
    "if time_sta==2001:  i_sta = 0\n",
    "else:               sys.exit('Start time is not well defined for NGHGI')\n",
    "\n",
    "#Define index for time selection (end)\n",
    "if time_end==2010:    i_end = 2\n",
    "elif time_end==2015:  i_end = 3\n",
    "elif time_end==2020:  i_end = 4\n",
    "else:                 sys.exit('End time is not well defined for NGHGI')\n",
    "\n",
    "#Select time and calculate average\n",
    "data_NGHGI = data_NGHGI.iloc[:, i_sta:i_end].mean(axis=1)\n",
    "data_NGHGI = pd.Series(data_NGHGI, index = data_NGHGI.index).to_frame(name='NGHGI')\n",
    "\n",
    "#Calculate average for Indonesia in selected period and add replace old NGHGI data of IDN\n",
    "data_IDN  = data_IDN[data_IDN.columns[(data_IDN.columns>=time_sta) & (data_IDN.columns<=time_end)]].mean(axis=1)\n",
    "data_NGHGI.loc['IDN'] = data_IDN['LULUCF flux'] / 1000\n",
    "\n",
    "#Convert from Mt CO2 yr-1 to Mt C yr-1 (=Tg C / year)\n",
    "data_NGHGI = 12 / 44 * data_NGHGI\n",
    "\n",
    "\n",
    "## Add REDD+ data for DR Congo\n",
    "\n",
    "#Read data   \n",
    "fname_REDD = dir_ELUC_NGHGI + 'REDDplus_DRC.xlsx'\n",
    "data_REDD  = pd.read_excel(fname_REDD, header=1, index_col=1)\n",
    "\n",
    "#Select data and time period\n",
    "data_REDD = data_REDD.iloc[0:3,1::]\n",
    "data_REDD = data_REDD.loc['Net']\n",
    "data_REDD = data_REDD[(data_REDD.index>=time_sta) & (data_REDD.index<=time_end)].mean()\n",
    "\n",
    "#Convert from kt CO2 yr-1 to Mt C yr-1 (=Tg C / year)\n",
    "data_REDD = 12 / 44 / 1000 * data_REDD\n",
    "\n",
    "#Add to NGHGI data\n",
    "data_COD = [data_REDD, data_NGHGI.loc['COD', 'NGHGI']]\n",
    "data_NGHGI.loc['COD', 'NGHGI'] = np.mean(data_COD)\n",
    "\n",
    "#Calculate sum over EU countries and add to dataframe\n",
    "data_NGHGI_EU   = data_NGHGI.loc[countries_EU].sum()\n",
    "data_NGHGI.loc['EU27_UK'] = data_NGHGI_EU\n",
    "\n",
    "#Select countries\n",
    "data_NGHGI_ctrs = data_NGHGI.loc[countries_sel]\n",
    "\n",
    "#Rename column\n",
    "data_NGHGI_ctrs = data_NGHGI_ctrs.rename(columns={'NGHGI': 'mean'})\n",
    "\n",
    "#Add uncertainty\n",
    "data_unc_perc = pd.DataFrame(columns=['uncertainty_lower', 'uncertainty_upper'])\n",
    "data_unc_perc.loc['USA']     = [-17.1, 19.7]\n",
    "data_unc_perc.loc['RUS']     = [-42.8, 42.8]\n",
    "data_unc_perc.loc['CAN']     = [-209.0, 209.0]\n",
    "data_unc_perc.loc['CHN']     = [-23.4, 23.4]\n",
    "data_unc_perc.loc['BRA']     = [-34.9, 34.9]\n",
    "data_unc_perc.loc['IDN']     = [-20.1, 20.1]\n",
    "data_unc_perc.loc['EU27_UK'] = [-34.2, 34.2]\n",
    "data_unc_perc = data_unc_perc.astype(float)\n",
    "\n",
    "#Calculate uncertainty in Tg C /year\n",
    "data_unc = pd.DataFrame(columns=['unc1', 'unc2'])\n",
    "data_unc['unc1'] = data_NGHGI_ctrs['mean']  * (1 + data_unc_perc['uncertainty_upper'] / 100)\n",
    "data_unc['unc2'] = data_NGHGI_ctrs['mean']  * (1 + data_unc_perc['uncertainty_lower'] / 100)\n",
    "\n",
    "#Add uncertainty for COD\n",
    "data_unc.loc['COD'] = [np.min(data_COD), np.max(data_COD)]\n",
    "\n",
    "#Get minimum and maximum and drop unnecessary columns\n",
    "data_unc['uncertainty_lower'] = data_unc.min(axis=1)\n",
    "data_unc['uncertainty_upper'] = data_unc.max(axis=1)\n",
    "data_unc = data_unc.drop(columns=['unc1', 'unc2'])\n",
    "\n",
    "#Add uncertainty to data frame\n",
    "data_NGHGI_ctrs = pd.concat((data_NGHGI_ctrs, data_unc), axis=1)\n",
    "\n",
    "## UNITS\n",
    "#data_NGHGI has units: Tg C / year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71921e3-31b3-403d-a844-2001a02d7eb2",
   "metadata": {},
   "source": [
    "## Save NGHGI data in excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39dd9012-1282-4522-8638-f25a34a31ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define output file name\n",
    "fname_out = dir_out + 'Fig2_Data_country-level_LULUCF-flux_UNFCCC-reports_' + time_str + '-average.xlsx'\n",
    "if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    \n",
    "#Create xlsx-file (it will be filled at end of loop with country data from every model)\n",
    "with pd.ExcelWriter(fname_out) as writer:\n",
    "\n",
    "    #Convert Tg C/year to Tg CO2/year\n",
    "    data = data_NGHGI_ctrs * 44 / 12        \n",
    "\n",
    "    #Add units in first cell and sort\n",
    "    data = data.rename_axis('unit: Tg CO2/year')\n",
    "    data = data.sort_index()\n",
    "    \n",
    "    #Create sheet in xlsx for every model and store country data\n",
    "    data.to_excel(writer, sheet_name='LULUCF from UNFCCC reports', index=True, header=True, float_format='%.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa2509-55ac-4427-aceb-2aa16cc9f371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
