{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import mplotutils as mpu\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main path\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "\n",
    "dir_EMT_CORDEX = f'{path_main}Data/EURO-CORDEX/EMT/'\n",
    "dir_data       = f'{path_main}Data/'\n",
    "dir_names      = f'{path_main}Scripts/Model_lists/'\n",
    "dir_fig        = f'{path_main}Figures/Paper_v2/'\n",
    "dir_repo       = f'{path_main}Data/RepositoryPublication/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955f6b4",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define models and RCPs which should be used\n",
    "models_CORDEX = dict()\n",
    "models_CORDEX = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        models_CORDEX.append(eval(line[:-1]))\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "models_CMIP5 = dict()\n",
    "models_CMIP5 = []\n",
    "with open(dir_names + 'Models_CMIP5_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        models_CMIP5.append(line[:-1])\n",
    "      \n",
    "    \n",
    "    \n",
    "models_CMIP5 = models_CMIP5[0:-1]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Define models and RCPs which should be used\n",
    "models_CMIP6 = dict()\n",
    "models_CMIP6 = []\n",
    "with open(dir_names + 'Models_CMIP6_SSP585.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        models_CMIP6.append(line[:-1])        \n",
    "        \n",
    "models_set = dict()\n",
    "models_set['CMIP6']       = models_CMIP6  \n",
    "models_set['CMIP5']       = models_CMIP5\n",
    "models_set['EURO-CORDEX'] = models_CORDEX\n",
    "\n",
    "colors = dict()\n",
    "colors['EURO-CORDEX'] = 'tab:red'\n",
    "colors['CMIP5']       = 'darkorchid'\n",
    "colors['CMIP6']       = 'k'  \n",
    "\n",
    "dEMT = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23086316",
   "metadata": {},
   "source": [
    "## Extract CMIP models used in EURO-CORDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f229f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count occurrence of CORDEX GCMs\n",
    "GCMs_COR_orig = [model[0] + '_' + model[2] for model in models_CORDEX]\n",
    "\n",
    "GCMs_CORDEX = []\n",
    "for GCM in GCMs_COR_orig:\n",
    "    \n",
    "    if 'MPI' in GCM or 'CNRM' in GCM:  GCMs_CORDEX.append(\"-\".join(GCM.split('-')[2::]))\n",
    "    else:                              GCMs_CORDEX.append(\"-\".join(GCM.split('-')[1::]))\n",
    "\n",
    "GCMs_unique = list(set(GCMs_CORDEX))\n",
    "counts_GCMs = {GCM:GCMs_CORDEX.count(GCM) for GCM in GCMs_unique}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b8fb5",
   "metadata": {},
   "source": [
    "## Get EMT and GMT change for CMIP5 and CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define reference period\n",
    "ref_per = slice('1981', '2010')\n",
    "\n",
    "#Create dict for storing data and for creating output dataframe\n",
    "data_dict     = dict()\n",
    "data_coll_out = dict()\n",
    "\n",
    "#Loop over CMIP5, CMIP6, CORDEX\n",
    "p_all = []\n",
    "for model_set, models in models_set.items():\n",
    "\n",
    "    #Define scenarios\n",
    "    if model_set=='EURO-CORDEX':  continue\n",
    "    elif model_set=='CMIP6':      scen_fut = 'ssp585'\n",
    "    elif model_set=='CMIP5':      scen_fut = 'rcp85'\n",
    "\n",
    "    #Define scenarios\n",
    "    scenarios = ['historical', scen_fut]\n",
    "    \n",
    "    #Loop over GMT and EMT\n",
    "    for T_sel in ['GMT', 'EMT']:\n",
    "\n",
    "        #Define folder\n",
    "        dir_read = dir_data + model_set + '/' + T_sel + '/'\n",
    "    \n",
    "        #Loop over all models\n",
    "        model_names = []\n",
    "        data_coll_out2 = pd.DataFrame(columns=models)\n",
    "        for i, model in enumerate(models):\n",
    "\n",
    "            #Define members for CMIP5\n",
    "            if model_set=='CMIP5':\n",
    "                if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "                elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "                else:                      members = ['r1i1p1']        \n",
    "            else:\n",
    "                members = ['']\n",
    "                \n",
    "            #Loop over members\n",
    "            for member in members:\n",
    "\n",
    "                if model_set=='CMIP5':\n",
    "                    model_names.append( model + '_' + member)\n",
    "                else:\n",
    "                    model_names.append( model)\n",
    "                \n",
    "                #Loop over scenarios\n",
    "                for scen in scenarios:\n",
    "\n",
    "                    #Get file names\n",
    "                    fnames_hist = [file for file in os.listdir(dir_read) if T_sel + '_' in file and model + '_' in file and member in file and 'historical' in file]\n",
    "                    fnames_rcp  = [file for file in os.listdir(dir_read) if T_sel + '_' in file and model + '_' in file and member in file and scen_fut in file]\n",
    "                    if len(fnames_hist)>1:\n",
    "                        fnames_hist = [fname for fname in fnames_hist if int(fname.split('_')[-1].split('-')[0])>1900]\n",
    "                    if len(fnames_hist)!=1:  sys.exit('File is not unique')\n",
    "                    if len(fnames_rcp)!=1:   sys.exit('File is not unique')\n",
    "\n",
    "                    #Read and concatenate data\n",
    "                    fnames = fnames_hist + fnames_rcp\n",
    "                    data_read = xr.concat((xr.open_dataset(dir_read + fname, use_cftime=True) for fname in fnames), dim='time')\n",
    "\n",
    "                #Drop height\n",
    "                if 'height' in data_read:  data_read = data_read.drop('height')                    \n",
    "                    \n",
    "                #Collect data for saving in excel file\n",
    "                data_pd = data_read.copy()\n",
    "                data_pd['time'] = data_pd.time.dt.year\n",
    "                data_coll_out2[model] = data_pd.tas.to_dataframe()['tas']\n",
    "\n",
    "                #Calculate change w.r.t. reference period\n",
    "                data_rel = data_read - data_read.sel(time=ref_per).mean()\n",
    "\n",
    "                #Smooth data\n",
    "                data_rel_smooth = data_rel.rolling(time=10, center=True).mean('time')\n",
    "\n",
    "                #Concatenate data\n",
    "                if i==0:\n",
    "                    data_coll = data_rel_smooth\n",
    "                else:\n",
    "                    data_rel_smooth['time'] = data_coll.time\n",
    "                    data_coll = xr.concat((data_coll, data_rel_smooth), dim='model')\n",
    "\n",
    "        #Add model names and save in dict\n",
    "        data_coll['model'] = model_names\n",
    "        data_dict[T_sel + '_' + model_set]     = data_coll\n",
    "        data_coll_out[T_sel + '_' + model_set] = data_coll_out2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf10b4",
   "metadata": {},
   "source": [
    "## Calculate global warming since PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40884ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define reference period\n",
    "ref_per = slice('1850', '1900')\n",
    "\n",
    "#Create dict for storing data \n",
    "data_GlobWarm = dict()\n",
    "\n",
    "#Loop over CMIP5, CMIP6, CORDEX\n",
    "p_all = []\n",
    "for model_set, models in models_set.items():\n",
    "    \n",
    "    if model_set=='EURO-CORDEX':  continue    \n",
    "    \n",
    "    #Define folder\n",
    "    dir_read = dir_data + model_set + '/GMT/'\n",
    "\n",
    "    array_coll = np.zeros(len(models)) * np.NaN\n",
    "    \n",
    "    #Loop over all models\n",
    "    for i, model in enumerate(models):        \n",
    "\n",
    "        #Define members for CMIP5\n",
    "        if model_set=='CMIP5':\n",
    "            member = 'r1i1p1'\n",
    "        else:\n",
    "            member = ''\n",
    "\n",
    "        #Get file names\n",
    "        fnames_hist = [file for file in os.listdir(dir_read) if 'GMT_' in file and model + '_' in file and member in file and 'historical' in file]\n",
    "        if len(fnames_hist)>1:\n",
    "            fnames_hist = [fname for fname in fnames_hist if int(fname.split('_')[-1].split('-')[0])<1900]\n",
    "        if len(fnames_hist)!=1:  sys.exit('File is not unique')\n",
    "\n",
    "        #Read data\n",
    "        data_read = xr.open_dataset(dir_read + fnames_hist[0], use_cftime=True)\n",
    "\n",
    "        #Calculate change w.r.t. reference period\n",
    "        data_rel = data_read - data_read.sel(time=ref_per).mean()\n",
    "        data_rel = data_rel.sel(time=slice('1981', '2010')).mean()\n",
    "        \n",
    "        \n",
    "        array_coll[i] = data_rel.tas.item()\n",
    "            \n",
    "    #Add model names and save in dict\n",
    "    print('Global warming up to 1981-2010 for ' + model_set, end=': ')\n",
    "    print('{:.2f}'.format(array_coll.mean()) + '°C')\n",
    "    data_GlobWarm['GMT_' + model_set] = array_coll\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a5408",
   "metadata": {},
   "source": [
    "## Interpolate CMIP5 and CMIP6 GMT and EMT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aeb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target x vector\n",
    "x = np.arange(-1, 7, 0.1)\n",
    "y_plot = dict()\n",
    "\n",
    "#Loop over model sets\n",
    "for model_set, models in models_set.items():\n",
    "\n",
    "    if model_set=='EURO-CORDEX':  continue    \n",
    "    \n",
    "    #Get data\n",
    "    GMT = data_dict['GMT_' + model_set]\n",
    "    EMT = data_dict['EMT_' + model_set]\n",
    "\n",
    "    #Array for storing data\n",
    "    y_all = np.zeros((len(x), len(GMT.model))) * np.NaN\n",
    "    \n",
    "    #Loop over models\n",
    "    for i0, model in enumerate(GMT.model):\n",
    "    \n",
    "        #Get data\n",
    "        xp = GMT.sel(model=model).tas\n",
    "        yp = EMT.sel(model=model).tas\n",
    "        \n",
    "        #Interpolate and save in array\n",
    "        y_all[:, i0] = np.interp(x, xp, yp)\n",
    "    \n",
    "    #Calculate quantiles and store in dict\n",
    "    y_plot[model_set + '_Q10'] = np.nanquantile(y_all, 0.10, axis=1)\n",
    "    y_plot[model_set + '_Q25'] = np.nanquantile(y_all, 0.25, axis=1)\n",
    "    y_plot[model_set + '_Q50'] = np.nanquantile(y_all, 0.50, axis=1)\n",
    "    y_plot[model_set + '_Q75'] = np.nanquantile(y_all, 0.75, axis=1)\n",
    "    y_plot[model_set + '_Q90'] = np.nanquantile(y_all, 0.90, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce67a7e",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150895c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define reference period\n",
    "ref_per = slice('1981', '2010')\n",
    "\n",
    "#Create figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "\n",
    "### Plot EMT ###\n",
    "\n",
    "ax = axes[0]\n",
    "\n",
    "#Empty dict for collecting data\n",
    "coll_years = dict()\n",
    "\n",
    "#Loop over CMIP5, CMIP6, CORDEX\n",
    "p_all = []\n",
    "for model_set, models in models_set.items():\n",
    "    \n",
    "    dir_EMT = dir_data + model_set + '/EMT/'\n",
    "    \n",
    "    coll_years[model_set] = np.zeros(len(models)) * np.NaN\n",
    "    \n",
    "    if model_set=='EURO-CORDEX':\n",
    "        data_coll_out3 = pd.DataFrame(columns=[\"_\".join(model) for model in models])\n",
    "\n",
    "    #Loop over all CORDEX models\n",
    "    model_names = []\n",
    "    for i, model in enumerate(models):\n",
    "        \n",
    "        if model_set=='EURO-CORDEX':\n",
    "            mod_read = \"_\".join(model)\n",
    "        else:\n",
    "            mod_read = model + '_'\n",
    "        \n",
    "        #Select scenarios\n",
    "        if model_set=='CMIP6':  scen_fut = 'ssp585'\n",
    "        else:                   scen_fut = 'rcp85'\n",
    "        \n",
    "        scenarios = ['historical', scen_fut]\n",
    "        \n",
    "        #Define members for CMIP5\n",
    "        if model_set=='CMIP5':\n",
    "            if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "            elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "            else:                      members = ['r1i1p1']        \n",
    "        else:\n",
    "            members = ['']     \n",
    "\n",
    "        #Loop over members\n",
    "        for member in members:\n",
    "\n",
    "            #Define model names\n",
    "            if model_set=='CMIP5':  model_names.append(model + '_' + member)\n",
    "            else:                   model_names.append(mod_read[0::])                        \n",
    "            \n",
    "            #Loop over scenarios\n",
    "            for scen in scenarios:\n",
    "\n",
    "                #Get file names\n",
    "                fnames_hist = [file for file in os.listdir(dir_EMT) if 'EMT_' in file and mod_read in file and member in file and 'historical' in file]\n",
    "                fnames_rcp = [file for file in os.listdir(dir_EMT) if 'EMT_' in file and mod_read in file and member in file and scen_fut in file]\n",
    "                if len(fnames_hist)!=1:  sys.exit('File is not unique')\n",
    "                if len(fnames_rcp)!=1:  sys.exit('File is not unique')\n",
    "\n",
    "                #Read and concatenate EMT\n",
    "                fnames = fnames_hist + fnames_rcp\n",
    "                data_EMT = xr.concat((xr.open_dataset(dir_EMT + fname, use_cftime=True) for fname in fnames), dim='time')\n",
    "\n",
    "                #Select in time window and collect data in dataframe\n",
    "                if model_set=='EURO-CORDEX':\n",
    "                    data_EMT = data_EMT.sel(time=slice('1971', '2100'))\n",
    "                    \n",
    "                    #Collect data for saving in excel file\n",
    "                    data_pd = data_EMT.copy()\n",
    "                    data_pd['time'] = data_pd.time.dt.year\n",
    "                    data_coll_out3[\"_\".join(model)] = data_pd.tas.to_dataframe()['tas']\n",
    "                    \n",
    "            #Calculate change w.r.t. reference period\n",
    "            data_EMT_rel = data_EMT - data_EMT.sel(time=ref_per).mean()\n",
    "\n",
    "            #Select data in common period\n",
    "            if model_set=='EURO-CORDEX':\n",
    "                data_EMT_rel = data_EMT_rel.sel(time=slice('1971', '2098'))\n",
    "\n",
    "            #Drop height\n",
    "            if 'height' in data_EMT_rel: data_EMT_rel = data_EMT_rel.drop('height')\n",
    "\n",
    "            #Smooth data and find year in which a certain EMT value is exceeded for the first time\n",
    "            data_EMT_smooth = data_EMT_rel.rolling(time=20, center=True).mean('time')\n",
    "            ind = np.where(data_EMT_smooth.tas>dEMT)[0]\n",
    "            if len(ind)!=0:\n",
    "                central_year = data_EMT_smooth.isel(time=ind[0]).time.dt.year\n",
    "\n",
    "                if (model_set=='CMIP5' and model in ['EC-EARTH', 'MIROC5', 'MPI-ESM-LR']):\n",
    "                    print('Skip ' + model + ' for central year')\n",
    "                else:\n",
    "                    coll_years[model_set][i] = central_year\n",
    "            else:\n",
    "                print(mod_read)\n",
    "\n",
    "            #Concatenate data\n",
    "            if i==0:\n",
    "                data_EMT_coll = data_EMT_rel\n",
    "            else:\n",
    "                data_EMT_rel['time'] = data_EMT_coll.time\n",
    "                data_EMT_coll = xr.concat((data_EMT_coll, data_EMT_rel), dim='model')\n",
    "    \n",
    "    #Add model names to data array\n",
    "    data_EMT_coll['model'] = model_names\n",
    "    \n",
    "    #Collect dat for saving in excel file\n",
    "    if model_set=='EURO-CORDEX':\n",
    "        data_coll_out['EMT_EURO-CORDEX'] = data_coll_out3\n",
    "    \n",
    "    #Calculate weighted average for CMIP5 models (to match the EURO-CORDEX GCM ensemble)\n",
    "    if model_set=='CMIP5':\n",
    "        \n",
    "        #Loop over GCMs used in CORDEX\n",
    "        create = 1\n",
    "        for GCM, N in counts_GCMs.items():\n",
    "            \n",
    "            #Replace r3i1p1 member of EC-EARTH with a different member, as no data exits for it\n",
    "            if GCM=='EC-EARTH_r3i1p1':  GCM = 'EC-EARTH_r1i1p1'            \n",
    "\n",
    "            #Select GCM and add it N times to arrray\n",
    "            data_sel = data_EMT_coll.sel(model=GCM)\n",
    "            for n in range(0, N):\n",
    "                if create==1:\n",
    "                    data_CMIP5_weighted = data_sel\n",
    "                    create = 0\n",
    "                else:\n",
    "                    data_CMIP5_weighted = xr.concat((data_CMIP5_weighted, data_sel), dim='N')\n",
    "        \n",
    "        #Calculate model average and moving average\n",
    "        data_CMIP5_weighted = data_CMIP5_weighted.median('N')\n",
    "        data_CMIP5_weighted = data_CMIP5_weighted.rolling(time=10, center=True).mean('time')\n",
    "        \n",
    "        #Select only one ensemble member per model\n",
    "        models_sel = [model for model in data_EMT_coll.model.values if 'r1i1p1' in model]\n",
    "        data_EMT_coll = data_EMT_coll.sel(model=models_sel)\n",
    "        \n",
    "    #Calculate multi-model median\n",
    "    data_Q10 = data_EMT_coll.quantile(0.1, 'model')\n",
    "    data_Q50 = data_EMT_coll.quantile(0.5, 'model')\n",
    "    data_Q90 = data_EMT_coll.quantile(0.9, 'model')\n",
    "\n",
    "    #Moving average\n",
    "    data_Q10 = data_Q10.rolling(time=10, center=True).mean('time')\n",
    "    data_Q50 = data_Q50.rolling(time=10, center=True).mean('time')\n",
    "    data_Q90 = data_Q90.rolling(time=10, center=True).mean('time')\n",
    "\n",
    "    ax.fill_between(data_Q10.time.dt.year, data_Q10.tas, data_Q90.tas, color=colors[model_set], edgecolor='none', alpha=0.15, zorder=10)\n",
    "\n",
    "    #Plot multi-model median\n",
    "    p = ax.plot(data_Q50.time.dt.year, data_Q50.tas, linewidth=2, color=colors[model_set], alpha=1, zorder=20, label=model_set)    \n",
    "    p_all.append(p[0])\n",
    "    \n",
    "    if model_set=='CMIP5':\n",
    "        p_extra = ax.plot(data_CMIP5_weighted.time.dt.year, data_CMIP5_weighted.tas, linewidth=2, linestyle='--', color=colors[model_set], alpha=1, zorder=20, label='EURO-CORDEX GCM ensemble')\n",
    "\n",
    "#Limits, labels, and ticks    \n",
    "xlims = [1981, 2094]\n",
    "ylims = [-1, 7]\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.set_xticks(range(1990, 2100, 20))\n",
    "ax.set_xlabel('time', fontsize=20, labelpad=10)\n",
    "ax.set_ylabel('$\\Delta$ESAT / °C', fontsize=20, labelpad=10)\n",
    "# ax.set_title('Change in European mean temperature', fontsize=20, pad=15)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "#Legend\n",
    "ax.legend(loc=2, fontsize=14)\n",
    "\n",
    "#Gridlines\n",
    "ax.yaxis.grid(color='gainsboro')\n",
    "\n",
    "#Write letter\n",
    "ax.text(xlims[0] + 0.02 * np.diff(xlims), ylims[0] + 1.03 * np.diff(ylims), '(a)', va='bottom', ha='left', fontweight='bold', fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "### EMT-GMT plot ####\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "x_text = [0.6, 0.6]\n",
    "y_text = [3.3, 2.9]\n",
    "    \n",
    "#Loop over model sets  \n",
    "p_all = []\n",
    "for ii, (model_set, models) in enumerate(models_set.items()):\n",
    "\n",
    "    if model_set=='EURO-CORDEX':  continue\n",
    "    \n",
    "    #Get data\n",
    "    y_Q10 = y_plot[model_set + '_Q10']\n",
    "    y_Q50 = y_plot[model_set + '_Q50']\n",
    "    y_Q90 = y_plot[model_set + '_Q90']\n",
    "    \n",
    "    #Plot\n",
    "    ax.fill_between(x, y_Q10, y_Q90, color=colors[model_set], edgecolor='none', alpha=0.15, zorder=10)\n",
    "    p = ax.plot(x, y_Q50, color=colors[model_set])\n",
    "    p_all.append(p[0])\n",
    "    \n",
    "#     #Calculate slope of median\n",
    "#     x_reg = x[~np.isnan(y_Q50)]\n",
    "#     y_reg = y_Q50[~np.isnan(y_Q50)]\n",
    "#     regr  = linregress(x_reg, y_reg)\n",
    "    \n",
    "#     #Show slope in figures\n",
    "#     text = r'$\\frac{\\partial \\mathrm{EMT}}{\\partial \\mathrm{GMT}}$' + ' = ' + '{:.2f}'.format(regr.slope) + ' °C/°C'\n",
    "#     ax.text(x_text[ii], y_text[ii], text, fontsize=14, color=colors[model_set])\n",
    "    \n",
    "    #Print warming in CMIP models at 3°C European warming\n",
    "    Q25 = y_plot[model_set + '_Q25']\n",
    "    Q50 = y_plot[model_set + '_Q50']\n",
    "    Q75 = y_plot[model_set + '_Q75']\n",
    "    print('dGMT(dEMT=3°C) in ' + model_set , end=': ')\n",
    "    print(np.round(x[np.nanargmin(np.abs(Q50 - 3))], 2), end = ' (')\n",
    "    print(np.round(x[np.nanargmin(np.abs(Q75 - 3))], 2), end=' to ')\n",
    "    print(np.round(x[np.nanargmin(np.abs(Q25 - 3))], 2), end=', IQR)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "#Plot one-to-one line\n",
    "ax.plot([-1, 6], [-1, 6], linestyle='--', color='gray', zorder=5)\n",
    "\n",
    "#Limits, labels, and ticks\n",
    "xlims = [0, 4]\n",
    "ylims = [0, 5]\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.set_xticks(np.arange(0, 5))\n",
    "ax.set_xlabel('$\\Delta$GSAT / °C', fontsize=20, labelpad=10)\n",
    "ax.set_ylabel('$\\Delta$ESAT / °C', fontsize=20, labelpad=10)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "#Legend\n",
    "ax.legend(p_all, list(models_set.keys()), frameon=False, loc=2, fontsize=14)\n",
    "\n",
    "#Change size of lower axes\n",
    "pos = ax.get_position()\n",
    "pos.x0 = pos.x0 + 0.10\n",
    "pos.x1 = pos.x1 - 0.10\n",
    "ax.set_position(pos)\n",
    "\n",
    "#Write letter\n",
    "ax.text(xlims[0] + 0.02 * np.diff(xlims), ylims[0] + 1.03 * np.diff(ylims), '(b)', va='bottom', ha='left', fontweight='bold', fontsize=14)\n",
    "\n",
    "#Save figure\n",
    "fig.savefig(dir_fig + 'Fig2_ESAT_GSAT.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f5e60",
   "metadata": {},
   "source": [
    "## Export data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define names for output\n",
    "T_out = dict()\n",
    "T_out['GMT'] = 'GSAT'\n",
    "T_out['EMT'] = 'ESAT'\n",
    "\n",
    "#Define output file name\n",
    "fname_out = dir_repo + 'Data_Fig2_timeseries-GSAT-ESAT_EURO-CORDEX_CMIP5_CMIP6_1971-2100_RCP85_SSP585.xlsx'\n",
    "if os.path.exists(fname_out):  os.remove(fname_out)\n",
    "\n",
    "#Create excel file\n",
    "with pd.ExcelWriter(fname_out, mode=\"w\") as writer:\n",
    "\n",
    "    #Loop over model sets\n",
    "    for model_set in models_set:\n",
    "\n",
    "        #Loop over GSAT & EMT\n",
    "        for T_sel in ['GMT', 'EMT']:\n",
    "\n",
    "            #Skip non-existing data for EURO-CORDEX\n",
    "            if model_set=='EURO-CORDEX' and T_sel=='GMT':\n",
    "                continue\n",
    "\n",
    "            #Select data\n",
    "            data = data_coll_out[T_sel + '_' + model_set]\n",
    "\n",
    "            #Select data between 1971-2100\n",
    "            data = data.loc[slice(1971, 2100)]\n",
    "            \n",
    "            #Add unit\n",
    "            data.index = data.index.rename('unit: K')\n",
    "            data.columns = data.columns.rename('')\n",
    "\n",
    "            #Save in file\n",
    "            data.to_excel(writer, sheet_name=f'{T_sel} {model_set}', float_format=\"%.2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3d769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
