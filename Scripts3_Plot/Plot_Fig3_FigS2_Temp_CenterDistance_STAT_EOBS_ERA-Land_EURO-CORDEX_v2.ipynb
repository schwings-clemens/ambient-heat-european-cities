{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import mplotutils as mpu\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main path\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "\n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_CORDEX  = f'{path_main}Data/EURO-CORDEX/JJA/'\n",
    "dir_EOBS    = f'{path_main}Data/EOBS/JJA/'\n",
    "dir_ERA     = f'{path_main}Data/ERA5-Land/JJA/'\n",
    "dir_STA     = f'{path_main}Data/Stations/JJA/'\n",
    "dir_GSOD    = f'{path_main}Data/GSOD/JJA/'\n",
    "dir_fig     = f'{path_main}Figures/Paper_v2/'\n",
    "if not os.path.exists(dir_fig): os.mkdir(dir_fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Lisbon', 'Madrid', 'Barcelona', 'Rome', 'Athens', 'Istanbul', 'Sofia', 'Bucharest', 'Belgrade', 'Zagreb',\n",
    "          'Milan', 'Budapest', 'Munich', 'Vienna', 'Prague', 'Paris', 'Brussels', 'Amsterdam', 'London', 'Dublin',\n",
    "          'Hamburg', 'Copenhagen', 'Berlin', 'Warsaw', 'Kharkiv', 'Kyiv', 'Minsk', 'Vilnius', 'Riga', 'Moscow',\n",
    "          'NizhnyNovgorod', 'Kazan', 'SaintPetersburg', 'Helsinki', 'Stockholm', 'Oslo']\n",
    "\n",
    "#Define scenarios and variables\n",
    "vars_ERA5 = ['mintemp2m', 'maxtemp2m']\n",
    "vars_STAT = ['TN', 'TX']\n",
    "vars_EOBS = ['tn', 'tx']\n",
    "var_names = ['tasmin', 'tasmax']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Define scenarios and variables\n",
    "RCP = 'rcp85'\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models.append(eval(line[:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_data(data, city, city_coords, var_name, data_source):\n",
    "    \n",
    "    #Convert longitude from [0, 360] to [-180, 180]\n",
    "    if 'longitude' in data.coords:  lat_name, lon_name = 'latitude', 'longitude'\n",
    "    elif 'lon' in data.coords:      lat_name, lon_name = 'lat', 'lon'\n",
    "    if data[lon_name].max()>180:\n",
    "        data[lon_name] = data[lon_name].where(data[lon_name]<180, ((data[lon_name] + 180) % 360) - 180)\n",
    "\n",
    "    #Get lat and lon of city\n",
    "    lat_sel, lon_sel = city_coords[city]\n",
    "    \n",
    "    #Find grid point closest to city\n",
    "    if data_source in ['EOBS', 'ERA5-Land']:\n",
    "        \n",
    "        #Find grid point closest to city\n",
    "        lat_city = np.argmin(np.abs(data[lat_name].values - lat_sel))\n",
    "        lon_city = np.argmin(np.abs(data[lon_name].values - lon_sel))\n",
    "\n",
    "        #Select NxN box around grid point\n",
    "        N = 11\n",
    "        N_half = int((N-1)/2)\n",
    "        lat_rng  = slice(lat_city - N_half, lat_city + N_half + 1)\n",
    "        lon_rng  = slice(lon_city - N_half, lon_city + N_half + 1)\n",
    "        data_sel = data.isel(latitude=lat_rng, longitude=lon_rng)        \n",
    "        \n",
    "    elif data_source=='EURO-CORDEX':\n",
    "\n",
    "        #Find grid point closest to city\n",
    "        loc_city = (np.abs(data[lon_name] - lon_sel)) + (np.abs(data[lat_name] - lat_sel))\n",
    "        ind_city = np.unravel_index(np.argmin(loc_city.values), loc_city.shape)\n",
    "\n",
    "        #Select NxN box around grid point\n",
    "        N = 9\n",
    "        N1 = int(N/2 - 0.5)\n",
    "        N2 = int(N/2 + 0.5)\n",
    "        lat_rng  = slice(ind_city[0] - N1, ind_city[0] + N2)\n",
    "        lon_rng  = slice(ind_city[1] - N1, ind_city[1] + N2)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        sys.exit('Data source not defined')\n",
    "\n",
    "    if 'rlat' in data.dims:   data_city = data.isel(rlat=lat_rng, rlon=lon_rng)\n",
    "    elif 'x' in data.dims:    data_city = data.isel(y=lat_rng, x=lon_rng)\n",
    "    else:                     data_city = data.isel(latitude=lat_rng, longitude=lon_rng)\n",
    "\n",
    "    #Calculate distance from city center\n",
    "    dist = np.sqrt((data_city[lat_name] - lat_sel)**2 + (data_city[lon_name] - lon_sel)**2)                \n",
    "\n",
    "    #Convert K to Â°C\n",
    "    if data_city[var_name].mean()>200:\n",
    "        data_city = data_city - 273.15    \n",
    "\n",
    "    return(data_city, dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_CORD = dict()\n",
    "data_EOBS = dict()\n",
    "data_ERA5 = dict()\n",
    "data_STAT = dict()\n",
    "data_GSOD = dict()\n",
    "\n",
    "\n",
    "## EURO-CORDEX ##\n",
    "        \n",
    "data_source = 'EURO-CORDEX'\n",
    "print(\"Preparing \" + data_source)\n",
    "    \n",
    "#Loop over variables\n",
    "for variab in var_names:\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #Get file name\n",
    "        dir_variab = dir_CORDEX + variab + '/'\n",
    "        \n",
    "        for model in all_models:\n",
    "            \n",
    "            #Get file name\n",
    "            fnames = [file for file in os.listdir(dir_variab) if variab in file and model[0] in file and model[1] in file and model[2] in file and RCP in file]\n",
    "            fnames = [file for file in fnames if variab + '_JJA-mean' in file and '1981-2010' in file]\n",
    "            fnames = [file for file in fnames if 'masked-sea' in file]\n",
    "            \n",
    "            if len(fnames)!=1:\n",
    "                sys.exit('Filename not unique')                \n",
    "\n",
    "            #Read data\n",
    "            data = xr.open_dataset(dir_variab + fnames[0])\n",
    "            \n",
    "            if (variab in ['tasmin', 'tasmax']) and (data[variab].mean().values.item()<200):\n",
    "                print(model)\n",
    "                print(data[variab].mean().values.item())\n",
    "\n",
    "            #Get data around city\n",
    "            data_city, dist = get_city_data(data, city, city_coords, variab, data_source)\n",
    "            \n",
    "            if data_city[variab].mean().values.item()<0:\n",
    "                print(model)\n",
    "                print(variab)\n",
    "                print(data_city[variab].mean().values.item())            \n",
    "            \n",
    "            #Save in dict\n",
    "            data_CORD['data_' + city + '_' + \"_\".join(model) + '_' + variab] = data_city\n",
    "            data_CORD['dist_' + city + '_' + \"_\".join(model) + '_' + variab] = dist\n",
    "\n",
    "            \n",
    "## ERA5-Land ##\n",
    "\n",
    "data_source = 'ERA5-Land'\n",
    "print(\"Preparing \" + data_source)\n",
    "\n",
    "#Loop over variables\n",
    "for variab, var_out in zip(vars_ERA5, var_names):\n",
    "    \n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #Read data\n",
    "        fname = dir_ERA + variab + '/' + variab + '_JJA-mean_ERA5-Land_day_1981-2010.nc'\n",
    "        data = xr.open_dataset(fname)\n",
    "\n",
    "        #Get data around city\n",
    "        data_city, dist = get_city_data(data, city, city_coords, variab, data_source)\n",
    "        \n",
    "        #Rename\n",
    "        data_city = data_city.rename({variab: var_out})\n",
    "        \n",
    "        #Save in dict\n",
    "        data_ERA5['data_' + city + '_' + var_out] = data_city\n",
    "        data_ERA5['dist_' + city + '_' + var_out] = dist\n",
    "\n",
    "        \n",
    "## EOBS ##\n",
    "\n",
    "data_source = 'EOBS'\n",
    "print(\"Preparing \" + data_source)\n",
    "\n",
    "\n",
    "#Loop over variables\n",
    "for variab, var_out in zip(vars_EOBS, var_names):\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #Read data\n",
    "        fname = dir_EOBS + variab + '/' + variab + '_JJA-mean_EOBS_day_1981-2010.nc'\n",
    "        data = xr.open_dataset(fname)\n",
    "\n",
    "        #Get data around city\n",
    "        data_city, dist = get_city_data(data, city, city_coords, variab, data_source)\n",
    "        \n",
    "        #Rename\n",
    "        data_city = data_city.rename({variab: var_out})\n",
    "        \n",
    "        #Save in dict\n",
    "        data_EOBS['data_' + city + '_' + var_out] = data_city\n",
    "        data_EOBS['dist_' + city + '_' + var_out] = dist\n",
    "        \n",
    "        \n",
    "## STATIONS ##\n",
    "\n",
    "print(\"Preparing STATIONS\")\n",
    "\n",
    "#Loop over variables\n",
    "for var_name, var_out in zip(vars_STAT, var_names):\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #File name\n",
    "        fname_STA = dir_STA + var_name + '_Stations_' + city + \".csv\"\n",
    "        fname_GSOD = dir_GSOD + var_name + '_GSOD-stations_' + city + \".csv\"\n",
    "        \n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]        \n",
    "        \n",
    "        #Check if station data exist\n",
    "        if os.path.exists(fname_STA):\n",
    "            \n",
    "            #Read station data\n",
    "            data_STA = pd.read_csv(fname_STA)\n",
    "            \n",
    "            #Get distance to city center\n",
    "            latS, lonS = data_STA.iloc[:,0], data_STA.iloc[:,1]\n",
    "            distS = np.sqrt((latS - lat_sel)**2 + (lonS - lon_sel)**2)   \n",
    "\n",
    "            #Rename\n",
    "            data_STA = data_STA.rename({var_name: var_out}, axis='columns')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('No station data for ' + city)\n",
    "            data_STA = []\n",
    "            distS = []\n",
    "            \n",
    "        #Check if station data exist\n",
    "        if os.path.exists(fname_GSOD):\n",
    "            \n",
    "            #Read station data\n",
    "            data_GS = pd.read_csv(fname_GSOD)\n",
    "\n",
    "            #Get distance to city center\n",
    "            latG, lonG = data_GS.iloc[:,0], data_GS.iloc[:,1]\n",
    "            distG = np.sqrt((latG - lat_sel)**2 + (lonG - lon_sel)**2)   \n",
    "\n",
    "            #Rename\n",
    "            data_GS = data_GS.rename({var_name: var_out}, axis='columns')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('No station data for ' + city)\n",
    "            data_STA = []\n",
    "            distS = []\n",
    "                \n",
    "        \n",
    "                \n",
    "        #Save in dict\n",
    "        data_STAT['data_' + city + '_' + var_out] = data_STA\n",
    "        data_STAT['dist_' + city + '_' + var_out] = distS\n",
    "        \n",
    "        \n",
    "        \n",
    "## GSOD stations ##\n",
    "            \n",
    "print(\"Preparing GSOD\")\n",
    "    \n",
    "#Loop over variables\n",
    "for var_name, var_out in zip(vars_STAT, var_names):\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #File name\n",
    "        fname_GSOD = dir_GSOD + var_name + '_GSOD-stations_' + city + \".csv\"\n",
    "        \n",
    "        #Check if GSOD station data exist\n",
    "        if os.path.exists(fname_GSOD):\n",
    "            \n",
    "            #Read GSOD station data\n",
    "            data_GS = pd.read_csv(fname_GSOD)\n",
    "\n",
    "            #Get lat and lon of city\n",
    "            lat_sel, lon_sel = city_coords[city]\n",
    "\n",
    "            #Get distance to city center\n",
    "            latS, lonS = data_GS.iloc[:,0], data_GS.iloc[:,1]\n",
    "            distS = np.sqrt((latS - lat_sel)**2 + (lonS - lon_sel)**2)   \n",
    "\n",
    "            #Rename\n",
    "            data_GS = data_GS.rename({var_name: var_out}, axis='columns')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('No GSOD station data for ' + city)\n",
    "            data_GS = []\n",
    "            distS = []\n",
    "        \n",
    "        #Save in dict\n",
    "        data_GSOD['data_' + city + '_' + var_out] = data_GS\n",
    "        data_GSOD['dist_' + city + '_' + var_out] = distS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot T as function of city center distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vars_plot   = ['tasmax', 'tasmin']#, 'huss']\n",
    "vars_legend = ['TX', 'TN']#, 'q']\n",
    "\n",
    "#Define method for interpolation\n",
    "met_scatter = 'quantiles-filling'\n",
    "# met_scatter = 'gaussian-kde'\n",
    "\n",
    "#Loop over variables\n",
    "for variab, var_leg in zip(vars_plot, vars_legend):\n",
    "    \n",
    "    #Create figures\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(14, 10))     \n",
    "    axes = axes.flatten()\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0.2)\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(sorted(cities)):\n",
    "\n",
    "        #Get axes\n",
    "        ax = axes[i1]\n",
    "\n",
    "        \n",
    "        #### EURO-CORDEX ####\n",
    "        \n",
    "        CORD_x = []\n",
    "        CORD_y = []\n",
    "        for model in all_models:\n",
    "            \n",
    "            #Get data\n",
    "            x = data_CORD['dist_' + city + '_' + \"_\".join(model) + '_' + variab].values.flatten()\n",
    "            y = data_CORD['data_' + city + '_' + \"_\".join(model) + '_' + variab][variab].values.flatten()\n",
    "            \n",
    "            #Collect data to define limits\n",
    "            CORD_x.append(x)\n",
    "            CORD_y.append(y)\n",
    "    \n",
    "        x  = np.array(CORD_x).flatten()\n",
    "        y  = np.array(CORD_y).flatten()\n",
    "        x = x[~np.isnan(y)]\n",
    "        y = y[~np.isnan(y)]\n",
    "        \n",
    "        if met_scatter=='gaussian-kde':\n",
    "\n",
    "            xy = np.vstack([x,y])\n",
    "\n",
    "            x1 = np.linspace(np.min(x), np.max(x), 100)\n",
    "            y1 = np.linspace(np.min(y), np.max(y), 100)\n",
    "            xy_mesh = np.array(np.meshgrid(x1, y1))\n",
    "            x1 = xy_mesh[0,:,:].flatten()\n",
    "            y1 = xy_mesh[1,:,:].flatten()\n",
    "\n",
    "            # Calculate the point density\n",
    "            z1 = stats.gaussian_kde(xy)([x1, y1])\n",
    "\n",
    "\n",
    "            # Sort the points by density, so that the densest points are plotted last\n",
    "            idx = z1.argsort()\n",
    "            x1, y1, z1 = x1[idx], y1[idx], z1[idx]\n",
    "\n",
    "            ax.scatter(x1, y1, c=z1, s=4**2, cmap='Greys')\n",
    "            \n",
    "        elif met_scatter=='quantiles-filling':\n",
    "\n",
    "            alphas = [0.03, 0.15, 0.3, 0.15, 0.03]\n",
    "\n",
    "            \n",
    "            bins      = np.linspace(x.min(), x.max(), 10)\n",
    "            quantiles = [0.01, 0.1, 0.25, 0.75, 0.9, 0.99, 0.5]\n",
    "            # quantiles = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "\n",
    "            y_q = np.empty((len(bins)-1, len(quantiles))) * np.NaN\n",
    "            x_q = []\n",
    "            for iq1, (b1, b2) in enumerate(zip(bins[0:-1], bins[1::])):\n",
    "\n",
    "                y_sel = y[(x>=b1) & (x<b2)]\n",
    "                x_q.append(np.mean([b1, b2]))\n",
    "\n",
    "                for iq2, q in enumerate(quantiles):\n",
    "\n",
    "                    y_q[iq1, iq2] = np.quantile(y_sel, q)\n",
    "\n",
    "            \n",
    "            x_q = np.append(np.min(x), x_q)\n",
    "            y0 = y_q[0,:]\n",
    "            y0 = np.transpose(np.expand_dims(y0, 1))\n",
    "            y_q = np.concatenate((y0, y_q), axis=0)\n",
    "                    \n",
    "            for i2, (q, alpha) in enumerate(zip(quantiles[0:-2], alphas)):\n",
    "                ax.fill_between(x_q, y_q[:,i2], y_q[:,i2+1], color='k', alpha=alpha, edgecolor='none')\n",
    "\n",
    "            p_CORD = ax.plot(x_q, y_q[:,-1], 'k') \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "        #### ERA5 ####\n",
    "            \n",
    "        #Get data\n",
    "        ERA5_plot_x = data_ERA5['dist_' + city + '_' + variab]\n",
    "        ERA5_plot_y = data_ERA5['data_' + city + '_' + variab]\n",
    "\n",
    "        #Plot ERA5\n",
    "        ax.scatter(ERA5_plot_x, ERA5_plot_y[variab], marker='o', s=4**2, color='lightgray',\n",
    "                   edgecolor='darkred', linewidth=0.5, alpha=1, zorder=10)\n",
    "                \n",
    "\n",
    "\n",
    "        #### EOBS ####\n",
    "\n",
    "        if variab in ['tasmin', 'tasmax']:\n",
    "            \n",
    "            #Get data\n",
    "            EOBS_plot_x = data_EOBS['dist_' + city + '_' + variab]\n",
    "            EOBS_plot_y = data_EOBS['data_' + city + '_' + variab]\n",
    "\n",
    "            #Plot EOBS\n",
    "            ax.scatter(EOBS_plot_x, EOBS_plot_y[variab], marker='o', s=4**2, color='lightgray',\n",
    "                       edgecolor='tab:blue', linewidth=0.5, alpha=1, zorder=15)\n",
    "\n",
    "\n",
    "        #### STATIONS ####\n",
    "            \n",
    "        if variab in ['tasmin', 'tasmax']:\n",
    "            \n",
    "            #Get data\n",
    "            STAT_plot_x = data_STAT['dist_' + city + '_' + variab]\n",
    "            STAT_plot_y = data_STAT['data_' + city + '_' + variab]\n",
    "\n",
    "            #Plot stations\n",
    "            if type(STAT_plot_y) is not list:\n",
    "                colors = np.empty(len(STAT_plot_x), dtype='object')\n",
    "                colors[STAT_plot_y['flag']==1] = 'tab:blue'\n",
    "                colors[STAT_plot_y['flag']==2] = 'tab:blue'#'lightblue'\n",
    "                ax.scatter(STAT_plot_x, STAT_plot_y[variab], marker='o', s=4**2, color=colors, \n",
    "                           edgecolor='tab:blue', linewidth=0.5, zorder=20)\n",
    "            \n",
    "            \n",
    "        #### GSOD STATIONS ####\n",
    "            \n",
    "        if variab in ['tasmin', 'tasmax']:\n",
    "            \n",
    "            #Get data\n",
    "            GSOD_plot_x = data_GSOD['dist_' + city + '_' + variab]\n",
    "            GSOD_plot_y = data_GSOD['data_' + city + '_' + variab]\n",
    "\n",
    "            #Plot stations\n",
    "            if type(GSOD_plot_y) is not list:\n",
    "                colors = np.empty(len(GSOD_plot_x), dtype='object')\n",
    "                colors[GSOD_plot_y['flag']==1] = 'tab:blue'\n",
    "                colors[GSOD_plot_y['flag']==2] = 'tab:blue'#'lightblue'\n",
    "                ax.scatter(GSOD_plot_x, GSOD_plot_y[variab], marker='o', s=4**2, color=colors, \n",
    "                           edgecolor='tab:blue', linewidth=0.5, zorder=20)\n",
    "            \n",
    "        #x-ticks and labels\n",
    "        if i1<30:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel('Center distance [Â°]')\n",
    "        if np.mod(i1,6)==0:\n",
    "            ax.set_ylabel(var_leg + ' [Â°C]')\n",
    "            \n",
    "        #Set limits\n",
    "        ylim1 = np.quantile(y, 0.01)\n",
    "        ylim2 = np.quantile(y, 0.99)\n",
    "        ylim_d = ylim2 - ylim1\n",
    "        ylim1 = ylim1 - 0.1 * ylim_d\n",
    "        ylim2 = ylim2 + 0.1 * ylim_d\n",
    "\n",
    "        lims_ERA5 = ERA5_plot_y.where(ERA5_plot_x<0.51)\n",
    "        lims_ERA5 = lims_ERA5[variab].values.flatten()\n",
    "        if variab in ['tasmin', 'tasmax']:\n",
    "            lims_EOBS = EOBS_plot_y.where(EOBS_plot_x<0.51)\n",
    "            lims_EOBS = lims_EOBS[variab].values.flatten()\n",
    "            if len(GSOD_plot_y)!=0:  lims_GSOD = np.array(GSOD_plot_y[(GSOD_plot_x<0.51).values][variab])\n",
    "            else:                    lims_GSOD = [np.NaN]\n",
    "            if len(STAT_plot_y)!=0:  lims_STAT = np.array(STAT_plot_y[(STAT_plot_x<0.51).values][variab])\n",
    "            else:                    lims_STAT = [np.NaN]\n",
    "            lims_conc = np.concatenate((lims_ERA5, lims_EOBS, lims_GSOD, lims_STAT))\n",
    "        else:\n",
    "            lims_conc = lims_ERA5\n",
    "            \n",
    "        #Set limits\n",
    "        ylim1 = np.min([np.nanmin(lims_conc) - 0.05*(ylim2 - ylim1), ylim1])\n",
    "        ylim2 = np.max([np.nanmax(lims_conc) + 0.05*(ylim2 - ylim1), ylim2])\n",
    "        ax.set_ylim([ylim1, ylim2])\n",
    "        ax.set_xlim([-0.01, 0.5])\n",
    "    \n",
    "        if variab!='huss':\n",
    "            yl = np.diff(ax.get_ylim())\n",
    "            if yl<6:\n",
    "                yticks = np.arange(np.ceil(ylim1), np.ceil(ylim1) + 7, 2)\n",
    "            elif (yl>=6) & (yl<9):\n",
    "                yticks = np.arange(np.ceil(ylim1)+1, np.ceil(ylim1) + 10, 2)\n",
    "\n",
    "            elif (yl>=9) & (yl<12):\n",
    "                yticks = np.arange(np.ceil(ylim1), np.ceil(ylim1) + 12, 3)\n",
    "            elif (yl>=12) & (yl<16):\n",
    "                yticks = np.arange(np.ceil(ylim1), np.ceil(ylim1) + 16, 4)\n",
    "\n",
    "            else:\n",
    "                yticks = np.arange(np.ceil(ylim1), np.ceil(ylim1) + yl + 5, 5)\n",
    "\n",
    "            ax.set_yticks(yticks)\n",
    "            \n",
    "        #Set limits (to be sure)\n",
    "        ax.set_ylim([ylim1, ylim2])\n",
    "\n",
    "        #Write city names\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        x_txt = xlim[0] + 0.50 * np.diff(xlim)\n",
    "        y_txt = ylim[1] - 0.03 * np.diff(ylim)\n",
    "\n",
    "        if city=='NizhnyNovgorod':     city_out = 'Nizhny Novgorod'\n",
    "        elif city=='SaintPetersburg':  city_out = 'Saint Petersburg'\n",
    "        else:                          city_out = city\n",
    "                \n",
    "        #Write city name\n",
    "        ax.text(x_txt, y_txt, city_out, fontsize=8, ha='center', va='top', zorder=50, bbox=dict(facecolor='white', edgecolor='none', pad=0.5, alpha=0.5))\n",
    "        \n",
    "        #Define direction of ticks\n",
    "        ax.tick_params(direction='in')\n",
    "        \n",
    "        #Put spines in front\n",
    "        for k, spine in ax.spines.items():\n",
    "            spine.set_zorder(30)\n",
    "        \n",
    "    #Create helper plots for legend\n",
    "    p_help1 = ax.scatter(4, 15, marker='o', s=7**2, color='lightgray', edgecolor='darkred')\n",
    "    p_help2 = ax.scatter(4, 15, marker='o', s=7**2, color='lightgray', edgecolor='tab:blue')\n",
    "    p_help3 = ax.scatter(4, 15, marker='o', s=7**2, color='tab:blue', edgecolor='tab:blue')\n",
    "    \n",
    "    #Save figure\n",
    "    if variab=='tasmax':\n",
    "        fig_name = 'Fig3_'\n",
    "    elif variab=='tasmin':\n",
    "        fig_name = 'FigS2_'\n",
    "    else:\n",
    "        fig_name = 'FigS_'\n",
    "        \n",
    "    #Legend\n",
    "    ax.legend([p_CORD[0], p_help1, p_help2, p_help3], ['EURO-CORDEX', 'ERA5-Land', 'E-OBS', 'Station data'],\n",
    "              frameon=False, ncol=5, fontsize=12, loc=9, bbox_to_anchor=(-2.5, -0.5), scatteryoffsets=[0.6])\n",
    "        \n",
    "    #Save figure\n",
    "    fig.savefig(dir_fig + fig_name + 'Validation_EURO-CORDEX_' + variab + '-JJA_1981-2010.png', dpi=200, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Select whether to include EOBS or not\n",
    "EOBS_incl = 1\n",
    "\n",
    "#Select variables to plot\n",
    "vars_plot  = ['tasmax']#'tasmin', \n",
    "vars_legend = ['TX']#'TN', \n",
    "\n",
    "#Loop over variables\n",
    "for variab, var_leg in zip(vars_plot, vars_legend):\n",
    "    \n",
    "    #Create figures\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(14, 10))     \n",
    "    axes = axes.flatten()\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(sorted(cities)):\n",
    "\n",
    "        #Get axes\n",
    "        ax = axes[i1]\n",
    "\n",
    "        \n",
    "        #### EURO-CORDEX ####\n",
    "        \n",
    "        #EURO-CORDEX\n",
    "        CORD_all = np.empty(0)\n",
    "        for model in all_models:\n",
    "            \n",
    "            #Get data\n",
    "            CORD_dist = data_CORD['dist_' + city + '_' + \"_\".join(model) + '_' + variab]\n",
    "            CORD_vals = data_CORD['data_' + city + '_' + \"_\".join(model) + '_' + variab]\n",
    "            \n",
    "            #Get data in 0.5Â° radius \n",
    "            CORD_coll = CORD_vals.where(CORD_dist<0.5)['tasmax'].values.flatten()\n",
    "            CORD_coll = CORD_coll[~np.isnan(CORD_coll)]\n",
    "            \n",
    "            #Collect data in one array\n",
    "            CORD_all = np.concatenate((CORD_all, CORD_coll))\n",
    "            \n",
    "            #Plot distribution\n",
    "            p1 = pd.DataFrame(CORD_coll).plot.kde(ax=ax, color='k', alpha=0.1)        \n",
    "\n",
    "        #Collect median\n",
    "        CORD_med = np.median(CORD_all)\n",
    "        \n",
    "#         #Get y-values of median\n",
    "#         CORD_med_y = np.empty(0)\n",
    "#         for line in p1.get_lines():\n",
    "#             x1, y1 = line.get_data()\n",
    "#             CORD_med_line = y1[np.argmin(np.abs(x1 - CORD_med))]\n",
    "#             CORD_med_y = np.concatenate((CORD_med_y, [CORD_med_line]))\n",
    "            \n",
    "        \n",
    "        #### ERA5 ####\n",
    "    \n",
    "        #Get data\n",
    "        ERA5_dist = data_ERA5['dist_' + city + '_' + variab]\n",
    "        ERA5_vals = data_ERA5['data_' + city + '_' + variab]\n",
    "\n",
    "        #Get data in 0.5Â° radius \n",
    "        ERA5_coll = ERA5_vals.where(ERA5_dist<0.5)['tasmax'].values.flatten()\n",
    "        ERA5_coll = ERA5_coll[~np.isnan(ERA5_coll)]\n",
    "\n",
    "        #Collect median\n",
    "        ERA5_med = np.median(ERA5_coll)\n",
    "        \n",
    "        #Plot distribution\n",
    "        p2 = pd.DataFrame(ERA5_coll).plot.kde(ax=ax, linestyle='-', color='darkred')\n",
    "        \n",
    "#         #Get y-values of median\n",
    "#         x2, y2 = p2.get_lines()[-1].get_data()\n",
    "#         ERA5_med_y = y2[np.argmin(np.abs(x2 - ERA5_med))]\n",
    "        \n",
    "    \n",
    "        #### EOBS ####\n",
    "\n",
    "        if EOBS_incl==1:\n",
    "            \n",
    "            EOBS_dist = data_EOBS['dist_' + city + '_' + variab]\n",
    "            EOBS_vals = data_EOBS['data_' + city + '_' + variab]\n",
    "\n",
    "            EOBS_coll = EOBS_vals.where(EOBS_dist<0.5)['tasmax'].values.flatten()\n",
    "            EOBS_coll = EOBS_coll[~np.isnan(EOBS_coll)]\n",
    "\n",
    "            #Collect median\n",
    "            EOBS_med = np.median(EOBS_coll)\n",
    "\n",
    "            #Plot distribution\n",
    "            if len(EOBS_coll)!=0:\n",
    "                p2 = pd.DataFrame(EOBS_coll).plot.kde(ax=ax, linestyle='-', color='tab:blue')\n",
    "\n",
    "#             #Get y-values of median\n",
    "#             x2, y2 = p2.get_lines()[0].get_data()\n",
    "#             EOBS_med_y = y2[np.argmin(np.abs(x2 - EOBS_med))]\n",
    "\n",
    "        #Plot medians\n",
    "        ylims = ax.get_ylim()\n",
    "        med_y = ylims[0] + 0.1 * np.diff(ylims)\n",
    "        ax.plot(CORD_med, 0, marker='o', markersize=5, linestyle='none', color='k')\n",
    "        ax.plot(ERA5_med, 0, marker='o', markersize=5, linestyle='none', color='darkred')\n",
    "        if EOBS_incl==1:\n",
    "            ax.plot(EOBS_med, 0, marker='o', markersize=5, linestyle='none', color='tab:blue')\n",
    "            \n",
    "        #x-ticks and labels\n",
    "        ax.set_yticklabels([])\n",
    "        if i1>=30:\n",
    "            ax.set_xlabel('TX / Â°C')\n",
    "        if np.mod(i1,6)==0:\n",
    "            ax.set_ylabel('Density')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "            \n",
    "        #Set limits\n",
    "        xlim1 = np.quantile(CORD_all, 0.01)\n",
    "        xlim2 = np.quantile(CORD_all, 0.99)\n",
    "        xlim_d = xlim2 - xlim1\n",
    "        xlim1 = xlim1 - 0.1 * xlim_d\n",
    "        xlim2 = xlim2 + 0.1 * xlim_d\n",
    "        #ax.set_ylim([ylim1, ylim2])\n",
    "        ax.set_xlim([xlim1, xlim2])\n",
    "        \n",
    "        #Set x-ticks\n",
    "        ax.set_xticks(np.arange(np.ceil(xlim1), xlim2, 2))        \n",
    "        \n",
    "        if city=='NizhnyNovgorod':     city_out = 'Nizhny Novgorod'\n",
    "        elif city=='SaintPetersburg':  city_out = 'Saint Petersburg'\n",
    "        else:                          city_out = city        \n",
    "        \n",
    "        #Write cities\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        x_txt = xlim[0] + 0.05 * np.diff(xlim)\n",
    "        y_txt = ylim[1] - 0.05 * np.diff(ylim)\n",
    "        ax.text(x_txt, y_txt, city_out, fontsize=8, ha='left', va='top') \n",
    "        \n",
    "        ax.tick_params(direction='in')\n",
    "        \n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    #Helper plot for legend\n",
    "    p_help = ax.plot([-200, -180], [0, 0], color='k', alpha=0.5)\n",
    "    ax.set_xlim([xlim1, xlim2])\n",
    "    \n",
    "    #Prepare legend and output string\n",
    "    if EOBS_incl==1: \n",
    "        p_leg    = [p_help[0], p2.get_lines()[-4], p2.get_lines()[-6], p2.get_lines()[-3], p2.get_lines()[-5], p2.get_lines()[-2]]\n",
    "        txt_leg  = ['EURO-CORDEX models', 'EURO-CORDEX median', 'ERA5-Land', 'ERA5-Land median', 'E-OBS', 'E-OBS median']\n",
    "        ncol     = 3\n",
    "        EOBS_str = '_vEOBS'\n",
    "    else:\n",
    "        p_leg    = [p_help[0], p2.get_lines()[-3], p2.get_lines()[-4], p2.get_lines()[-2]]\n",
    "        txt_leg  = ['EURO-CORDEX models', 'EURO-CORDEX median', 'ERA5-Land', 'ERA5-Land median']\n",
    "        ncol     = 2\n",
    "        EOBS_str = ''\n",
    "        \n",
    "    #Legend        \n",
    "    ax.legend(p_leg, txt_leg, ncol=ncol, fontsize=14, loc=8, bbox_to_anchor=(-2.2, -1.4), frameon=False)\n",
    "    \n",
    "    #Save figure\n",
    "    fig.savefig(dir_fig + 'FigS_Distribution_' + variab + '_1981-2010_JJA' + EOBS_str + '.png', dpi=200, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loop over variables\n",
    "for varf, varn, varS, varo in zip(vars_ERA5[0:2], vars_ERA5[0:2], vars_STAT, var_names[0:2]):\n",
    "    \n",
    "    #Create figures\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(14, 10), subplot_kw=dict(projection=ccrs.PlateCarree()))        \n",
    "    axes = axes.flatten()\n",
    "    plt.subplots_adjust(hspace=0.25, wspace=0.1)\n",
    "\n",
    "    #Loop over models\n",
    "    for i1, city in enumerate(cities):\n",
    "\n",
    "        #Get axes\n",
    "        ax = axes[i1]\n",
    "        ax.spines['geo'].set_edgecolor([0.8, 0.8, 0.8])\n",
    "\n",
    "        #Get file name\n",
    "        dir_variab = dir_ERA + varf + '/'\n",
    "        fname = [file for file in os.listdir(dir_variab) if varf in file]\n",
    "        if len(fname)==0:\n",
    "            sys.exit('Filename not unique')                \n",
    "\n",
    "        #Read data\n",
    "        data = xr.open_dataset(dir_variab + fname[0])\n",
    "\n",
    "        #Read station data\n",
    "        fname_STA = dir_STA + varS + '_Stations_' + city + \".csv\"\n",
    "        if os.path.exists(fname_STA):\n",
    "            data_STA = pd.read_csv(fname_STA)\n",
    "            STA_exists = True\n",
    "        else:\n",
    "            STA_exists = False\n",
    "        \n",
    "        #Convert longitude from [0, 360] to [-180, 180]\n",
    "        if 'longitude' in data.coords:  lat_name, lon_name = 'latitude', 'longitude'\n",
    "        elif 'lon' in data.coords:      lat_name, lon_name = 'lat', 'lon'\n",
    "        if data[lon_name].max()>180:\n",
    "            data[lon_name] = data[lon_name].where(data[lon_name]<180, ((data[lon_name] + 180) % 360) - 180)\n",
    "\n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]\n",
    "        \n",
    "        #Find grid point closest to city\n",
    "        lat_city = np.argmin(np.abs(data[lat_name].values - lat_sel))\n",
    "        lon_city = np.argmin(np.abs(data[lon_name].values - lon_sel))\n",
    "        \n",
    "        #Select NxN box around grid point\n",
    "        N = 11\n",
    "        N_half = int((N-1)/2)\n",
    "        lat_rng  = slice(lat_city - N_half, lat_city + N_half + 1)\n",
    "        lon_rng  = slice(lon_city - N_half, lon_city + N_half + 1)\n",
    "        data_sel = data.isel(latitude=lat_rng, longitude=lon_rng)        \n",
    "\n",
    "        #Convert K to Â°C\n",
    "        data_plot = data_sel - 273.15\n",
    "        \n",
    "        #Define min and max for colorbar\n",
    "        d1 = np.nanquantile(data_plot[varf].values, 0.05)\n",
    "        d2 = np.nanquantile(data_STA.iloc[:,2], 0.05)\n",
    "        vmin = np.min([d1, d2])\n",
    "        \n",
    "        d1 = np.nanquantile(data_plot[varf].values, 0.95)\n",
    "        d2 = np.nanquantile(data_STA.iloc[:,2], 0.95)\n",
    "        vmax = np.max([d1, d2])\n",
    "        \n",
    "        #Adjust coordinates\n",
    "        try:\n",
    "            LON, LAT = mpu.infer_interval_breaks(data_plot[lon_name], data_plot[lat_name])\n",
    "        except:\n",
    "            LON, LAT = data_plot[lon_name], data_plot[lat_name]\n",
    "\n",
    "        #Add coastlines and borders\n",
    "        ax.coastlines(resolution='50m', linewidth=1, color='#444444', zorder=5)                \n",
    "            \n",
    "        #Plot ERA5\n",
    "        hp = ax.pcolormesh(LON, LAT, data_plot[varn], vmin=vmin, vmax=vmax, cmap='RdBu_r', zorder=3)\n",
    "        \n",
    "        #Plot stations\n",
    "        if STA_exists:\n",
    "            ax.scatter(data_STA.iloc[:,1], data_STA.iloc[:,0], c=data_STA.iloc[:,2], transform=ccrs.PlateCarree(),\n",
    "                       edgecolor='k', vmin=vmin, vmax=vmax, cmap='RdBu_r', zorder=12)\n",
    "        \n",
    "        #Plot city center\n",
    "        ax.scatter(lon_sel, lat_sel, 50, transform=ccrs.PlateCarree(), color='k', marker='x', linewidth=2, zorder=10)\n",
    "\n",
    "        if city=='NizhnyNovgorod':     city_out = 'Nizhny Novgorod'\n",
    "        elif city=='SaintPetersburg':  city_out = 'Saint Petersburg'\n",
    "        else:                          city_out = city\n",
    "            \n",
    "        #Set extent and title\n",
    "        ax.set_extent([lon_sel - 0.6, lon_sel + 0.6, lat_sel - 0.5, lat_sel + 0.5])\n",
    "        ax.set_title(city_out)\n",
    "\n",
    "        #Colorbar\n",
    "        cbar = mpu.colorbar(hp, ax, orientation='vertical', extend='both', size=0.05, shrink=0.1, pad=0.05)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "        if np.mod(i1,6)==5:\n",
    "            cbar.set_label(varS + ' [Â°C]', fontsize=11)    \n",
    "    \n",
    "#     #Save figure\n",
    "#     fig.savefig(dir_fig + 'FigS_UHI_ERA5_stations_' + varo + '_' + str(N) + 'x' + str(N) + '_1981-2005_JJA.png', dpi=200, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
