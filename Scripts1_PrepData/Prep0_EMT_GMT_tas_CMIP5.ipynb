{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:   path_main  = file.read()\n",
    "with open('../path_CMIP5.txt', 'r') as file:  path_cmip5 = file.read()\n",
    "    \n",
    "dir_CMIP5   = path_cmip5\n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_out1    = f'{path_main}Data/CMIP5/EMT/'\n",
    "dir_out2    = f'{path_main}Data/CMIP5/GMT/'\n",
    "if not os.path.exists(dir_out1):  os.mkdir(dir_out1)\n",
    "if not os.path.exists(dir_out2):  os.mkdir(dir_out2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define limits for European box\n",
    "lon_limits_EUR = [-10, 35]\n",
    "lat_limits_EUR = [30, 70]\n",
    "\n",
    "#Define scenarios\n",
    "scenarios = ['historical', 'rcp85']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CMIP5_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(line[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop over models\n",
    "for model in all_models['rcp85']:\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    if model=='EC-EARTH':\n",
    "        members = ['r1i1p1', 'r12i1p1']\n",
    "    elif model=='MPI-ESM-LR':\n",
    "        members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "    else:\n",
    "        members = ['r1i1p1']\n",
    "\n",
    "    for member in members:\n",
    "    \n",
    "        #Loop over scenarios\n",
    "        for scen in scenarios:\n",
    "\n",
    "            #Get file names\n",
    "            dir_data = dir_CMIP5 + scen + '/'\n",
    "            fnames = [dir_data + file for file in os.listdir(dir_data) if model + '_' in file and member in file and 'tas_' in file and scen in file and '_Amon_' in file]\n",
    "            fnames = sorted(fnames)\n",
    "            if len(fnames)==0: sys.exit('No file found for this model.')\n",
    "\n",
    "            #Merge single files to one large file\n",
    "            file_merge = dir_out1 + 'CMIP5_merged_tas_' + scen + \"_\" + model + '_yearmean_tmp.nc'\n",
    "            if os.path.exists(file_merge): os.remove(file_merge)\n",
    "            os.system('cdo mergetime ' + \" \".join(fnames) + \" \" + file_merge)\n",
    "\n",
    "            #Open data set and rename variable\n",
    "            data = xr.open_dataset(file_merge, use_cftime=True)\n",
    "\n",
    "            #Convert longitude from [0, 360] to [-180, 180]\n",
    "            data['lon'] = data['lon'].where(data['lon']<180, ((data['lon'] + 180) % 360) - 180)\n",
    "            data = data.sortby('lon')\n",
    "\n",
    "\n",
    "            #Select time period\n",
    "            if scen=='historical':\n",
    "                data = data.sel(time=slice('1950', '2005'))\n",
    "            elif scen=='rcp85':\n",
    "                data = data.sel(time=slice('2006', '2100'))        \n",
    "\n",
    "            #Calculate yearly mean\n",
    "            ds_grid = data.resample(time='1Y').mean('time')\n",
    "\n",
    "            #Get mask for Europe\n",
    "            mask_EUR = ((data['lon']>=lon_limits_EUR[0]) & (data['lon']<=lon_limits_EUR[1]) & \n",
    "                        (data['lat']>=lat_limits_EUR[0]) & (data['lat']<=lat_limits_EUR[1]))\n",
    "\n",
    "            #Mask Europe (only for EMT!)\n",
    "            ds_masked = ds_grid.where(mask_EUR)\n",
    "\n",
    "            #Calculate EMT\n",
    "            area_weights = np.cos(ds_masked['lat'] * np.pi/180)\n",
    "            ds_EMT = ds_masked.tas.weighted(area_weights).mean(('lat', 'lon'))\n",
    "            ds_EMT = ds_EMT.to_dataset(name='tas')        \n",
    "\n",
    "            #Calculate GMT\n",
    "            area_weights = np.cos(ds_grid['lat'] * np.pi/180)\n",
    "            ds_GMT = ds_grid.tas.weighted(area_weights).mean(('lat', 'lon'))  \n",
    "            ds_GMT = ds_GMT.to_dataset(name='tas')        \n",
    "\n",
    "            #Create output file names\n",
    "            time_str  = str(data.time[0].dt.year.values) + '-' + str(data.time[-1].dt.year.values)\n",
    "            fname_out_EMT = dir_out1 + 'EMT_year_' + scen + '_' + model + '_' + member + '_' + time_str + \".nc\"\n",
    "            fname_out_GMT = dir_out2 + 'GMT_year_' + scen + '_' + model + '_' + member + '_' + time_str + \".nc\"\n",
    "\n",
    "            #Save in file\n",
    "            if os.path.exists(fname_out_EMT): os.remove(fname_out_EMT)\n",
    "            if os.path.exists(fname_out_GMT): os.remove(fname_out_GMT)\n",
    "            ds_EMT.to_netcdf(fname_out_EMT)\n",
    "            ds_GMT.to_netcdf(fname_out_GMT)\n",
    "\n",
    "            #Remove temporarily merged file\n",
    "            os.remove(file_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate GMT for full historical period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over models\n",
    "for model in all_models['rcp85']:\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    if model=='EC-EARTH':\n",
    "        members = ['r1i1p1', 'r12i1p1']\n",
    "    elif model=='MPI-ESM-LR':\n",
    "        members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "    else:\n",
    "        members = ['r1i1p1']\n",
    "\n",
    "    for member in members:\n",
    "\n",
    "        #Get file names\n",
    "        dir_data = dir_CMIP5 + 'historical/'\n",
    "        fnames = [dir_data + file for file in os.listdir(dir_data) if model + '_' in file and member in file and 'tas_' in file and 'historical' in file and '_Amon_' in file]\n",
    "        fnames = sorted(fnames)\n",
    "        if len(fnames)==0: sys.exit('No file found for this model.')\n",
    "\n",
    "        #Merge single files to one large file\n",
    "        file_merge = dir_out1 + 'CMIP5_merged_tas_historical_' + model + '_yearmean_tmp.nc'\n",
    "        if os.path.exists(file_merge): os.remove(file_merge)\n",
    "        os.system('cdo mergetime ' + \" \".join(fnames) + \" \" + file_merge)\n",
    "\n",
    "        #Open data set and rename variable\n",
    "        data = xr.open_dataset(file_merge, use_cftime=True)\n",
    "\n",
    "        #Convert longitude from [0, 360] to [-180, 180]\n",
    "        data['lon'] = data['lon'].where(data['lon']<180, ((data['lon'] + 180) % 360) - 180)\n",
    "        data = data.sortby('lon')\n",
    "\n",
    "        #Select time period\n",
    "        data = data.sel(time=slice(None, '2005'))\n",
    "\n",
    "        #Calculate yearly mean\n",
    "        ds_grid = data.resample(time='1Y').mean('time')\n",
    "\n",
    "        #Calculate GMT\n",
    "        area_weights = np.cos(ds_grid['lat'] * np.pi/180)\n",
    "        ds_GMT = ds_grid.tas.weighted(area_weights).mean(('lat', 'lon'))  \n",
    "        ds_GMT = ds_GMT.to_dataset(name='tas')        \n",
    "\n",
    "        #Create output file names\n",
    "        time_str = str(data.time[0].dt.year.values) + '-' + str(data.time[-1].dt.year.values)\n",
    "        fname_out_GMT = dir_out2 + 'GMT_year_historical_' + model + '_' + member + '_' + time_str + \".nc\"\n",
    "\n",
    "        #Save in file\n",
    "        if os.path.exists(fname_out_GMT): os.remove(fname_out_GMT)\n",
    "        ds_GMT.to_netcdf(fname_out_GMT)\n",
    "\n",
    "        #Remove temporarily merged file\n",
    "        os.remove(file_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
