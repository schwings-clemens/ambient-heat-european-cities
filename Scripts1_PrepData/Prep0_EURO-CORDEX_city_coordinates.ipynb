{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import yaml\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_EUR-11.txt', 'r') as file:  path_eur11 = file.read()\n",
    "\n",
    "dir_CORDEX  = path_eur11\n",
    "dir_names   = f'{path_main}Scripts//Model_lists/'\n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_files   = f'{dir_CORDEX}historical/tasmax/'\n",
    "dir_coord   = f'{path_main}Data/EURO-CORDEX/City_coordinates/'\n",
    "if not os.path.exists(dir_coord): os.mkdir(dir_coord)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp26'] = []\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP26.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp26'].append(eval(line[:-1]))\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "        \n",
    "#Get list with all models\n",
    "mod_85 = [\"_\".join(model) for model in all_models['rcp85']]\n",
    "mod_26 = [\"_\".join(model) for model in all_models['rcp26']]\n",
    "all_models = [model.split('_') for model in sorted(list(set(mod_85).union(set(mod_26))))]\n",
    "\n",
    "#Define cities\n",
    "cities = ['Istanbul', 'Moscow', 'London', 'SaintPetersburg', 'Berlin', 'Madrid', 'Kyiv', 'Rome', 'Paris',\n",
    "          'Bucharest', 'Minsk', 'Vienna', 'Hamburg', 'Warsaw', 'Budapest', 'Barcelona', 'Munich', 'Kharkiv',\n",
    "          'Milan', 'Belgrade', 'Prague', 'NizhnyNovgorod', 'Kazan', 'Sofia', 'Brussels', 'Stockholm', 'Oslo',\n",
    "          'Dublin', 'Lisbon', 'Vilnius', 'Copenhagen', 'Helsinki', 'Athens', 'Amsterdam', 'Riga', 'Zagreb']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coordinates and save in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "area_sel = 'gridpoint'\n",
    "\n",
    "#Initialize dict\n",
    "all_coords = dict()\n",
    "\n",
    "#Loop over models\n",
    "for model in all_models:\n",
    "    \n",
    "    print(\"_\".join(model))\n",
    "    \n",
    "    #Read data\n",
    "    files = [file for file in os.listdir(dir_files) if model[0] in file and model[1] in file and model[2] in file]\n",
    "    data  = xr.open_dataset(dir_files + files[0])\n",
    "    \n",
    "    if 'longitude' in data.coords:\n",
    "        lon_name, lat_name = 'longitude', 'latitude'\n",
    "    else:\n",
    "        lon_name, lat_name = 'lon', 'lat'    \n",
    "    \n",
    "    #Convert longitude from [0, 360] to [-180, 180]\n",
    "    if data[lon_name].max()>180:\n",
    "        data[lon_name] = data.lon.where(data[lon_name]<180, ((data[lon_name] + 180) % 360) - 180 )         \n",
    "    \n",
    "    data_empty = xr.Dataset(coords=dict(zip(data.coords, [data[coord] for coord in data.coords])))\n",
    "    data_empty = data_empty.drop('time')\n",
    "    if 'rlat' in data.dims:\n",
    "        coord_names = ['rlat', 'rlon']\n",
    "        data_empty['dummy'] = (coord_names, np.zeros((len(data_empty[coord_names[0]]), len(data_empty[coord_names[1]]))))    \n",
    "    elif 'x' in data.dims:\n",
    "        coord_names = ['x', 'y']\n",
    "        data_empty['dummy'] = (coord_names, np.zeros((len(data_empty[coord_names[0]]), len(data_empty[coord_names[1]]))))    \n",
    "\n",
    "    all_coords[\"_\".join(model)] = dict()\n",
    "    \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "\n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]\n",
    "\n",
    "        #Find grid point closest to city\n",
    "        loc_city = (np.abs(data[lon_name] - lon_sel)) + (np.abs(data[lat_name] - lat_sel))\n",
    "        ind_city = np.unravel_index(np.argmin(loc_city.values), loc_city.shape)\n",
    "        \n",
    "        if area_sel=='gridpoint':\n",
    "            lat_rng = ind_city[0]\n",
    "            lon_rng = ind_city[1]\n",
    "        elif area_sel=='3x3':\n",
    "            lat_rng  = slice(ind_city[0] - 1, ind_city[0] + 2)\n",
    "            lon_rng  = slice(ind_city[1] - 1, ind_city[1] + 2)            \n",
    "            \n",
    "        if 'rlat' in data.dims:\n",
    "            data_city = data_empty.isel(rlat=lat_rng, rlon=lon_rng)\n",
    "            coords = [data_city[lon_name].item(), data_city[lat_name].item()]\n",
    "            if 'rlat' not in data_city.dims:  data_city = data_city.drop(('rlat', 'rlon'))\n",
    "        elif 'x' in data.dims:\n",
    "            data_city = data_empty.isel(x=lon_rng, y=lat_rng)\n",
    "            coords = [data_city[lon_name].item(), data_city[lat_name].item()]\n",
    "            if 'x' not in data_city.dims:  data_city = data_city.drop(('x', 'y'))\n",
    "        else: sys.exit('Coordinate names could not be identified')\n",
    "            \n",
    "#         #Save grid in NetCDF file\n",
    "#         fname_grid = dir_coord + 'Grid_' + area_sel + '_' + \"_\".join(model) + '_' + city + '_tmp.nc'\n",
    "#         data_city.to_netcdf(fname_grid)\n",
    "\n",
    "#         #Create grid description for cdo\n",
    "#         fname_out =  dir_coord + 'grid_' + area_sel + '_' + \"_\".join(model) + '_' + city\n",
    "#         os.system(\"cdo griddes -selvar,dummy \" + fname_grid + \" > \" + fname_out)\n",
    "\n",
    "        #Save coordinates in dict\n",
    "        all_coords[\"_\".join(model)][city] = dict(zip(coord_names, coords))\n",
    "                    \n",
    "#Save in file\n",
    "fname_out = dir_coord + 'EURO-CORDEX_city_coordinates.yml'\n",
    "with open(fname_out, 'w') as outfile:\n",
    "    yaml.dump(all_coords, outfile, default_flow_style=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
