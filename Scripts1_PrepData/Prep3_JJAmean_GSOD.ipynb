{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main path\n",
    "with open('../path_main.txt', 'r') as file:   path_main = file.read()\n",
    "\n",
    "dir_scripts   = f'{path_main}Scripts/'\n",
    "dir_variables = f'{path_main}Data/GSOD/Stations_all_years/'\n",
    "dir_JJA       = f'{path_main}Data/GSOD/JJA/'\n",
    "if not os.path.exists(dir_JJA):   os.mkdir(dir_JJA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Istanbul', 'Moscow', 'London', 'SaintPetersburg', 'Berlin', 'Madrid', 'Kyiv', 'Rome', 'Paris',\n",
    "          'Bucharest', 'Minsk', 'Vienna', 'Hamburg', 'Warsaw', 'Budapest', 'Barcelona', 'Munich', 'Kharkiv',\n",
    "          'Milan', 'Belgrade', 'Prague', 'NizhnyNovgorod', 'Kazan', 'Sofia', 'Brussels', 'Stockholm', 'Oslo',\n",
    "          'Dublin', 'Lisbon', 'Vilnius', 'Copenhagen', 'Helsinki', 'Athens', 'Amsterdam', 'Riga', 'Zagreb']\n",
    "\n",
    "#Define variables\n",
    "variables = ['TN', 'TX']\n",
    "\n",
    "#Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Get lat and lon of city\n",
    "city_names  = list(city_coords.keys())\n",
    "city_coords = np.array(list(city_coords.values()))\n",
    "lat_city = city_coords[:, 0]\n",
    "lon_city = city_coords[:, 1]\n",
    "    \n",
    "#Select time (reference period)\n",
    "time_sel = slice('1981', '2010')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate JJA average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop over variables\n",
    "for variab in variables:\n",
    "\n",
    "    print(\" -\" + variab, end=': ')\n",
    "    \n",
    "    #Get all files\n",
    "    files = [dir_variables + file for file in os.listdir(dir_variables) if variab + '_' in file]\n",
    "    \n",
    "    #Initialize dictionary to store data\n",
    "    data_coll = dict([(city, []) for city in cities])\n",
    "    \n",
    "    #Loop over files\n",
    "    for file in files:\n",
    "    \n",
    "        #Read data, lat, lon\n",
    "        data = xr.open_dataset(file)\n",
    "        lat = data.lat.values.item()\n",
    "        lon = data.lon.values.item()\n",
    "\n",
    "        #Identify city that is closest to station\n",
    "        min_dist = np.sqrt((lat_city - lat)**2 + (lon_city - lon)**2)\n",
    "        city_sel = city_names[np.argmin(min_dist)]\n",
    "\n",
    "        #Select data in reference period\n",
    "        data = data.sel(time=time_sel)\n",
    "\n",
    "        #Select summer\n",
    "        sel_JJA  = (data.time.dt.month>=6) & (data.time.dt.month<=8)\n",
    "        data_JJA = data.isel(time=sel_JJA)\n",
    "\n",
    "        #Calculate sum of NaNs\n",
    "        NaN_sum = np.sum(np.isnan(data_JJA[variab])).values\n",
    "\n",
    "        #Skip station if too many NaNs or no data in time period\n",
    "        if (NaN_sum<10*92) or ((len(data_JJA.time)/92>=20) & (len(data_JJA.time)/92<25)):\n",
    "            flag = 2\n",
    "        if NaN_sum<5*92:\n",
    "            flag = 1\n",
    "        if (NaN_sum>=10*92) or (len(data_JJA.time)/92<20):\n",
    "            continue\n",
    "         \n",
    "        #Calculate summer average\n",
    "        values = data_JJA.mean('time')[variab].values.item()\n",
    "\n",
    "        #Save data in dict\n",
    "        data_coll[city_sel].append([lat, lon, values, flag])\n",
    "        \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "        \n",
    "        #Exctract data\n",
    "        data_sel = data_coll[city]\n",
    "        \n",
    "        #Check that data is not empty\n",
    "        if data_sel==[]:\n",
    "            print(city)\n",
    "            continue\n",
    "        \n",
    "        #Convert to dataframe\n",
    "        data_out = pd.DataFrame(data_sel)\n",
    "        data_out.columns = ['lat', 'lon', variab, 'flag']\n",
    "        \n",
    "        #Save to file\n",
    "        fname_out = dir_JJA + variab + '_GSOD-stations_' + city + \".csv\"\n",
    "        data_out.to_csv(fname_out, index=False)\n",
    "        \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
