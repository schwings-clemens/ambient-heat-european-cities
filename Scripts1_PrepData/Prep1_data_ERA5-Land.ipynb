{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:       path_main = file.read()\n",
    "with open('../path_ERA5-Land.txt', 'r') as file:  path_era5 = file.read()\n",
    "\n",
    "dir_ERA5     = path_era5\n",
    "dir_scripts  = f'{path_main}Scripts/'\n",
    "dir_ERA5_out = f'{path_main}/Data/ERA5-Land/Variables/'\n",
    "if not os.path.exists(dir_ERA5_out): os.mkdir(dir_ERA5_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Istanbul', 'Moscow', 'London', 'SaintPetersburg', 'Berlin', 'Madrid', 'Kyiv', 'Rome', 'Paris',\n",
    "          'Bucharest', 'Minsk', 'Vienna', 'Hamburg', 'Warsaw', 'Budapest', 'Barcelona', 'Munich', 'Kharkiv',\n",
    "          'Milan', 'Belgrade', 'Prague', 'NizhnyNovgorod', 'Kazan', 'Sofia', 'Brussels', 'Stockholm', 'Oslo',\n",
    "          'Dublin', 'Lisbon', 'Vilnius', 'Copenhagen', 'Helsinki', 'Athens', 'Amsterdam', 'Riga', 'Zagreb']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Define compression level\n",
    "comp = dict(zlib=True, complevel=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ERA5-Land for single grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define variables\n",
    "file_names     = ['tasmax', 'tasmin']\n",
    "var_names      = ['t2m', 't2m']\n",
    "var_names_out  = ['tasmax', 'tasmin']\n",
    "\n",
    "#Time limits\n",
    "time_lim = ['1981', '2010']\n",
    "time_str = time_lim[0] + '-' + time_lim[1]\n",
    "\n",
    "#Create pandas data frame\n",
    "all_dates = pd.date_range(time_lim[0] + '-01-01', time_lim[1] + '-12-31', freq='D')\n",
    "data_ERA  = pd.DataFrame(index=all_dates, columns=var_names_out)\n",
    "\n",
    "#Create dictionaries for storing data\n",
    "all_data_ERA = dict()\n",
    "for city in cities:\n",
    "    all_data_ERA[city] = data_ERA.copy(deep=True)\n",
    "\n",
    "#Loop over variables\n",
    "for fname, variab, var_out in zip(file_names, var_names, var_names_out):\n",
    "\n",
    "    #Read ERA5 data\n",
    "    fname_ERA5 = [dir_ERA5 + file for file in os.listdir(dir_ERA5) if fname in file]\n",
    "    if len(fname_ERA5)!=1: sys.exit('Filename is not unique')\n",
    "    data_ERA5_in = xr.open_dataset(fname_ERA5[0]).load()\n",
    "    \n",
    "    print(var_out)\n",
    "    \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "\n",
    "        print(\" -\" + city)\n",
    "\n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]\n",
    "        \n",
    "        #Select ERA5 data closest to city and in period 1979-2018\n",
    "        data_ERA5_sel = data_ERA5_in.sel(latitude=lat_sel, longitude=lon_sel, method='nearest')\n",
    "        data_ERA5_sel = data_ERA5_sel.sel(time=slice(time_lim[0], time_lim[1]))\n",
    "    \n",
    "        #Save in data frame\n",
    "        all_data_ERA[city].loc[:, var_out] = data_ERA5_sel[variab]\n",
    "        \n",
    "#Save data in CSV file\n",
    "for city in cities:\n",
    "    all_data_ERA[city].to_csv(dir_ERA5_out + 'Variables_' + city + '_ERA5_day_' + time_str + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ERA5-Land for NxN grid box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define variables\n",
    "file_names     = ['tasmax', 'tasmin']\n",
    "var_names      = ['t2m', 't2m']\n",
    "var_names_out  = ['tasmax', 'tasmin']\n",
    "\n",
    "#Time limits\n",
    "time_lim = ['1981', '2010']\n",
    "time_str = time_lim[0] + '-' + time_lim[1]\n",
    "\n",
    "#Create dictionaries for storing data\n",
    "all_data_ERA = dict()\n",
    "\n",
    "# N should be uneven!\n",
    "N = 5\n",
    "\n",
    "#Loop over variables\n",
    "for i0, (fname, variab, var_out) in enumerate(zip(file_names, var_names, var_names_out)):\n",
    "    \n",
    "    print(var_out)\n",
    "    \n",
    "    #Read ERA5 data\n",
    "    fname_ERA5 = [dir_ERA5 + file for file in os.listdir(dir_ERA5) if fname in file]\n",
    "    if len(fname_ERA5)!=1: sys.exit('Filename is not unique')\n",
    "    data_ERA5_in = xr.open_dataset(fname_ERA5[0]).load()\n",
    "    \n",
    "    #Re-index longitude\n",
    "    attrs = data_ERA5_in.longitude.attrs\n",
    "    data_ERA5_in = data_ERA5_in.assign_coords(longitude=(((data_ERA5_in.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "    data_ERA5_in['longitude'].attrs = attrs\n",
    "    \n",
    "    #Loop over cities\n",
    "    for city in cities:\n",
    "\n",
    "        print(\" -\" + city)\n",
    "\n",
    "        #Get lat and lon of city\n",
    "        lat_sel, lon_sel = city_coords[city]\n",
    "\n",
    "        #Find grid point closest to city\n",
    "        lat_city = np.argmin(np.abs(data_ERA5_in.latitude.values - lat_sel))\n",
    "        lon_city = np.argmin(np.abs(data_ERA5_in.longitude.values - lon_sel))\n",
    "        \n",
    "        #Select NxN box around grid point\n",
    "        N_half = int((N-1)/2)\n",
    "        lat_rng  = slice(lat_city - N_half, lat_city + N_half + 1)\n",
    "        lon_rng  = slice(lon_city - N_half, lon_city + N_half + 1)\n",
    "        data_ERA5_sel = data_ERA5_in.isel(latitude=lat_rng, longitude=lon_rng)\n",
    "        \n",
    "        #Select ERA5 data in period 1979-2018\n",
    "        data_ERA5_sel = data_ERA5_sel.sel(time=slice(time_lim[0], time_lim[1]))\n",
    "    \n",
    "        #Save in data frame\n",
    "        if i0==0:\n",
    "            data_ERA5_sel = data_ERA5_sel.rename({variab: var_out})\n",
    "            all_data_ERA[city] = data_ERA5_sel.load()\n",
    "        else:\n",
    "            data_ERA5_sel['time'] = all_data_ERA[city].time\n",
    "            all_data_ERA[city][var_out] = data_ERA5_sel[variab].load()\n",
    "\n",
    "#Save data in CSV file\n",
    "for city in cities:\n",
    "    \n",
    "    #Define file name\n",
    "    fname_out = dir_ERA5_out + 'Variables-' + str(N) + 'x' + str(N) + '_' + city + '_ERA5_day_' + time_str + '.nc'\n",
    "    if os.path.exists(fname_out): os.remove(fname_out)\n",
    "    \n",
    "    #Save in NetCDF (with compression)\n",
    "    encoding = {var: comp for var in all_data_ERA[city].data_vars}\n",
    "    all_data_ERA[city].to_netcdf(fname_out, encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
