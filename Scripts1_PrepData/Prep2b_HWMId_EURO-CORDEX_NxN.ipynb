{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "#My functions\n",
    "sys.path.insert(0,'../functions/')\n",
    "import functions_HeatWavesCities as fun_HWC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main path\n",
    "with open('../path_main.txt', 'r') as file:   path_main = file.read()\n",
    "    \n",
    "dir_CORDEX    = f'{path_main}Data/EURO-CORDEX/'\n",
    "dir_data      = f'{path_main}Data/EURO-CORDEX/Variables/'\n",
    "dir_scripts   = f'{path_main}Scripts/'\n",
    "dir_names     = f'{path_main}Scripts/Model_lists/'\n",
    "dir_functions = f'{path_main}Scripts/functions/'\n",
    "dir_HSI_out   = f'{path_main}Data/EURO-CORDEX/HSIs/'\n",
    "if not os.path.exists(dir_HSI_out):   os.mkdir(dir_HSI_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source R functions\n",
    "r = ro.r\n",
    "r.source(dir_scripts + 'functions/get_HWMId_vCities_NxN.r')\n",
    "\n",
    "#Define cities\n",
    "cities = ['Istanbul', 'Moscow', 'London', 'SaintPetersburg', 'Berlin', 'Madrid', 'Kyiv', 'Rome', 'Paris',\n",
    "          'Bucharest', 'Minsk', 'Vienna', 'Hamburg', 'Warsaw', 'Budapest', 'Barcelona', 'Munich', 'Kharkiv',\n",
    "          'Milan', 'Belgrade', 'Prague', 'NizhnyNovgorod', 'Kazan', 'Sofia', 'Brussels', 'Stockholm', 'Oslo',\n",
    "          'Dublin', 'Lisbon', 'Vilnius', 'Copenhagen', 'Helsinki', 'Athens', 'Amsterdam', 'Riga', 'Zagreb']\n",
    "\n",
    "#Define HSIs\n",
    "HSI_names = ['TN', 'TX']\n",
    "\n",
    "N = 5\n",
    "N_str = str(N) + 'x' + str(N)\n",
    "\n",
    "#Define RCPs\n",
    "RCPs = ['rcp85']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp26'] = []\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP26.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp26'].append(eval(line[:-1]))\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "\n",
    "#Add models for historical\n",
    "mod_85 = [\"_\".join(model) for model in all_models['rcp85']]\n",
    "mod_26 = [\"_\".join(model) for model in all_models['rcp26']]\n",
    "all_models['historical'] = [model.split('_') for model in sorted(list(set(mod_85).union(set(mod_26))))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HWMId for NxN grid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select NxN grid points\n",
    "area_sel = N_str\n",
    "\n",
    "#Only performs calculation for gridpoint, otherwise use script 'Prep_HSI_HWMId_EURO-CORDEX'\n",
    "if area_sel=='':\n",
    "    sys.exit('Use script Prep_HSI_HWMId_EURO-CORDEX for data on on a single gripdoint.')\n",
    "\n",
    "#Define output folder\n",
    "dir_HWMId_out = dir_CORDEX + 'HWMId_' + N_str + '/'\n",
    "if not os.path.exists(dir_HWMId_out): os.mkdir(dir_HWMId_out)\n",
    "    \n",
    "#Define reference and application years\n",
    "app_years = [1981, 2099]\n",
    "ref_years_vec = ro.r.c(1981, 2010)\n",
    "app_years_vec = ro.r.seq(app_years[0], app_years[1])\n",
    "\n",
    "#Create time vector for HWMId\n",
    "time_HWMID = xr.cftime_range(start=str(app_years[0]) + '0101', end=str(app_years[1]) + '1231', freq='Y', calendar='standard')\n",
    "\n",
    "#Loop over RCPs\n",
    "for RCP in RCPs:\n",
    "    \n",
    "    #Define scenarios and select models\n",
    "    scenarios = ['historical', RCP]\n",
    "    models    = all_models[RCP]\n",
    "\n",
    "    #Loop over models\n",
    "    for model in models:\n",
    "        \n",
    "        print('')\n",
    "        print(\" -\" + \"_\".join(model), end=': ')\n",
    "\n",
    "        #Loop over cities\n",
    "        for i0, city in enumerate(cities):\n",
    "\n",
    "            print(city, end=', ')\n",
    "            \n",
    "            #Define and create output directory\n",
    "            dir_city = dir_HWMId_out + city + '/'\n",
    "            dir_out  = dir_HWMId_out + city + '/' + RCP + '/'\n",
    "            if not os.path.exists(dir_city): os.mkdir(dir_city)\n",
    "            if not os.path.exists(dir_out): os.mkdir(dir_out)\n",
    " \n",
    "            #Loop over HSIs\n",
    "            for HSI_name in HSI_names:\n",
    "                \n",
    "                #Loop over scenarios\n",
    "                for i1, scen in enumerate(scenarios):\n",
    "\n",
    "                    #Get file name\n",
    "                    dir_HSI = dir_HSI_out + city + '/' + scen + '/'\n",
    "                    var_data = HSI_name\n",
    "                    files_HSI = [file for file in os.listdir(dir_HSI) if area_sel + '_' in file and scen in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "                    if len(files_HSI)!=1:  sys.exit('File is not unique')\n",
    "                        \n",
    "                    #Read data\n",
    "                    data_read = xr.open_dataset(dir_HSI + files_HSI[0])\n",
    "                    data_read = data_read[var_data].to_dataset(name=HSI_name)\n",
    "\n",
    "                    #Concatenate historical and future data\n",
    "                    if i1==0:\n",
    "                        data_comb = data_read\n",
    "                    else:\n",
    "                        data_comb = xr.concat((data_comb, data_read), dim='time')\n",
    "                \n",
    "                #Save data temporarily in NetCDF\n",
    "                fname_tmp   = dir_HSI + 'tmp_EURO-CORDEX_' + area_sel + '.nc'\n",
    "                if os.path.exists(fname_tmp): os.remove(fname_tmp)\n",
    "                data_comb.to_netcdf(fname_tmp)\n",
    "\n",
    "                #Define lon and lat name\n",
    "                if 'rlat' in data_comb.dims:\n",
    "                    coord_names = ['rlon', 'rlat']\n",
    "                    coord_names_R = ro.r.c('rlon', 'rlat')\n",
    "                elif 'x' in data_comb.dims:\n",
    "                    coord_names = ['y', 'x']\n",
    "                    coord_names_R = ro.r.c('y', 'x')\n",
    "                    \n",
    "                #Calculate HWMId\n",
    "                output = r.get_HWMId_vCities_NxN(HSI_name, fname_tmp, ref_years_vec, app_years_vec, coord_names_R, dir_functions)\n",
    "\n",
    "                #Extract variables from R output (dims: lon, lat, time)\n",
    "                HWMID_strength = np.array(output.rx2(\"HWMID_strength\"))\n",
    "                HWMID_length   = np.array(output.rx2(\"HWMID_length\"))\n",
    "                HWMID_DOYstart = np.array(output.rx2(\"HWMID_DOYstart\"))\n",
    "\n",
    "                #Create dataset with same coords as original dataset\n",
    "                data_HWMID = xr.Dataset(coords=dict(zip(data_comb.coords, [data_comb[coord] for coord in data_comb.coords])))\n",
    "                if 'height' in data_HWMID.coords: data_HWMID = data_HWMID.drop('height')\n",
    "                \n",
    "                #Put yearly time axis\n",
    "                data_HWMID = data_HWMID.isel(time=1).drop('time')\n",
    "                data_HWMID = data_HWMID.assign_coords({'time': time_HWMID})\n",
    "\n",
    "                #Put HWMID\n",
    "                data_HWMID['HWMID'] = (coord_names + ['time'], HWMID_strength)\n",
    "                data_HWMID['HWMID_length'] = (coord_names + ['time'], HWMID_length)\n",
    "                data_HWMID['HWMID_DOYstart'] = (coord_names + ['time'], HWMID_DOYstart)\n",
    "                \n",
    "                #Save in file\n",
    "                fname_HWMId = dir_out + 'HWMId-' + HSI_name + \"_\" + \"_\".join(model) + '_' + \"-\".join(scenarios) + \"_\" + str(app_years[0]) + \"-\" + str(app_years[1]) + \".nc\"\n",
    "                if os.path.exists(fname_HWMId): os.remove(fname_HWMId)\n",
    "                data_HWMID.to_netcdf(fname_HWMId)\n",
    "\n",
    "                #Remove temporary file\n",
    "                os.remove(fname_tmp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
