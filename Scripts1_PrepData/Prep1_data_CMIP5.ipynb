{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n",
    "\n",
    "#My functions\n",
    "sys.path.insert(0,'./../functions/')\n",
    "import functions_HeatWavesCities as fun_HWC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:   path_main  = file.read()\n",
    "with open('../path_CMIP5.txt', 'r') as file:  path_cmip5 = file.read()\n",
    "with open('../path_grids.txt', 'r') as file:  dir_grids  = file.read()\n",
    "    \n",
    "dir_CMIP5   = path_cmip5\n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_orog    = f'{dir_grids}Orography/'\n",
    "dir_tmp     = f'{path_main}Data/CMIP5_tmp/'\n",
    "dir_out     = f'{path_main}Data/CMIP5/Variables/'\n",
    "if not os.path.exists(dir_out): os.mkdir(dir_out)\n",
    "if not os.path.exists(dir_tmp): os.mkdir(dir_tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cities\n",
    "cities = ['Istanbul', 'Moscow', 'London', 'SaintPetersburg', 'Berlin', 'Madrid', 'Kyiv', 'Rome', 'Paris',\n",
    "          'Bucharest', 'Minsk', 'Vienna', 'Hamburg', 'Warsaw', 'Budapest', 'Barcelona', 'Munich', 'Kharkiv',\n",
    "          'Milan', 'Belgrade', 'Prague', 'NizhnyNovgorod', 'Kazan', 'Sofia', 'Brussels', 'Stockholm', 'Oslo',\n",
    "          'Dublin', 'Lisbon', 'Vilnius', 'Copenhagen', 'Helsinki', 'Athens', 'Amsterdam', 'Riga', 'Zagreb']\n",
    "\n",
    "#Define scenarios and variables\n",
    "scenarios = ['historical', 'rcp85']\n",
    "variables  = ['tasmax']\n",
    "variabs_out = ['tasmax']\n",
    "\n",
    "# Load city coordinates\n",
    "fname_coords = dir_scripts + 'City_coordinates.yml'\n",
    "with open(fname_coords, 'r') as file:\n",
    "    city_coords = yaml.safe_load(file)\n",
    "\n",
    "#Define models and SSPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CMIP5_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(line[:-1])\n",
    "        \n",
    "#Add models for historical\n",
    "all_models['historical'] = all_models['rcp85']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CMIP5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create temporary folder\n",
    "if not os.path.exists(dir_tmp): os.mkdir(dir_tmp)\n",
    "\n",
    "#Loop over scenarios\n",
    "for scen in scenarios:\n",
    "\n",
    "    dir_scen = dir_CMIP5 + scen + '/'\n",
    "    \n",
    "    models = all_models[scen]\n",
    "    \n",
    "    #Loop over models\n",
    "    for model in models:\n",
    "\n",
    "        print(model)\n",
    "\n",
    "        #Define members\n",
    "        if model=='EC-EARTH':      members = ['r1i1p1', 'r12i1p1']\n",
    "        elif model=='MPI-ESM-LR':  members = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "        else:                      members = ['r1i1p1']        \n",
    "\n",
    "        #Select time limits\n",
    "        if scen=='historical':\n",
    "            time_sel = slice('1980', '2005')\n",
    "        elif scen in ['rcp26', 'rcp85']:\n",
    "            if model in ['HadGEM2-AO', 'HadGEM2-CC', 'HadGEM2-ES']:\n",
    "                time_sel = slice('2005', '2100')\n",
    "            else:\n",
    "                time_sel = slice('2006', '2100')\n",
    "                \n",
    "        #Loop over members\n",
    "        for member in members:\n",
    "\n",
    "            #Initialize dict to store data\n",
    "            data_coll = dict()\n",
    "\n",
    "            #Loop over variables\n",
    "            for variab in variables:\n",
    "\n",
    "                print(\" -\" + variab, end='')\n",
    "\n",
    "                #Get file names\n",
    "                fnames = [dir_scen + file for file in os.listdir(dir_scen) if model +'_' in file and member in file and variab in file and scen in file and '_day_' in file]\n",
    "                fnames = [fname for fname in fnames if int(fname[-11:-7])>=1980]\n",
    "                t_sta = t_util.time()\n",
    "\n",
    "                if len(fnames)==0:\n",
    "                    sys.exit('Input file not uniquely defined')\n",
    "                elif len(fnames)>1:\n",
    "\n",
    "                    #Merge single files to one large file\n",
    "                    file_merge = dir_out + 'CMIP5_merged_' + variab + '_' + scen + \"_\" + model + '_' + member + '_gridpoint_tmp.nc'\n",
    "                    if os.path.exists(file_merge): os.remove(file_merge)\n",
    "                    os.system('cdo mergetime ' + \" \".join(fnames) + \" \" + file_merge)\n",
    "                    t_end = t_util.time()\n",
    "                    print(\" -- \" + \"{:.1f}\".format(t_end - t_sta), end='')   \n",
    "\n",
    "                    remove_file = True\n",
    "\n",
    "                else:\n",
    "                    file_merge = fnames[0]\n",
    "                    remove_file = False\n",
    "\n",
    "                #Load dataset\n",
    "                with xr.open_dataset(file_merge, use_cftime=True) as ds:\n",
    "                    data = ds.load()\n",
    "                    ds.close()\n",
    "\n",
    "                #Loop over cities\n",
    "                for city in cities:\n",
    "\n",
    "                    #Get lat and lon of city\n",
    "                    lat_sel, lon_sel = city_coords[city]\n",
    "\n",
    "                    #Convert longitude from [-180, 180] to [0, 360]\n",
    "                    if lon_sel<0: lon_sel = lon_sel + 360\n",
    "\n",
    "                    #Find grid point closest to city\n",
    "                    data_sel = data.sel(lat=lat_sel, lon=lon_sel, method='nearest')\n",
    "\n",
    "                    #Save in dict\n",
    "                    data_coll[city + '_' + variab] = data_sel.load()\n",
    "\n",
    "                #Delete temporary file\n",
    "                if (remove_file==True) and (dir_out in file_merge):\n",
    "                    os.remove(file_merge)\n",
    "\n",
    "                t_end = t_util.time()\n",
    "                print(\", \" + \"{:.1f}\".format(t_end - t_sta))\n",
    "\n",
    "            #Loop over cities\n",
    "            for city in cities:\n",
    "\n",
    "                #Define output folder\n",
    "                dir_city = dir_out + city  + '/'\n",
    "                dir_save = dir_city + scen + '/'\n",
    "                if not os.path.exists(dir_city): os.mkdir(dir_city)\n",
    "                if not os.path.exists(dir_save): os.mkdir(dir_save)\n",
    "\n",
    "                #Loop over variables\n",
    "                for i2, variab in enumerate(variables):          \n",
    "\n",
    "                    #Add missing 31 December 2099\n",
    "                    if (model=='bcc-csm1-1') and (scen=='rcp85'):\n",
    "\n",
    "                        fname_tmp = dir_out + 'tmp_time.nc'\n",
    "                        data_corr = data_coll[city + '_' + variab]\n",
    "                        data_full = fun_HWC.add_missing_data(data_corr, fname_tmp, variab, '20991231', '20991231', 1)\n",
    "                        data_full = data_full.sortby('time')\n",
    "\n",
    "                        #Save corrected data in dict\n",
    "                        data_coll[city + '_' + variab] = data_full           \n",
    "\n",
    "                    #Convert to pandas dataframe\n",
    "                    data_convert = data_coll[city + '_' + variab].sel(time=time_sel)\n",
    "                    data_convert = data_convert[variab].to_pandas().to_frame(name=variab)\n",
    "\n",
    "                    #Put all variables in one dataframe\n",
    "                    if i2==0:\n",
    "                        data_out = data_convert\n",
    "                    else:\n",
    "                        data_out = pd.concat((data_out, data_convert), axis=1)\n",
    "\n",
    "                    #Correct sea level pressure\n",
    "                    if variab=='psl':\n",
    "\n",
    "                        #Read orography data and get temperature data\n",
    "                        orog = fun_HWC.get_orog_CMIP6(model, city, city_coords[city], dir_orog)\n",
    "                        Temp = data_out.loc[:, 'tasmax']\n",
    "\n",
    "                        #Correct pressure\n",
    "                        T   = Temp.values\n",
    "                        psl = data_convert['psl'].values\n",
    "                        p_corr = fun_HWC.corr_press(psl, orog, T)\n",
    "\n",
    "                        #Save in data frame and rename psl -> sp\n",
    "                        data_out.loc[:, 'psl'] = p_corr\n",
    "                        data_out = data_out.rename(columns={'psl': 'sp'})\n",
    "\n",
    "                #Create file name\n",
    "                t1 = str(data_out.index[0].year)\n",
    "                t2 = str(data_out.index[-1].year)\n",
    "                fname_out = dir_save + \"Variables_\" + city + \"_\" + model + '_' + member + '_' + scen + '_day_' + t1 + \"-\" + t2 + \".csv\"\n",
    "\n",
    "#                 #Save in file (standard version)\n",
    "#                 if os.path.exists(fname_out):  os.remove(fname_out)\n",
    "#                 data_out.to_csv(fname_out) \n",
    "                \n",
    "                #Check if file already exists\n",
    "                if os.path.exists(fname_out):\n",
    "                    \n",
    "                    #Read data and add variables\n",
    "                    data_read = pd.read_csv(fname_out)\n",
    "                    for variab in variabs_out:\n",
    "                        data_read[variab] = data_out[variab].values\n",
    "\n",
    "                    #Save in file\n",
    "                    os.remove(fname_out)\n",
    "                    data_read.to_csv(fname_out)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #Save in file\n",
    "                    data_out.to_csv(fname_out)\n",
    "\n",
    "#Remove temporary folder\n",
    "os.rmdir(dir_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
