{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import yaml\n",
    "import calendar\n",
    "import xarray as xr\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "#My functions\n",
    "sys.path.insert(0,'../functions/')\n",
    "import functions_HeatWavesCities as fun_HWC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_EUR-11.txt', 'r') as file:  path_eur11 = file.read()\n",
    "    \n",
    "dir_CORDEX     = path_eur11\n",
    "dir_CORDEX_out = f'{path_main}Data/EURO-CORDEX/'\n",
    "dir_scripts    = f'{path_main}Scripts/'\n",
    "dir_names      = f'{path_main}Scripts/Model_lists/'\n",
    "dir_functions  = f'{path_main}Scripts/functions/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source R functions\n",
    "r = ro.r\n",
    "r.source(dir_scripts + 'functions/get_HWMId_vCities_NxN.r')\n",
    "\n",
    "#Define scenarios and variables\n",
    "scenarios = ['historical', 'rcp85']\n",
    "RCPs      = ['rcp85']\n",
    "variables = ['tasmax']\n",
    "variables_out = ['TX']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp26'] = []\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP26.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp26'].append(eval(line[:-1]))\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "\n",
    "#Add models for historical\n",
    "mod_85 = [\"_\".join(model) for model in all_models['rcp85']]\n",
    "mod_26 = [\"_\".join(model) for model in all_models['rcp26']]\n",
    "all_models['historical'] = [model.split('_') for model in sorted(list(set(mod_85).union(set(mod_26))))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HWMId for all of Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define output folder\n",
    "dir_HWMId_out = dir_CORDEX_out + 'HWMId_Europe/'\n",
    "if not os.path.exists(dir_HWMId_out): os.mkdir(dir_HWMId_out)\n",
    "    \n",
    "#Define reference and application years\n",
    "app_years = [1981, 2099]\n",
    "ref_years_vec = ro.r.c(1981, 2010)\n",
    "app_years_vec = ro.r.seq(app_years[0], app_years[1])\n",
    "years_cdo = str(app_years[0]) + '/' + str(app_years[-1])\n",
    "\n",
    "#Loop over RCPs\n",
    "for RCP in RCPs:\n",
    "    \n",
    "    #Define scenarios and select models\n",
    "    scenarios = ['historical', RCP]\n",
    "    models    = all_models[RCP]\n",
    "    \n",
    "    #Loop over models\n",
    "    for model in models:\n",
    "        \n",
    "        print(\" -\" + \"_\".join(model))\n",
    "\n",
    "        #Loop over HSIs\n",
    "        for (var_in, var_out) in zip(variables, variables_out):\n",
    "\n",
    "            #Loop over scenarios\n",
    "            files_merge =[]\n",
    "            for i1, scen in enumerate(scenarios):\n",
    "\n",
    "                #Get file name\n",
    "                dir_data = dir_CORDEX + '/' + scen + '/' + var_in + '/'\n",
    "                files_read = [dir_data + file for file in os.listdir(dir_data) if scen in file and model[0] in file and model[1] in file and model[2] in file]\n",
    "                if len(files_read)==0:  sys.exit('No files found')\n",
    "\n",
    "                #Select only years after 1981\n",
    "                if scen=='historical':  files_read = [file for file in files_read if int(file[-11:-7])>=1981]\n",
    "\n",
    "                #Collect all files (convert temperature from Â°C to K for ALADIN53 in RCP85)\n",
    "                if 'ALADIN53' in \"_\".join(model) and scen=='rcp85' and var_in=='tasmax':\n",
    "                    fname_ALA_tmp1 = dir_CORDEX + 'tmp/ALADIN53_correct1.nc'\n",
    "                    fname_ALA_tmp2 = dir_CORDEX + 'tmp/ALADIN53_correct2.nc'\n",
    "                    os.system('cdo mergetime ' + \" \".join(sorted(files_read)) + ' ' + fname_ALA_tmp1)\n",
    "                    os.system('cdo addc,+273.15 ' + fname_ALA_tmp1 + ' ' + fname_ALA_tmp2)\n",
    "                    files_merge = files_merge + [fname_ALA_tmp2]\n",
    "                    os.remove(fname_ALA_tmp1)\n",
    "                    \n",
    "                else:\n",
    "                    files_merge = files_merge + sorted(files_read)\n",
    "                \n",
    "            #Merge time\n",
    "            dir_tmp = dir_CORDEX + 'tmp/'\n",
    "            fname_tmp1 = dir_tmp + var_in + '_' + \"_\".join(model) + '_' + RCP + '_tmp1.nc'\n",
    "            fname_tmp2 = dir_tmp + var_in + '_' + \"_\".join(model) + '_' + RCP + '_tmp2.nc'\n",
    "            fname_tmp3 = fname_tmp2\n",
    "            if os.path.exists(fname_tmp1):  os.remove(fname_tmp1)\n",
    "            if os.path.exists(fname_tmp2):  os.remove(fname_tmp2)\n",
    "            os.system('cdo mergetime ' + \" \".join(files_merge) + ' ' + fname_tmp1)\n",
    "            os.system('cdo selyear,' + years_cdo + ' ' + fname_tmp1 + ' ' + fname_tmp2)\n",
    "\n",
    "            #Get lon and lat name\n",
    "            data_check = xr.open_dataset(fname_tmp2)\n",
    "            if 'rlat' in data_check.dims:\n",
    "                coord_names = ['rlon', 'rlat']\n",
    "                coord_names_R = ro.r.c('rlon', 'rlat')\n",
    "            elif 'x' in data_check.dims:\n",
    "                coord_names = ['x', 'y']\n",
    "                coord_names_R = ro.r.c('x', 'y')\n",
    "            \n",
    "            #Define input filename\n",
    "            fname_in = fname_tmp2\n",
    "            \n",
    "            #Check if last year is complete\n",
    "            DOY_max = data_check.time.dt.dayofyear.max().item()\n",
    "            DOY_end = data_check.time.dt.dayofyear[-1].item()\n",
    "            Yr_end  = data_check.time.dt.year[-1].item()\n",
    "            if DOY_max==366:  DOY_max = DOY_max - (not calendar.isleap(Yr_end)) #Adjust maximum DOY for non-leap years\n",
    "                \n",
    "            #Special treatment if last year is not complete\n",
    "            if DOY_end<DOY_max:\n",
    "                \n",
    "                print('Last year ' + str(Yr_end) + ' is not complete. Dropping ' + str(Yr_end))\n",
    "\n",
    "                #Sub-select data if last year is not complete and save in file\n",
    "                years_cdo2 = years_cdo.split('/')[0] + '/' + str(Yr_end-1)\n",
    "                fname_tmp3 = dir_tmp + var_in + '_' + \"_\".join(model) + '_' + RCP + '_tmp3.nc'\n",
    "                os.system('cdo selyear,' + years_cdo2 + ' ' + fname_tmp2 + ' ' + fname_tmp3)\n",
    "                \n",
    "                #Change input filename\n",
    "                fname_in = fname_tmp3\n",
    "                \n",
    "                #Re-read data for check\n",
    "                data_check = xr.open_dataset(fname_tmp3)\n",
    "                \n",
    "            #Adjust application time (if model simualtion does not go until 2099)\n",
    "            if data_check.time.dt.year[-1].item()<app_years[1]:\n",
    "                app_years_HWMId = ro.r.seq(app_years[0], data_check.time.dt.year[-1].item())\n",
    "            else:\n",
    "                app_years_HWMId = app_years_vec\n",
    "            \n",
    "            #Create time vector for HWMId\n",
    "            time_HWMID = xr.cftime_range(start=str(app_years_HWMId[0]) + '0101', end=str(app_years_HWMId[-1]) + '1231', freq='Y', calendar='standard')\n",
    "            \n",
    "            #Calculate HWMId\n",
    "            t_start = t_util.time()\n",
    "            N_cores = 5\n",
    "            output = r.get_HWMId_vCities_NxN(var_in, fname_in, ref_years_vec, app_years_HWMId, coord_names_R, dir_functions, N_cores)\n",
    "\n",
    "            #Extract variables from R output (dims: lon, lat, time)\n",
    "            HWMID_strength = np.array(output.rx2(\"HWMID_strength\"))\n",
    "            HWMID_length   = np.array(output.rx2(\"HWMID_length\"))\n",
    "            HWMID_DOYstart = np.array(output.rx2(\"HWMID_DOYstart\"))\n",
    "\n",
    "            #Create dataset with same coords as original dataset\n",
    "            data_HWMID = xr.Dataset(coords=dict(zip(data_check.coords, [data_check[coord] for coord in data_check.coords])))\n",
    "            if 'height' in data_HWMID.coords: data_HWMID = data_HWMID.drop('height')\n",
    "\n",
    "            #Put yearly time axis\n",
    "            data_HWMID = data_HWMID.isel(time=1).drop('time')\n",
    "            data_HWMID = data_HWMID.assign_coords({'time': time_HWMID})\n",
    "\n",
    "            #Put HWMID\n",
    "            data_HWMID['HWMID'] = (coord_names + ['time'], HWMID_strength)\n",
    "            data_HWMID['HWMID_length'] = (coord_names + ['time'], HWMID_length)\n",
    "            data_HWMID['HWMID_DOYstart'] = (coord_names + ['time'], HWMID_DOYstart)\n",
    "\n",
    "            #Make sure that the dimension order is correct\n",
    "            if 'x' in data_HWMID.dims:       lat_name, lon_name = 'y', 'x'\n",
    "            elif 'rlat' in data_HWMID.dims:  lat_name, lon_name = 'rlat', 'rlon'\n",
    "            else:                            sys.exit('Names for lat and lon undefined.')  \n",
    "            data_HWMID = data_HWMID.transpose(lat_name, lon_name, 'time')\n",
    "\n",
    "            #Save in file\n",
    "            fname_HWMId = dir_HWMId_out + 'HWMId-' + var_out + \"_\" + \"_\".join(model) + '_' + \"-\".join(scenarios) + \"_\" + str(app_years[0]) + \"-\" + str(app_years[1]) + \".nc\"\n",
    "            if os.path.exists(fname_HWMId): os.remove(fname_HWMId)\n",
    "            data_HWMID.to_netcdf(fname_HWMId)\n",
    "\n",
    "            t_stop = t_util.time()\n",
    "            print('Time elapsed:' + '{:.0f}'.format(t_stop - t_start))\n",
    "            \n",
    "            #Remove temporary files\n",
    "            if os.path.exists(fname_tmp1):      os.remove(fname_tmp1)\n",
    "            if os.path.exists(fname_tmp2):      os.remove(fname_tmp2)\n",
    "            if os.path.exists(fname_tmp3):      os.remove(fname_tmp3)\n",
    "            if os.path.exists(fname_ALA_tmp2):  os.remove(fname_ALA_tmp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
