{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import cftime\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import mplotutils as mpu\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_EUR-11.txt', 'r') as file:  path_eur11 = file.read()\n",
    "\n",
    "dir_CORDEX = path_eur11\n",
    "dir_names  = f'{path_main}Scripts/Model_lists/'\n",
    "dir_out    = f'{path_main}Data/EURO-CORDEX/EMT/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define limits for European box\n",
    "lon_limits_EUR = [-10, 35]\n",
    "lat_limits_EUR = [30, 70]\n",
    "\n",
    "#Define scenarios\n",
    "scenarios = ['historical', 'rcp85']\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models.append(eval(line[:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop over models\n",
    "for model in all_models:\n",
    "    \n",
    "    files = [file for file in os.listdir(dir_CORDEX) if model[0] in file and model[1] in file and model[2] in file]\n",
    "    \n",
    "    if not len(files)>0:\n",
    "        print(model)\n",
    "\n",
    "mod_EUR = ['_'.join(model) for model in all_models]\n",
    "mod_tas = [file.split('_')[2] + '_' + file.split('_')[5] + '_' + file.split('_')[4] for file in os.listdir(dir_CORDEX) if '.nc' in file]\n",
    "mod_tas = set(mod_tas)\n",
    "\n",
    "print(sorted(list(mod_tas.difference(mod_EUR))))\n",
    "print('')\n",
    "print(sorted(list(set(mod_EUR).difference(mod_tas))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate European mean temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_coll = []\n",
    "\n",
    "#Loop over scenarios\n",
    "for scen in scenarios:\n",
    "\n",
    "    print(scen)\n",
    "    \n",
    "    #Loop over models\n",
    "    for i1, model in enumerate(all_models):\n",
    "\n",
    "        #Skip model if no files exist\n",
    "        if model[1]=='IPSL-WRF381P':\n",
    "            t_freq = '_day_'\n",
    "        else:\n",
    "            t_freq = '_mon_'\n",
    "\n",
    "        print(\"  -\" + \"_\".join(model))\n",
    "\n",
    "        #Get files\n",
    "        files = [file for file in os.listdir(dir_CORDEX) if scen in file and model[0] in file and model[1] in file and model[2] in file and t_freq in file]\n",
    "        if len(files)==0:  sys.exit('No files available for this model.')\n",
    "            \n",
    "        #Merge files\n",
    "        files_in   = [dir_CORDEX + file for file in sorted(files)]\n",
    "        file_merge = dir_out + \"tas\" + t_freq + \"\" + \"_\".join(model) + '_' + scen + \"_tmp.nc\"\n",
    "        if os.path.exists(file_merge): os.remove(file_merge)\n",
    "        os.system('cdo mergetime ' + \" \".join(files_in) + \" \" + file_merge)\n",
    "\n",
    "        #Open file\n",
    "        ds = xr.open_dataset(file_merge)\n",
    "        \n",
    "        #Select time\n",
    "        if scen=='historical':  ds = ds.sel(time=slice(None, '2005'))\n",
    "        if scen=='rcp85':       ds = ds.sel(time=slice('2006', None))\n",
    "        \n",
    "        #Drop this variables as they cause problems with time averaging\n",
    "        if 'rotated_pole' in ds:       ds = ds.drop('rotated_pole')\n",
    "        if 'Lambert_Conformal' in ds:  ds = ds.drop('Lambert_Conformal')\n",
    "        if 'crs' in ds:                ds = ds.drop('crs')\n",
    "        \n",
    "        #Resample daily data to monthly data\n",
    "        if t_freq=='_day_':\n",
    "            print('     Resampling day -> month')\n",
    "            ds = ds.resample(time='1M').mean()\n",
    "            \n",
    "        #Get lat and lon names\n",
    "        if 'lat' in ds.coords:   lat_name, lon_name = 'lat', 'lon'\n",
    "        else:                    lat_name, lon_name = 'latitude', 'longitude'\n",
    "        if 'rlat' in ds.coords:  lat_name2, lon_name2 = 'rlat', 'rlon'\n",
    "        elif 'x' in ds.coords:   lat_name2, lon_name2 = 'x', 'y'\n",
    "            \n",
    "\n",
    "        #Convert longitude from [0, 360] to [-180, 180]\n",
    "        if np.any(ds[lon_name]>350):  mod_coll.append(model)\n",
    "        ds[lon_name] = ds[lon_name].where(ds[lon_name]<180, ((ds[lon_name] + 180) % 360) - 180)\n",
    "            \n",
    "        #Get mask for Europe\n",
    "        mask_EUR = ((ds[lon_name]>=lon_limits_EUR[0]) & (ds[lon_name]<=lon_limits_EUR[1]) & \n",
    "                    (ds[lat_name]>=lat_limits_EUR[0]) & (ds[lat_name]<=lat_limits_EUR[1]))\n",
    "        \n",
    "        #Mask Europe (only for EMT!)\n",
    "        ds_masked = ds.where(mask_EUR)\n",
    "        \n",
    "        #Weight by area\n",
    "        area_weights = np.cos(ds_masked[lat_name] * np.pi/180)\n",
    "        ds_EMT = ds_masked.tas.weighted(area_weights).mean((lat_name2, lon_name2))  \n",
    "        \n",
    "        #Calculate yearly averages\n",
    "        ds_grid = ds.resample(time='1Y').mean('time')\n",
    "        ds_EMT  = ds_EMT.resample(time='1Y').mean('time')\n",
    "        ds_EMT  = ds_EMT.to_dataset(name='tas')\n",
    "\n",
    "        #Save data in file\n",
    "        time_str  = str(ds.time[0].dt.year.values) + '-' + str(ds.time[-1].dt.year.values)\n",
    "        fname_out_EMT  = dir_out + 'EMT_year_' + scen + '_' + \"_\".join(model) + '_' + time_str + \".nc\"\n",
    "        fname_out_grid = dir_out + 'tas_year_' + scen + '_' + \"_\".join(model) + '_' + time_str + \".nc\"\n",
    "        if os.path.exists(fname_out_EMT):   os.remove(fname_out_EMT)\n",
    "        if os.path.exists(fname_out_grid):  os.remove(fname_out_grid)\n",
    "        ds_EMT.to_netcdf(fname_out_EMT)\n",
    "        ds_grid.to_netcdf(fname_out_grid)\n",
    "        \n",
    "        #Remove temporary merge file\n",
    "        os.remove(file_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data and box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(1, 1, figsize=(14,6), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax1.coastlines(linewidth=0.75)\n",
    "\n",
    "for i1, model in enumerate(all_models):\n",
    "    \n",
    "    files = [file for file in os.listdir(dir_CORDEX) if model[0] in file and model[1] in file and model[2] in file and 'tas_' in file]\n",
    "    if len(files)==0:\n",
    "        print(model)\n",
    "        continue\n",
    "        \n",
    "#     print(model)\n",
    "\n",
    "    file = files[0]\n",
    "    ds = xr.open_dataset(dir_CORDEX + file)\n",
    "    ds = ds['tas'].isel(time=0)\n",
    "    \n",
    "    ds = ds * 0 + i1\n",
    "    \n",
    "    if 'lat' in ds.coords:  lat_name_p, lon_name_p = 'lat', 'lon'\n",
    "    else:                   lat_name_p, lon_name_p = 'latitude', 'longitude'\n",
    "\n",
    "    ax1.pcolormesh(ds[lon_name_p], ds[lat_name_p], ds, vmin=0, vmax=len(all_models), shading='auto', transform=ccrs.PlateCarree(), alpha=0.1)\n",
    "\n",
    "# Draw the rectangular extent of the second plot on the first:\n",
    "x = [-10, 35, 35, -10, -10]\n",
    "y = [30, 30, 70, 70, 30]\n",
    "ax1.fill(x, y, transform=ccrs.PlateCarree(), edgecolor='r', facecolor='none', linewidth=3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
