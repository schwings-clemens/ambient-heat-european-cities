{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as t_util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import cftime\n",
    "import xarray as xr\n",
    "\n",
    "#My functions\n",
    "sys.path.insert(0,'../functions/')\n",
    "import functions_HeatWavesCities as fun_HWC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main paths\n",
    "with open('../path_main.txt', 'r') as file:    path_main  = file.read()\n",
    "with open('../path_EUR-11.txt', 'r') as file:  path_eur11 = file.read()\n",
    "    \n",
    "dir_CORDEX  = path_eur11\n",
    "dir_scripts = f'{path_main}Scripts/'\n",
    "dir_names   = f'{path_main}Scripts/Model_lists/'\n",
    "dir_JJA     = f'{path_main}Data/EURO-CORDEX/JJA/'\n",
    "dir_Yearmax = f'{path_main}Data/EURO-CORDEX/Yearmax/'\n",
    "if not os.path.exists(dir_JJA):      os.mkdir(dir_JJA)\n",
    "if not os.path.exists(dir_Yearmax):  os.mkdir(dir_Yearmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-reflection",
   "metadata": {},
   "source": [
    "## Prepare variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define scenarios and variables\n",
    "variables = ['tasmax', 'tasmin']\n",
    "\n",
    "\n",
    "#Define models and RCPs which should be used\n",
    "all_models = dict()\n",
    "all_models['rcp85'] = []\n",
    "with open(dir_names + 'Models_CORDEX-EUR-11_RCP85.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        all_models['rcp85'].append(eval(line[:-1]))\n",
    "\n",
    "#Define time periods\n",
    "time_periods = [[1981, 2010], [2070, 2099]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-novelty",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-stability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop over time periods\n",
    "for time_per in time_periods:\n",
    "    \n",
    "    #Create slice for selecting data\n",
    "    time_sel = slice(str(time_per[0]), str(time_per[1]))\n",
    "    \n",
    "    #Define scenarios\n",
    "    if int(time_sel.start)>2005:\n",
    "        scenarios = ['rcp85']\n",
    "    else:\n",
    "        scenarios = ['historical', 'rcp85']\n",
    "\n",
    "    #Loop over models\n",
    "    for model in all_models['rcp85']:\n",
    "        \n",
    "        print(\"_\".join(model))\n",
    "\n",
    "        #Loop over variables\n",
    "        for variab in variables:\n",
    "\n",
    "            print(\" -\" + variab, end=': ')\n",
    "\n",
    "            #Get file names\n",
    "            fnames_merge = []\n",
    "            for scen in scenarios:\n",
    "\n",
    "                dir_files = dir_CORDEX + scen + '/' + variab + '/'\n",
    "                fnames = [dir_files + file for file in os.listdir(dir_files) if model[0] in file and model[1] in file and model[2] in file]\n",
    "                fnames = sorted(fnames)\n",
    "\n",
    "                #Only include files within selected period\n",
    "                fnames = [fname for fname in fnames if int(fname[-11:-7])>=time_per[0]]\n",
    "                fnames = [fname for fname in fnames if int(fname[-20:-16])<=time_per[1]]\n",
    "            \n",
    "                #Add to list for all files for merging\n",
    "                fnames_merge = fnames_merge + fnames\n",
    "\n",
    "            print(fnames_merge[0][-20:-16] + '-' + fnames_merge[-1][-11:-7])\n",
    "\n",
    "            #Merge single files to one large file\n",
    "            t_sta = t_util.time()\n",
    "            file_merge = dir_JJA + 'CORDEX_merged_' + variab + '_' + scen + \"_\" + \"_\".join(model) + '_' + \"_\".join([str(time) for time in time_per]) + '_JJAmean_tmp.nc'\n",
    "            if os.path.exists(file_merge): os.remove(file_merge)\n",
    "            os.system('cdo mergetime ' + \" \".join(fnames_merge) + \" \" + file_merge)\n",
    "            t_end = t_util.time()\n",
    "            print(\" -- \" + \"{:.1f}\".format(t_end - t_sta))\n",
    "\n",
    "            #Open data set \n",
    "            data = xr.open_dataset(file_merge, use_cftime=True)\n",
    "            \n",
    "            #Select time\n",
    "            data = data.sel(time=time_sel)\n",
    "\n",
    "            #Read calendar\n",
    "            with xr.open_dataset(fnames[0], decode_times=False) as ds:\n",
    "                calendar = ds.time.attrs['calendar']\n",
    "                ds.close()            \n",
    "\n",
    "            #Drop unnecessary variables\n",
    "            vars_drop = set(data.data_vars).difference([variab])\n",
    "            for var in vars_drop:  data = data.drop(var)\n",
    "            \n",
    "            #Convert Â°C to K (if necessary)\n",
    "            if (model[0]=='CNRM-CERFACS-CNRM-CM5') and (model[1]=='CNRM-ALADIN53') and (variab in ['tasmax', 'tasmin']):\n",
    "                \n",
    "                sel_time = (data.time.dt.year>=2006) * 273.15\n",
    "                attrs = data[variab].attrs\n",
    "                data[variab] = data[variab] + sel_time\n",
    "                data[variab].attrs = attrs\n",
    "                \n",
    "            #Check units of huss\n",
    "            check1 = data[variab].isel(time=slice(0, 100)).mean()\n",
    "            check2 = data[variab].isel(time=slice(-100, -1)).mean()\n",
    "            if (variab=='huss') and ((check1>0.01) or (check1<0.0001) or (check2>0.01) or (check2<0.0001)):\n",
    "                sys.exit('Check units of ' + variab)\n",
    "                \n",
    "            #Select summer\n",
    "            sel_JJA  = (data.time.dt.month>=6) & (data.time.dt.month<=8)\n",
    "            data_JJA = data.isel(time=sel_JJA)\n",
    "\n",
    "            #Get climatology for summer months\n",
    "            month_sta = 6\n",
    "            month_end = 8\n",
    "            win_half  = 15\n",
    "            climatology = fun_HWC.get_clim_or_quant('climatology', data, calendar, [variab], month_sta, month_end, win_half)\n",
    "\n",
    "            #Select original data in JJA and adjust time (for matching DOY)\n",
    "            data_JJA = fun_HWC.replace_time(data_JJA, calendar, month_sta, month_end)\n",
    "\n",
    "            #Calculate JJA anomalies\n",
    "            JJA_anom = data_JJA.groupby(\"time.dayofyear\") - climatology.groupby(\"time.dayofyear\").mean()\n",
    "\n",
    "            #Calculate summer mean, median, Q90, Q99\n",
    "            data_JJA_mean = data_JJA.mean('time')\n",
    "            data_JJA_Q50  = data_JJA.quantile(0.50, 'time')\n",
    "            data_JJA_Q90  = data_JJA.quantile(0.90, 'time')\n",
    "            data_JJA_Q99  = data_JJA.quantile(0.99, 'time')\n",
    "\n",
    "            #Calculate summer variability\n",
    "            JJA_anom_Q25 = JJA_anom.quantile(0.25, 'time')\n",
    "            JJA_anom_Q75 = JJA_anom.quantile(0.75, 'time')\n",
    "            JJA_anom_IQR = JJA_anom_Q75 - JJA_anom_Q25\n",
    "\n",
    "            #Calculate summer average, yearly maximum, and summer variability\n",
    "            data_Yearmax = data.resample(time='1Y').max()            \n",
    "\n",
    "            #Creat output directory\n",
    "            dir_JJA_out  =  dir_JJA + variab + '/'\n",
    "            dir_Ymax_out =  dir_Yearmax + variab + '/'\n",
    "            if not os.path.exists(dir_JJA_out):   os.mkdir(dir_JJA_out)\n",
    "            if not os.path.exists(dir_Ymax_out):  os.mkdir(dir_Ymax_out)\n",
    "\n",
    "            #Create output file names\n",
    "            output_str = \"_\" + \"_\".join(model) + '_' + \"-\".join(scenarios) +  \"_\" + time_sel.start + \"-\" + time_sel.stop + \".nc\"\n",
    "            fname_JJA_mean = dir_JJA_out + variab + \"_JJA-mean\" + output_str\n",
    "            fname_JJA_Q50  = dir_JJA_out + variab + \"_JJA-Q50\" + output_str\n",
    "            fname_JJA_Q90  = dir_JJA_out + variab + \"_JJA-Q90\" + output_str\n",
    "            fname_JJA_Q99  = dir_JJA_out + variab + \"_JJA-Q99\" + output_str\n",
    "            fname_JJQ_IQR  = dir_JJA_out + variab + \"-anom_JJA-IQR\" + output_str\n",
    "            fname_Yearmax  = dir_Ymax_out + variab + \"_Yearmax\" +  output_str\n",
    "            if os.path.exists(fname_JJA_mean):  os.remove(fname_JJA_mean)\n",
    "            if os.path.exists(fname_JJA_Q50):   os.remove(fname_JJA_Q50)\n",
    "            if os.path.exists(fname_JJA_Q90):   os.remove(fname_JJA_Q90)\n",
    "            if os.path.exists(fname_JJA_Q99):   os.remove(fname_JJA_Q99)\n",
    "            if os.path.exists(fname_JJQ_IQR):   os.remove(fname_JJQ_IQR)\n",
    "            if os.path.exists(fname_Yearmax):   os.remove(fname_Yearmax)\n",
    "\n",
    "            #Save in file\n",
    "            data_JJA_mean.to_netcdf(fname_JJA_mean)\n",
    "            data_JJA_Q50.to_netcdf(fname_JJA_Q50)\n",
    "            data_JJA_Q90.to_netcdf(fname_JJA_Q90)\n",
    "            data_JJA_Q99.to_netcdf(fname_JJA_Q99)\n",
    "            JJA_anom_IQR.to_netcdf(fname_JJQ_IQR)\n",
    "            data_Yearmax.to_netcdf(fname_Yearmax)\n",
    "\n",
    "            #Remove temporarily merged file\n",
    "            os.remove(file_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf26928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
